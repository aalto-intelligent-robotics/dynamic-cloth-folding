{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n",
      "Args Namespace(buffer_size=100000, distance_threshold=0.03, env_name='Cloth-v1', eval_steps=500, her_percent=0.8, image_size=84, image_training=1, max_advance=0.05, max_path_length=50, min_expl_steps=1000, num_cycles=100, num_epochs=100, profile=1, randomize_geoms=0, randomize_params=1, rgb=1, run=1, seed=1, strict=1, task='sideways', title='her-sac-validation-newrange-3cm', train_steps=100, uniform_jnt_tend=1)\n",
      "Training with GPU\n",
      "2020-10-25 21:38:43.130982 EET | Variant:\n",
      "2020-10-25 21:38:43.131191 EET | {\n",
      "  \"algorithm\": \"SAC\",\n",
      "  \"layer_size\": 256,\n",
      "  \"trainer_kwargs\": {\n",
      "    \"discount\": 0.99,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"target_update_period\": 1,\n",
      "    \"policy_lr\": 0.0003,\n",
      "    \"qf_lr\": 0.0003,\n",
      "    \"reward_scale\": 1,\n",
      "    \"use_automatic_entropy_tuning\": true\n",
      "  },\n",
      "  \"path_collector_kwargs\": {\n",
      "    \"additional_keys\": \"['robot_observation']\"\n",
      "  },\n",
      "  \"policy_kwargs\": {\n",
      "    \"input_width\": 84,\n",
      "    \"input_height\": 84,\n",
      "    \"input_channels\": 3,\n",
      "    \"kernel_sizes\": [\n",
      "      3,\n",
      "      3,\n",
      "      3,\n",
      "      3\n",
      "    ],\n",
      "    \"n_channels\": [\n",
      "      32,\n",
      "      32,\n",
      "      32,\n",
      "      32\n",
      "    ],\n",
      "    \"strides\": [\n",
      "      2,\n",
      "      2,\n",
      "      2,\n",
      "      2\n",
      "    ],\n",
      "    \"paddings\": [\n",
      "      0,\n",
      "      0,\n",
      "      0,\n",
      "      0\n",
      "    ],\n",
      "    \"hidden_sizes\": [\n",
      "      256,\n",
      "      256,\n",
      "      256,\n",
      "      256\n",
      "    ],\n",
      "    \"init_w\": 0.0001\n",
      "  },\n",
      "  \"replay_buffer_kwargs\": {\n",
      "    \"max_size\": 100000,\n",
      "    \"fraction_goals_env_goals\": 0,\n",
      "    \"fraction_goals_rollout_goals\": 0.19999999999999996,\n",
      "    \"internal_keys\": \"['image', 'model_params', 'robot_observation']\"\n",
      "  },\n",
      "  \"algorithm_kwargs\": {\n",
      "    \"num_epochs\": 100,\n",
      "    \"num_trains_per_train_loop\": 100,\n",
      "    \"num_expl_steps_per_train_loop\": 100,\n",
      "    \"num_train_loops_per_epoch\": 100,\n",
      "    \"max_path_length\": 50,\n",
      "    \"num_eval_steps_per_epoch\": 500,\n",
      "    \"min_num_steps_before_training\": 1000,\n",
      "    \"batch_size\": 256\n",
      "  },\n",
      "  \"env_name\": \"Cloth-v1\",\n",
      "  \"version\": \"her-sac-validation-newrange-3cm\",\n",
      "  \"image_training\": true,\n",
      "  \"env_kwargs\": {\n",
      "    \"task\": \"sideways\",\n",
      "    \"pixels\": true,\n",
      "    \"strict\": true,\n",
      "    \"distance_threshold\": 0.03,\n",
      "    \"randomize_params\": true,\n",
      "    \"randomize_geoms\": false,\n",
      "    \"uniform_jnt_tend\": true,\n",
      "    \"image_size\": 84,\n",
      "    \"rgb\": true,\n",
      "    \"max_advance\": 0.05,\n",
      "    \"random_seed\": 1\n",
      "  }\n",
      "}\n",
      "Env kwargs {'task': 'sideways', 'pixels': True, 'strict': True, 'distance_threshold': 0.03, 'randomize_params': True, 'randomize_geoms': False, 'uniform_jnt_tend': True, 'image_size': 84, 'rgb': True, 'max_advance': 0.05, 'random_seed': 1}\n",
      "Found 4 GPUs for rendering. Using device 0.\n",
      "/home/clothmanip/robotics/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "Env kwargs {'task': 'sideways', 'pixels': True, 'strict': True, 'distance_threshold': 0.03, 'randomize_params': True, 'randomize_geoms': False, 'uniform_jnt_tend': True, 'image_size': 84, 'rgb': True, 'max_advance': 0.05, 'random_seed': 1}\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 0\n",
      "\n",
      " Cycle 0 0\n",
      "Took to collect: 3.45522403717041\n",
      "Took to train: 6.775636911392212\n",
      "\n",
      " Cycle 1 0\n",
      "Took to collect: 4.878506422042847\n",
      "Took to train: 6.802162408828735\n",
      "\n",
      " Cycle 2 0\n",
      "Took to collect: 4.777579307556152\n",
      "Took to train: 6.741445064544678\n",
      "\n",
      " Cycle 3 0\n",
      "Took to collect: 3.388913154602051\n",
      "Took to train: 6.600188970565796\n",
      "\n",
      " Cycle 4 0\n",
      "Took to collect: 4.815216779708862\n",
      "Took to train: 6.55767297744751\n",
      "\n",
      " Cycle 5 0\n",
      "Took to collect: 5.794529676437378\n",
      "Took to train: 6.673816442489624\n",
      "\n",
      " Cycle 6 0\n",
      "Took to collect: 4.117269039154053\n",
      "Took to train: 6.744282007217407\n",
      "\n",
      " Cycle 7 0\n",
      "Took to collect: 4.16362190246582\n",
      "Took to train: 6.671435356140137\n",
      "\n",
      " Cycle 8 0\n",
      "Took to collect: 4.466702938079834\n",
      "Took to train: 6.7641026973724365\n",
      "\n",
      " Cycle 9 0\n",
      "Took to collect: 4.781481981277466\n",
      "Took to train: 6.681918144226074\n",
      "\n",
      " Cycle 10 0\n",
      "Took to collect: 5.080369710922241\n",
      "Took to train: 6.737580299377441\n",
      "\n",
      " Cycle 11 0\n",
      "Took to collect: 4.590215682983398\n",
      "Took to train: 6.750507116317749\n",
      "\n",
      " Cycle 12 0\n",
      "Took to collect: 3.9552547931671143\n",
      "Took to train: 6.777282953262329\n",
      "\n",
      " Cycle 13 0\n",
      "Took to collect: 4.583254814147949\n",
      "Took to train: 6.643032073974609\n",
      "\n",
      " Cycle 14 0\n",
      "Took to collect: 3.9788522720336914\n",
      "Took to train: 6.6240904331207275\n",
      "\n",
      " Cycle 15 0\n",
      "Took to collect: 4.046512842178345\n",
      "Took to train: 6.610950231552124\n",
      "\n",
      " Cycle 16 0\n",
      "Took to collect: 3.4868037700653076\n",
      "Took to train: 6.608020544052124\n",
      "\n",
      " Cycle 17 0\n",
      "Took to collect: 3.7902684211730957\n",
      "Took to train: 6.614627838134766\n",
      "\n",
      " Cycle 18 0\n",
      "Took to collect: 4.412933349609375\n",
      "Took to train: 6.628905534744263\n",
      "\n",
      " Cycle 19 0\n",
      "Took to collect: 5.014721155166626\n",
      "Took to train: 6.6173765659332275\n",
      "\n",
      " Cycle 20 0\n",
      "Took to collect: 4.571905136108398\n",
      "Took to train: 6.624835968017578\n",
      "\n",
      " Cycle 21 0\n",
      "Took to collect: 4.7528767585754395\n",
      "Took to train: 6.694334506988525\n",
      "\n",
      " Cycle 22 0\n",
      "Took to collect: 4.74585747718811\n",
      "Took to train: 6.630837678909302\n",
      "\n",
      " Cycle 23 0\n",
      "Took to collect: 4.7368950843811035\n",
      "Took to train: 6.627577543258667\n",
      "\n",
      " Cycle 24 0\n",
      "Took to collect: 5.139927387237549\n",
      "Took to train: 6.630519151687622\n",
      "\n",
      " Cycle 25 0\n",
      "Took to collect: 5.2134480476379395\n",
      "Took to train: 6.635230779647827\n",
      "\n",
      " Cycle 26 0\n",
      "Took to collect: 3.5595908164978027\n",
      "Took to train: 6.628434419631958\n",
      "\n",
      " Cycle 27 0\n",
      "Took to collect: 4.4884560108184814\n",
      "Took to train: 6.633333444595337\n",
      "\n",
      " Cycle 28 0\n",
      "Took to collect: 4.149884223937988\n",
      "Took to train: 6.622318744659424\n",
      "\n",
      " Cycle 29 0\n",
      "Took to collect: 4.6869425773620605\n",
      "Took to train: 6.813567161560059\n",
      "\n",
      " Cycle 30 0\n",
      "Took to collect: 4.066912412643433\n",
      "Took to train: 6.883075714111328\n",
      "\n",
      " Cycle 31 0\n",
      "Took to collect: 4.045697927474976\n",
      "Took to train: 6.735025644302368\n",
      "\n",
      " Cycle 32 0\n",
      "Took to collect: 3.992065906524658\n",
      "Took to train: 6.69452166557312\n",
      "\n",
      " Cycle 33 0\n",
      "Took to collect: 4.111604928970337\n",
      "Took to train: 6.7328572273254395\n",
      "\n",
      " Cycle 34 0\n",
      "Took to collect: 3.884941816329956\n",
      "Took to train: 6.717320680618286\n",
      "\n",
      " Cycle 35 0\n",
      "Took to collect: 3.9131202697753906\n",
      "Took to train: 6.676076173782349\n",
      "\n",
      " Cycle 36 0\n",
      "Took to collect: 4.14197564125061\n",
      "Took to train: 6.699440956115723\n",
      "\n",
      " Cycle 37 0\n",
      "Took to collect: 3.9247262477874756\n",
      "Took to train: 6.577937602996826\n",
      "\n",
      " Cycle 38 0\n",
      "Took to collect: 4.055187702178955\n",
      "Took to train: 6.713369131088257\n",
      "\n",
      " Cycle 39 0\n",
      "Took to collect: 4.416384696960449\n",
      "Took to train: 6.663429498672485\n",
      "\n",
      " Cycle 40 0\n",
      "Took to collect: 5.133575201034546\n",
      "Took to train: 6.55055570602417\n",
      "\n",
      " Cycle 41 0\n",
      "Took to collect: 4.244913578033447\n",
      "Took to train: 6.656989336013794\n",
      "\n",
      " Cycle 42 0\n",
      "Took to collect: 5.690836191177368\n",
      "Took to train: 6.6846911907196045\n",
      "\n",
      " Cycle 43 0\n",
      "Took to collect: 4.83428692817688\n",
      "Took to train: 6.6803367137908936\n",
      "\n",
      " Cycle 44 0\n",
      "Took to collect: 3.987367630004883\n",
      "Took to train: 6.656575441360474\n",
      "\n",
      " Cycle 45 0\n",
      "Took to collect: 3.8759357929229736\n",
      "Took to train: 6.720355749130249\n",
      "\n",
      " Cycle 46 0\n",
      "Took to collect: 4.063852548599243\n",
      "Took to train: 6.681140899658203\n",
      "\n",
      " Cycle 47 0\n",
      "Took to collect: 4.892111539840698\n",
      "Took to train: 6.7298078536987305\n",
      "\n",
      " Cycle 48 0\n",
      "Took to collect: 5.12348747253418\n",
      "Took to train: 6.66328501701355\n",
      "\n",
      " Cycle 49 0\n",
      "Took to collect: 3.585726499557495\n",
      "Took to train: 6.714486598968506\n",
      "\n",
      " Cycle 50 0\n",
      "Took to collect: 4.688937664031982\n",
      "Took to train: 6.614465951919556\n",
      "\n",
      " Cycle 51 0\n",
      "Took to collect: 4.241864442825317\n",
      "Took to train: 6.645103454589844\n",
      "\n",
      " Cycle 52 0\n",
      "Took to collect: 3.5581886768341064\n",
      "Took to train: 6.499927520751953\n",
      "\n",
      " Cycle 53 0\n",
      "Took to collect: 6.331151247024536\n",
      "Took to train: 6.540135145187378\n",
      "\n",
      " Cycle 54 0\n",
      "Took to collect: 3.8195221424102783\n",
      "Took to train: 6.563689470291138\n",
      "\n",
      " Cycle 55 0\n",
      "Took to collect: 3.6337270736694336\n",
      "Took to train: 6.680408239364624\n",
      "\n",
      " Cycle 56 0\n",
      "Took to collect: 5.616616725921631\n",
      "Took to train: 6.567263841629028\n",
      "\n",
      " Cycle 57 0\n",
      "Took to collect: 5.221402645111084\n",
      "Took to train: 6.512800931930542\n",
      "\n",
      " Cycle 58 0\n",
      "Took to collect: 4.642910957336426\n",
      "Took to train: 6.558451175689697\n",
      "\n",
      " Cycle 59 0\n",
      "Took to collect: 4.5880210399627686\n",
      "Took to train: 6.723251581192017\n",
      "\n",
      " Cycle 60 0\n",
      "Took to collect: 4.701382160186768\n",
      "Took to train: 6.445599555969238\n",
      "\n",
      " Cycle 61 0\n",
      "Took to collect: 4.066442489624023\n",
      "Took to train: 6.4392218589782715\n",
      "\n",
      " Cycle 62 0\n",
      "Took to collect: 3.9979302883148193\n",
      "Took to train: 6.4470765590667725\n",
      "\n",
      " Cycle 63 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 6.224533557891846\n",
      "Took to train: 6.446218013763428\n",
      "\n",
      " Cycle 64 0\n",
      "Took to collect: 5.3171067237854\n",
      "Took to train: 6.637284755706787\n",
      "\n",
      " Cycle 65 0\n",
      "Took to collect: 5.753134489059448\n",
      "Took to train: 6.670085430145264\n",
      "\n",
      " Cycle 66 0\n",
      "Took to collect: 6.910505771636963\n",
      "Took to train: 6.6516101360321045\n",
      "\n",
      " Cycle 67 0\n",
      "Took to collect: 6.8535027503967285\n",
      "Took to train: 6.663463592529297\n",
      "\n",
      " Cycle 68 0\n",
      "Took to collect: 7.337776184082031\n",
      "Took to train: 6.641089200973511\n",
      "\n",
      " Cycle 69 0\n",
      "Took to collect: 7.355886459350586\n",
      "Took to train: 6.419955253601074\n",
      "\n",
      " Cycle 70 0\n",
      "Took to collect: 6.104175806045532\n",
      "Took to train: 6.4236531257629395\n",
      "\n",
      " Cycle 71 0\n",
      "Took to collect: 5.362196922302246\n",
      "Took to train: 6.418001890182495\n",
      "\n",
      " Cycle 72 0\n",
      "Took to collect: 4.818782329559326\n",
      "Took to train: 6.4172375202178955\n",
      "\n",
      " Cycle 73 0\n",
      "Took to collect: 5.182776689529419\n",
      "Took to train: 6.612403631210327\n",
      "\n",
      " Cycle 74 0\n",
      "Took to collect: 8.322316884994507\n",
      "Took to train: 6.514460325241089\n",
      "\n",
      " Cycle 75 0\n",
      "Took to collect: 7.046366930007935\n",
      "Took to train: 6.614407539367676\n",
      "\n",
      " Cycle 76 0\n",
      "Took to collect: 6.781808137893677\n",
      "Took to train: 6.623324155807495\n",
      "\n",
      " Cycle 77 0\n",
      "Took to collect: 5.790254592895508\n",
      "Took to train: 6.582635164260864\n",
      "\n",
      " Cycle 78 0\n",
      "Took to collect: 6.4914000034332275\n",
      "Took to train: 6.612980604171753\n",
      "\n",
      " Cycle 79 0\n",
      "Took to collect: 8.251107692718506\n",
      "Took to train: 6.65779709815979\n",
      "\n",
      " Cycle 80 0\n",
      "Took to collect: 8.301198720932007\n",
      "Took to train: 6.665887832641602\n",
      "\n",
      " Cycle 81 0\n",
      "Took to collect: 6.634016513824463\n",
      "Took to train: 6.614804029464722\n",
      "\n",
      " Cycle 82 0\n",
      "Took to collect: 5.020727634429932\n",
      "Took to train: 6.6518943309783936\n",
      "\n",
      " Cycle 83 0\n",
      "Took to collect: 5.467621326446533\n",
      "Took to train: 6.674199819564819\n",
      "\n",
      " Cycle 84 0\n",
      "Took to collect: 5.520261764526367\n",
      "Took to train: 6.58627462387085\n",
      "\n",
      " Cycle 85 0\n",
      "Took to collect: 6.230893611907959\n",
      "Took to train: 6.64901876449585\n",
      "\n",
      " Cycle 86 0\n",
      "Took to collect: 7.165344476699829\n",
      "Took to train: 6.6765220165252686\n",
      "\n",
      " Cycle 87 0\n",
      "Took to collect: 5.4811835289001465\n",
      "Took to train: 6.666903257369995\n",
      "\n",
      " Cycle 88 0\n",
      "Took to collect: 4.869858741760254\n",
      "Took to train: 6.674504518508911\n",
      "\n",
      " Cycle 89 0\n",
      "Took to collect: 4.938470363616943\n",
      "Took to train: 6.656334638595581\n",
      "\n",
      " Cycle 90 0\n",
      "Took to collect: 5.011800527572632\n",
      "Took to train: 6.639475584030151\n",
      "\n",
      " Cycle 91 0\n",
      "Took to collect: 4.995947599411011\n",
      "Took to train: 6.520749568939209\n",
      "\n",
      " Cycle 92 0\n",
      "Took to collect: 4.456803321838379\n",
      "Took to train: 6.427732944488525\n",
      "\n",
      " Cycle 93 0\n",
      "Took to collect: 5.967164754867554\n",
      "Took to train: 6.62367582321167\n",
      "\n",
      " Cycle 94 0\n",
      "Took to collect: 4.751065254211426\n",
      "Took to train: 6.640181064605713\n",
      "\n",
      " Cycle 95 0\n",
      "Took to collect: 4.391962766647339\n",
      "Took to train: 6.647265911102295\n",
      "\n",
      " Cycle 96 0\n",
      "Took to collect: 5.5225207805633545\n",
      "Took to train: 6.603542327880859\n",
      "\n",
      " Cycle 97 0\n",
      "Took to collect: 4.400118827819824\n",
      "Took to train: 6.657415390014648\n",
      "\n",
      " Cycle 98 0\n",
      "Took to collect: 4.929547548294067\n",
      "Took to train: 6.52400279045105\n",
      "\n",
      " Cycle 99 0\n",
      "Took to collect: 4.7660276889801025\n",
      "Took to train: 6.647682428359985\n",
      "Time collect avg cycle: 4.97442991733551\n",
      "Time train avg cycle: 6.632893731594086\n",
      "Total avg cycle: 11.618962619304657\n",
      "Ending epoch\n",
      "2020-10-25 21:59:15.928542 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 0 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                            0\n",
      "trainer/QF1 Loss                                   1.40796\n",
      "trainer/QF2 Loss                                   1.40954\n",
      "trainer/Policy Loss                               -2.01047\n",
      "trainer/Q1 Predictions Mean                        0.000220282\n",
      "trainer/Q1 Predictions Std                         0.000169998\n",
      "trainer/Q1 Predictions Max                         0.000614212\n",
      "trainer/Q1 Predictions Min                        -0.000446349\n",
      "trainer/Q2 Predictions Mean                       -0.000512785\n",
      "trainer/Q2 Predictions Std                         0.000406172\n",
      "trainer/Q2 Predictions Max                         0.000228694\n",
      "trainer/Q2 Predictions Min                        -0.00182235\n",
      "trainer/Q Targets Mean                             1.0971\n",
      "trainer/Q Targets Std                              0.452563\n",
      "trainer/Q Targets Max                              2.56318\n",
      "trainer/Q Targets Min                             -0.0653381\n",
      "trainer/Log Pis Mean                              -2.01094\n",
      "trainer/Log Pis Std                                0.413044\n",
      "trainer/Log Pis Max                               -0.827267\n",
      "trainer/Log Pis Min                               -2.72489\n",
      "trainer/policy/mean Mean                           9.2615e-06\n",
      "trainer/policy/mean Std                            6.71031e-05\n",
      "trainer/policy/mean Max                            5.81505e-05\n",
      "trainer/policy/mean Min                           -8.56219e-05\n",
      "trainer/policy/normal/std Mean                     1.00002\n",
      "trainer/policy/normal/std Std                      5.92299e-06\n",
      "trainer/policy/normal/std Max                      1.00003\n",
      "trainer/policy/normal/std Min                      1.00001\n",
      "trainer/policy/normal/log_std Mean                 2.1219e-05\n",
      "trainer/policy/normal/log_std Std                  5.92288e-06\n",
      "trainer/policy/normal/log_std Max                  2.67025e-05\n",
      "trainer/policy/normal/log_std Min                  1.29937e-05\n",
      "trainer/Alpha                                      1\n",
      "trainer/Alpha Loss                                -0\n",
      "exploration/num steps total                    11000\n",
      "exploration/num paths total                      220\n",
      "exploration/path length Mean                      50\n",
      "exploration/path length Std                        0\n",
      "exploration/path length Max                       50\n",
      "exploration/path length Min                       50\n",
      "exploration/Rewards Mean                          -1\n",
      "exploration/Rewards Std                            0\n",
      "exploration/Rewards Max                           -1\n",
      "exploration/Rewards Min                           -1\n",
      "exploration/Returns Mean                         -50\n",
      "exploration/Returns Std                            0\n",
      "exploration/Returns Max                          -50\n",
      "exploration/Returns Min                          -50\n",
      "exploration/Actions Mean                          -0.124692\n",
      "exploration/Actions Std                            0.593242\n",
      "exploration/Actions Max                            0.996993\n",
      "exploration/Actions Min                           -0.999595\n",
      "exploration/Num Paths                            200\n",
      "exploration/Average Returns                      -50\n",
      "exploration/env_infos/final/is_success Mean        0\n",
      "exploration/env_infos/final/is_success Std         0\n",
      "exploration/env_infos/final/is_success Max         0\n",
      "exploration/env_infos/final/is_success Min         0\n",
      "exploration/env_infos/initial/is_success Mean      0\n",
      "exploration/env_infos/initial/is_success Std       0\n",
      "exploration/env_infos/initial/is_success Max       0\n",
      "exploration/env_infos/initial/is_success Min       0\n",
      "exploration/env_infos/is_success Mean              0\n",
      "exploration/env_infos/is_success Std               0\n",
      "exploration/env_infos/is_success Max               0\n",
      "exploration/env_infos/is_success Min               0\n",
      "evaluation/num steps total                       500\n",
      "evaluation/num paths total                        10\n",
      "evaluation/path length Mean                       50\n",
      "evaluation/path length Std                         0\n",
      "evaluation/path length Max                        50\n",
      "evaluation/path length Min                        50\n",
      "evaluation/Rewards Mean                           -1\n",
      "evaluation/Rewards Std                             0\n",
      "evaluation/Rewards Max                            -1\n",
      "evaluation/Rewards Min                            -1\n",
      "evaluation/Returns Mean                          -50\n",
      "evaluation/Returns Std                             0\n",
      "evaluation/Returns Max                           -50\n",
      "evaluation/Returns Min                           -50\n",
      "evaluation/Actions Mean                            9.26151e-06\n",
      "evaluation/Actions Std                             6.71031e-05\n",
      "evaluation/Actions Max                             5.81505e-05\n",
      "evaluation/Actions Min                            -8.56219e-05\n",
      "evaluation/Num Paths                              10\n",
      "evaluation/Average Returns                       -50\n",
      "evaluation/env_infos/final/is_success Mean         0\n",
      "evaluation/env_infos/final/is_success Std          0\n",
      "evaluation/env_infos/final/is_success Max          0\n",
      "evaluation/env_infos/final/is_success Min          0\n",
      "evaluation/env_infos/initial/is_success Mean       0\n",
      "evaluation/env_infos/initial/is_success Std        0\n",
      "evaluation/env_infos/initial/is_success Max        0\n",
      "evaluation/env_infos/initial/is_success Min        0\n",
      "evaluation/env_infos/is_success Mean               0\n",
      "evaluation/env_infos/is_success Std                0\n",
      "evaluation/env_infos/is_success Max                0\n",
      "evaluation/env_infos/is_success Min                0\n",
      "time/data storing (s)                              1.13843\n",
      "time/evaluation sampling (s)                      21.9429\n",
      "time/exploration sampling (s)                    497.462\n",
      "time/logging (s)                                   0.0280249\n",
      "time/sac training (s)                            199.985\n",
      "time/saving (s)                                    0.0136801\n",
      "time/training (s)                                  0.0069355\n",
      "time/epoch (s)                                   720.577\n",
      "time/total (s)                                  1232.79\n",
      "Epoch                                              0\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 1\n",
      "\n",
      " Cycle 0 1\n",
      "Took to collect: 4.775563716888428\n",
      "Took to train: 6.272667169570923\n",
      "\n",
      " Cycle 1 1\n",
      "Took to collect: 4.644464015960693\n",
      "Took to train: 6.295388221740723\n",
      "\n",
      " Cycle 2 1\n",
      "Took to collect: 5.639275550842285\n",
      "Took to train: 6.222780704498291\n",
      "\n",
      " Cycle 3 1\n",
      "Took to collect: 4.847559928894043\n",
      "Took to train: 6.108832597732544\n",
      "\n",
      " Cycle 4 1\n",
      "Took to collect: 5.47687292098999\n",
      "Took to train: 6.1147449016571045\n",
      "\n",
      " Cycle 5 1\n",
      "Took to collect: 4.715291261672974\n",
      "Took to train: 6.139095783233643\n",
      "\n",
      " Cycle 6 1\n",
      "Took to collect: 4.661783218383789\n",
      "Took to train: 6.259212255477905\n",
      "\n",
      " Cycle 7 1\n",
      "Took to collect: 5.621600866317749\n",
      "Took to train: 6.2565929889678955\n",
      "\n",
      " Cycle 8 1\n",
      "Took to collect: 6.2028114795684814\n",
      "Took to train: 6.169804334640503\n",
      "\n",
      " Cycle 9 1\n",
      "Took to collect: 4.874420881271362\n",
      "Took to train: 6.131378173828125\n",
      "\n",
      " Cycle 10 1\n",
      "Took to collect: 5.355997800827026\n",
      "Took to train: 6.136413812637329\n",
      "\n",
      " Cycle 11 1\n",
      "Took to collect: 5.243175745010376\n",
      "Took to train: 6.172369480133057\n",
      "\n",
      " Cycle 12 1\n",
      "Took to collect: 4.34339714050293\n",
      "Took to train: 6.237039804458618\n",
      "\n",
      " Cycle 13 1\n",
      "Took to collect: 6.013426303863525\n",
      "Took to train: 6.1778724193573\n",
      "\n",
      " Cycle 14 1\n",
      "Took to collect: 5.02804970741272\n",
      "Took to train: 6.1681108474731445\n",
      "\n",
      " Cycle 15 1\n",
      "Took to collect: 5.370603561401367\n",
      "Took to train: 6.166366100311279\n",
      "\n",
      " Cycle 16 1\n",
      "Took to collect: 5.538629531860352\n",
      "Took to train: 6.171040058135986\n",
      "\n",
      " Cycle 17 1\n",
      "Took to collect: 5.497379302978516\n",
      "Took to train: 6.251246452331543\n",
      "\n",
      " Cycle 18 1\n",
      "Took to collect: 5.348467588424683\n",
      "Took to train: 6.166675090789795\n",
      "\n",
      " Cycle 19 1\n",
      "Took to collect: 6.18099570274353\n",
      "Took to train: 6.288347482681274\n",
      "\n",
      " Cycle 20 1\n",
      "Took to collect: 5.0148398876190186\n",
      "Took to train: 6.258987903594971\n",
      "\n",
      " Cycle 21 1\n",
      "Took to collect: 5.2535436153411865\n",
      "Took to train: 6.277467489242554\n",
      "\n",
      " Cycle 22 1\n",
      "Took to collect: 5.557596206665039\n",
      "Took to train: 6.265293836593628\n",
      "\n",
      " Cycle 23 1\n",
      "Took to collect: 5.90013861656189\n",
      "Took to train: 6.284185171127319\n",
      "\n",
      " Cycle 24 1\n",
      "Took to collect: 6.268467664718628\n",
      "Took to train: 6.278201580047607\n",
      "\n",
      " Cycle 25 1\n",
      "Took to collect: 6.709604024887085\n",
      "Took to train: 6.2835798263549805\n",
      "\n",
      " Cycle 26 1\n",
      "Took to collect: 6.171195030212402\n",
      "Took to train: 6.262126684188843\n",
      "\n",
      " Cycle 27 1\n",
      "Took to collect: 6.3712475299835205\n",
      "Took to train: 6.274155855178833\n",
      "\n",
      " Cycle 28 1\n",
      "Took to collect: 6.667365789413452\n",
      "Took to train: 6.23642373085022\n",
      "\n",
      " Cycle 29 1\n",
      "Took to collect: 7.018148422241211\n",
      "Took to train: 6.25115704536438\n",
      "\n",
      " Cycle 30 1\n",
      "Took to collect: 6.257866144180298\n",
      "Took to train: 6.266911745071411\n",
      "\n",
      " Cycle 31 1\n",
      "Took to collect: 5.911227226257324\n",
      "Took to train: 6.25944972038269\n",
      "\n",
      " Cycle 32 1\n",
      "Took to collect: 6.562130928039551\n",
      "Took to train: 6.272680759429932\n",
      "\n",
      " Cycle 33 1\n",
      "Took to collect: 6.259169101715088\n",
      "Took to train: 6.322708606719971\n",
      "\n",
      " Cycle 34 1\n",
      "Took to collect: 6.421265363693237\n",
      "Took to train: 6.26142692565918\n",
      "\n",
      " Cycle 35 1\n",
      "Took to collect: 5.722374677658081\n",
      "Took to train: 6.297701358795166\n",
      "\n",
      " Cycle 36 1\n",
      "Took to collect: 6.924056768417358\n",
      "Took to train: 6.267068386077881\n",
      "\n",
      " Cycle 37 1\n",
      "Took to collect: 6.744355201721191\n",
      "Took to train: 6.29764461517334\n",
      "\n",
      " Cycle 38 1\n",
      "Took to collect: 7.113651275634766\n",
      "Took to train: 6.2237420082092285\n",
      "\n",
      " Cycle 39 1\n",
      "Took to collect: 5.8831634521484375\n",
      "Took to train: 6.192627429962158\n",
      "\n",
      " Cycle 40 1\n",
      "Took to collect: 7.126528263092041\n",
      "Took to train: 6.200785398483276\n",
      "\n",
      " Cycle 41 1\n",
      "Took to collect: 5.885658025741577\n",
      "Took to train: 6.186593294143677\n",
      "\n",
      " Cycle 42 1\n",
      "Took to collect: 6.392175197601318\n",
      "Took to train: 6.199794769287109\n",
      "\n",
      " Cycle 43 1\n",
      "Took to collect: 6.684261083602905\n",
      "Took to train: 6.2550208568573\n",
      "\n",
      " Cycle 44 1\n",
      "Took to collect: 7.091246843338013\n",
      "Took to train: 6.234668254852295\n",
      "\n",
      " Cycle 45 1\n",
      "Took to collect: 7.061839818954468\n",
      "Took to train: 6.244946241378784\n",
      "\n",
      " Cycle 46 1\n",
      "Took to collect: 7.315490007400513\n",
      "Took to train: 6.242352247238159\n",
      "\n",
      " Cycle 47 1\n",
      "Took to collect: 6.089113712310791\n",
      "Took to train: 6.19657301902771\n",
      "\n",
      " Cycle 48 1\n",
      "Took to collect: 6.30763578414917\n",
      "Took to train: 6.24288535118103\n",
      "\n",
      " Cycle 49 1\n",
      "Took to collect: 6.674092531204224\n",
      "Took to train: 6.228211879730225\n",
      "\n",
      " Cycle 50 1\n",
      "Took to collect: 7.443779468536377\n",
      "Took to train: 6.144689321517944\n",
      "\n",
      " Cycle 51 1\n",
      "Took to collect: 7.30877947807312\n",
      "Took to train: 6.124208927154541\n",
      "\n",
      " Cycle 52 1\n",
      "Took to collect: 7.299248218536377\n",
      "Took to train: 6.072782278060913\n",
      "\n",
      " Cycle 53 1\n",
      "Took to collect: 7.623904466629028\n",
      "Took to train: 6.019678592681885\n",
      "\n",
      " Cycle 54 1\n",
      "Took to collect: 7.806321859359741\n",
      "Took to train: 6.073164463043213\n",
      "\n",
      " Cycle 55 1\n",
      "Took to collect: 7.009960651397705\n",
      "Took to train: 6.075135231018066\n",
      "\n",
      " Cycle 56 1\n",
      "Took to collect: 7.7335076332092285\n",
      "Took to train: 6.0713584423065186\n",
      "\n",
      " Cycle 57 1\n",
      "Took to collect: 8.067559719085693\n",
      "Took to train: 6.135887384414673\n",
      "\n",
      " Cycle 58 1\n",
      "Took to collect: 7.020654678344727\n",
      "Took to train: 6.103139877319336\n",
      "\n",
      " Cycle 59 1\n",
      "Took to collect: 6.369653701782227\n",
      "Took to train: 6.152116060256958\n",
      "\n",
      " Cycle 60 1\n",
      "Took to collect: 6.4229896068573\n",
      "Took to train: 6.1361610889434814\n",
      "\n",
      " Cycle 61 1\n",
      "Took to collect: 7.427165508270264\n",
      "Took to train: 6.212866306304932\n",
      "\n",
      " Cycle 62 1\n",
      "Took to collect: 7.110088586807251\n",
      "Took to train: 6.183363437652588\n",
      "\n",
      " Cycle 63 1\n",
      "Took to collect: 6.683392286300659\n",
      "Took to train: 6.208788156509399\n",
      "\n",
      " Cycle 64 1\n",
      "Took to collect: 6.3492584228515625\n",
      "Took to train: 6.181352615356445\n",
      "\n",
      " Cycle 65 1\n",
      "Took to collect: 8.171314716339111\n",
      "Took to train: 6.198151350021362\n",
      "\n",
      " Cycle 66 1\n",
      "Took to collect: 7.884664297103882\n",
      "Took to train: 6.204662561416626\n",
      "\n",
      " Cycle 67 1\n",
      "Took to collect: 6.188570499420166\n",
      "Took to train: 6.200429916381836\n",
      "\n",
      " Cycle 68 1\n",
      "Took to collect: 6.761155128479004\n",
      "Took to train: 6.061557292938232\n",
      "\n",
      " Cycle 69 1\n",
      "Took to collect: 7.757935285568237\n",
      "Took to train: 6.0468854904174805\n",
      "\n",
      " Cycle 70 1\n",
      "Took to collect: 6.344221591949463\n",
      "Took to train: 6.013527870178223\n",
      "\n",
      " Cycle 71 1\n",
      "Took to collect: 8.16571831703186\n",
      "Took to train: 6.2054994106292725\n",
      "\n",
      " Cycle 72 1\n",
      "Took to collect: 7.80467963218689\n",
      "Took to train: 6.19871187210083\n",
      "\n",
      " Cycle 73 1\n",
      "Took to collect: 7.457379102706909\n",
      "Took to train: 6.220989942550659\n",
      "\n",
      " Cycle 74 1\n",
      "Took to collect: 8.240762710571289\n",
      "Took to train: 6.231018543243408\n",
      "\n",
      " Cycle 75 1\n",
      "Took to collect: 6.3102240562438965\n",
      "Took to train: 6.221203565597534\n",
      "\n",
      " Cycle 76 1\n",
      "Took to collect: 7.817763328552246\n",
      "Took to train: 6.094904661178589\n",
      "\n",
      " Cycle 77 1\n",
      "Took to collect: 7.666451454162598\n",
      "Took to train: 6.0645458698272705\n",
      "\n",
      " Cycle 78 1\n",
      "Took to collect: 6.277310609817505\n",
      "Took to train: 6.016739130020142\n",
      "\n",
      " Cycle 79 1\n",
      "Took to collect: 6.026073455810547\n",
      "Took to train: 6.014386415481567\n",
      "\n",
      " Cycle 80 1\n",
      "Took to collect: 9.235165357589722\n",
      "Took to train: 6.216892719268799\n",
      "\n",
      " Cycle 81 1\n",
      "Took to collect: 8.936859607696533\n",
      "Took to train: 6.135354995727539\n",
      "\n",
      " Cycle 82 1\n",
      "Took to collect: 7.371712923049927\n",
      "Took to train: 6.161545276641846\n",
      "\n",
      " Cycle 83 1\n",
      "Took to collect: 7.104294300079346\n",
      "Took to train: 6.106679201126099\n",
      "\n",
      " Cycle 84 1\n",
      "Took to collect: 10.283482789993286\n",
      "Took to train: 6.069332122802734\n",
      "\n",
      " Cycle 85 1\n",
      "Took to collect: 8.154016494750977\n",
      "Took to train: 6.121962785720825\n",
      "\n",
      " Cycle 86 1\n",
      "Took to collect: 9.671262502670288\n",
      "Took to train: 6.20914888381958\n",
      "\n",
      " Cycle 87 1\n",
      "Took to collect: 7.866148471832275\n",
      "Took to train: 6.220310926437378\n",
      "\n",
      " Cycle 88 1\n",
      "Took to collect: 8.316729068756104\n",
      "Took to train: 6.1829001903533936\n",
      "\n",
      " Cycle 89 1\n",
      "Took to collect: 8.38149619102478\n",
      "Took to train: 6.272353887557983\n",
      "\n",
      " Cycle 90 1\n",
      "Took to collect: 11.823403596878052\n",
      "Took to train: 6.354755878448486\n",
      "\n",
      " Cycle 91 1\n",
      "Took to collect: 10.539492845535278\n",
      "Took to train: 6.459613084793091\n",
      "\n",
      " Cycle 92 1\n",
      "Took to collect: 9.412174463272095\n",
      "Took to train: 6.287609577178955\n",
      "\n",
      " Cycle 93 1\n",
      "Took to collect: 7.848123550415039\n",
      "Took to train: 6.2645885944366455\n",
      "\n",
      " Cycle 94 1\n",
      "Took to collect: 9.429508686065674\n",
      "Took to train: 6.217454195022583\n",
      "\n",
      " Cycle 95 1\n",
      "Took to collect: 7.351454257965088\n",
      "Took to train: 6.274386644363403\n",
      "\n",
      " Cycle 96 1\n",
      "Took to collect: 7.997612237930298\n",
      "Took to train: 6.352256774902344\n",
      "\n",
      " Cycle 97 1\n",
      "Took to collect: 7.823230504989624\n",
      "Took to train: 6.261284351348877\n",
      "\n",
      " Cycle 98 1\n",
      "Took to collect: 10.065008401870728\n",
      "Took to train: 6.504957675933838\n",
      "\n",
      " Cycle 99 1\n",
      "Took to collect: 8.571044921875\n",
      "Took to train: 6.333225250244141\n",
      "Time collect avg cycle: 6.894719240665435\n",
      "Time train avg cycle: 6.203658697605133\n",
      "Total avg cycle: 13.109445168972016\n",
      "Ending epoch\n",
      "2020-10-25 22:21:32.202389 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 1 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged tensorboard\n",
      "---------------------------------------------  --------------\n",
      "trainer/num train calls                            0\n",
      "trainer/QF1 Loss                                   0.124798\n",
      "trainer/QF2 Loss                                   0.100456\n",
      "trainer/Policy Loss                               11.5625\n",
      "trainer/Q1 Predictions Mean                      -11.7022\n",
      "trainer/Q1 Predictions Std                         2.91395\n",
      "trainer/Q1 Predictions Max                        -5.51159\n",
      "trainer/Q1 Predictions Min                       -17.3281\n",
      "trainer/Q2 Predictions Mean                      -11.6434\n",
      "trainer/Q2 Predictions Std                         2.9311\n",
      "trainer/Q2 Predictions Max                        -5.45575\n",
      "trainer/Q2 Predictions Min                       -17.3836\n",
      "trainer/Q Targets Mean                           -11.6135\n",
      "trainer/Q Targets Std                              2.95071\n",
      "trainer/Q Targets Max                             -5.03408\n",
      "trainer/Q Targets Min                            -17.3423\n",
      "trainer/Log Pis Mean                              -0.175117\n",
      "trainer/Log Pis Std                                1.68123\n",
      "trainer/Log Pis Max                                3.70159\n",
      "trainer/Log Pis Min                               -7.56011\n",
      "trainer/policy/mean Mean                          -0.113485\n",
      "trainer/policy/mean Std                            0.650926\n",
      "trainer/policy/mean Max                            0.958455\n",
      "trainer/policy/mean Min                           -0.922133\n",
      "trainer/policy/normal/std Mean                     0.600383\n",
      "trainer/policy/normal/std Std                      0.0747194\n",
      "trainer/policy/normal/std Max                      0.756951\n",
      "trainer/policy/normal/std Min                      0.363846\n",
      "trainer/policy/normal/log_std Mean                -0.518205\n",
      "trainer/policy/normal/log_std Std                  0.127971\n",
      "trainer/policy/normal/log_std Max                 -0.278457\n",
      "trainer/policy/normal/log_std Min                 -1.01102\n",
      "trainer/Alpha                                      0.0561666\n",
      "trainer/Alpha Loss                                -9.14254\n",
      "exploration/num steps total                    21000\n",
      "exploration/num paths total                      420\n",
      "exploration/path length Mean                      50\n",
      "exploration/path length Std                        0\n",
      "exploration/path length Max                       50\n",
      "exploration/path length Min                       50\n",
      "exploration/Rewards Mean                          -1\n",
      "exploration/Rewards Std                            0\n",
      "exploration/Rewards Max                           -1\n",
      "exploration/Rewards Min                           -1\n",
      "exploration/Returns Mean                         -50\n",
      "exploration/Returns Std                            0\n",
      "exploration/Returns Max                          -50\n",
      "exploration/Returns Min                          -50\n",
      "exploration/Actions Mean                          -0.402422\n",
      "exploration/Actions Std                            0.560749\n",
      "exploration/Actions Max                            0.999495\n",
      "exploration/Actions Min                           -0.999875\n",
      "exploration/Num Paths                            200\n",
      "exploration/Average Returns                      -50\n",
      "exploration/env_infos/final/is_success Mean        0\n",
      "exploration/env_infos/final/is_success Std         0\n",
      "exploration/env_infos/final/is_success Max         0\n",
      "exploration/env_infos/final/is_success Min         0\n",
      "exploration/env_infos/initial/is_success Mean      0\n",
      "exploration/env_infos/initial/is_success Std       0\n",
      "exploration/env_infos/initial/is_success Max       0\n",
      "exploration/env_infos/initial/is_success Min       0\n",
      "exploration/env_infos/is_success Mean              0\n",
      "exploration/env_infos/is_success Std               0\n",
      "exploration/env_infos/is_success Max               0\n",
      "exploration/env_infos/is_success Min               0\n",
      "evaluation/num steps total                      1000\n",
      "evaluation/num paths total                        20\n",
      "evaluation/path length Mean                       50\n",
      "evaluation/path length Std                         0\n",
      "evaluation/path length Max                        50\n",
      "evaluation/path length Min                        50\n",
      "evaluation/Rewards Mean                           -1\n",
      "evaluation/Rewards Std                             0\n",
      "evaluation/Rewards Max                            -1\n",
      "evaluation/Rewards Min                            -1\n",
      "evaluation/Returns Mean                          -50\n",
      "evaluation/Returns Std                             0\n",
      "evaluation/Returns Max                           -50\n",
      "evaluation/Returns Min                           -50\n",
      "evaluation/Actions Mean                           -0.529243\n",
      "evaluation/Actions Std                             0.138487\n",
      "evaluation/Actions Max                             0.124807\n",
      "evaluation/Actions Min                            -0.784228\n",
      "evaluation/Num Paths                              10\n",
      "evaluation/Average Returns                       -50\n",
      "evaluation/env_infos/final/is_success Mean         0\n",
      "evaluation/env_infos/final/is_success Std          0\n",
      "evaluation/env_infos/final/is_success Max          0\n",
      "evaluation/env_infos/final/is_success Min          0\n",
      "evaluation/env_infos/initial/is_success Mean       0\n",
      "evaluation/env_infos/initial/is_success Std        0\n",
      "evaluation/env_infos/initial/is_success Max        0\n",
      "evaluation/env_infos/initial/is_success Min        0\n",
      "evaluation/env_infos/is_success Mean               0\n",
      "evaluation/env_infos/is_success Std                0\n",
      "evaluation/env_infos/is_success Max                0\n",
      "evaluation/env_infos/is_success Min                0\n",
      "time/data storing (s)                              1.08097\n",
      "time/evaluation sampling (s)                      25.2688\n",
      "time/exploration sampling (s)                    689.491\n",
      "time/logging (s)                                   0.0280173\n",
      "time/sac training (s)                            199.292\n",
      "time/saving (s)                                    0.0142071\n",
      "time/training (s)                                  0.00684197\n",
      "time/epoch (s)                                   915.183\n",
      "time/total (s)                                  2568.87\n",
      "Epoch                                              1\n",
      "---------------------------------------------  --------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 2\n",
      "\n",
      " Cycle 0 2\n",
      "Took to collect: 7.2887818813323975\n",
      "Took to train: 6.447079658508301\n",
      "\n",
      " Cycle 1 2\n",
      "Took to collect: 8.998056173324585\n",
      "Took to train: 6.462445259094238\n",
      "\n",
      " Cycle 2 2\n",
      "Took to collect: 7.681485891342163\n",
      "Took to train: 6.4537200927734375\n",
      "\n",
      " Cycle 3 2\n",
      "Took to collect: 8.009595394134521\n",
      "Took to train: 6.2935967445373535\n",
      "\n",
      " Cycle 4 2\n",
      "Took to collect: 6.8438732624053955\n",
      "Took to train: 6.245766878128052\n",
      "\n",
      " Cycle 5 2\n",
      "Took to collect: 8.781784296035767\n",
      "Took to train: 6.242340087890625\n",
      "\n",
      " Cycle 6 2\n",
      "Took to collect: 7.683398246765137\n",
      "Took to train: 6.350413084030151\n",
      "\n",
      " Cycle 7 2\n",
      "Took to collect: 11.245399951934814\n",
      "Took to train: 6.3608927726745605\n",
      "\n",
      " Cycle 8 2\n",
      "Took to collect: 8.18600583076477\n",
      "Took to train: 6.351543426513672\n",
      "\n",
      " Cycle 9 2\n",
      "Took to collect: 7.952089548110962\n",
      "Took to train: 6.367229223251343\n",
      "\n",
      " Cycle 10 2\n",
      "Took to collect: 7.097392559051514\n",
      "Took to train: 6.3756303787231445\n",
      "\n",
      " Cycle 11 2\n",
      "Took to collect: 7.828914403915405\n",
      "Took to train: 6.374082565307617\n",
      "\n",
      " Cycle 12 2\n",
      "Took to collect: 9.438469886779785\n",
      "Took to train: 6.342301607131958\n",
      "\n",
      " Cycle 13 2\n",
      "Took to collect: 8.15899658203125\n",
      "Took to train: 6.292752742767334\n",
      "\n",
      " Cycle 14 2\n",
      "Took to collect: 8.01793646812439\n",
      "Took to train: 6.2466347217559814\n",
      "\n",
      " Cycle 15 2\n",
      "Took to collect: 7.608701229095459\n",
      "Took to train: 6.450324535369873\n",
      "\n",
      " Cycle 16 2\n",
      "Took to collect: 7.4644811153411865\n",
      "Took to train: 6.263438940048218\n",
      "\n",
      " Cycle 17 2\n",
      "Took to collect: 7.109252691268921\n",
      "Took to train: 6.404165267944336\n",
      "\n",
      " Cycle 18 2\n",
      "Took to collect: 7.716931581497192\n",
      "Took to train: 6.428822755813599\n",
      "\n",
      " Cycle 19 2\n",
      "Took to collect: 8.018875122070312\n",
      "Took to train: 6.325901985168457\n",
      "\n",
      " Cycle 20 2\n",
      "Took to collect: 8.824372291564941\n",
      "Took to train: 6.412130355834961\n",
      "\n",
      " Cycle 21 2\n",
      "Took to collect: 8.19539737701416\n",
      "Took to train: 6.39024806022644\n",
      "\n",
      " Cycle 22 2\n",
      "Took to collect: 7.7418670654296875\n",
      "Took to train: 6.417881011962891\n",
      "\n",
      " Cycle 23 2\n",
      "Took to collect: 7.229365825653076\n",
      "Took to train: 6.282500267028809\n",
      "\n",
      " Cycle 24 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 7.311795711517334\n",
      "Took to train: 6.2544355392456055\n",
      "\n",
      " Cycle 25 2\n",
      "Took to collect: 7.388352155685425\n",
      "Took to train: 6.366231918334961\n",
      "\n",
      " Cycle 26 2\n",
      "Took to collect: 6.383652210235596\n",
      "Took to train: 6.393250226974487\n",
      "\n",
      " Cycle 27 2\n",
      "Took to collect: 8.155610799789429\n",
      "Took to train: 6.382534503936768\n",
      "\n",
      " Cycle 28 2\n",
      "Took to collect: 7.792537212371826\n",
      "Took to train: 6.3983213901519775\n",
      "\n",
      " Cycle 29 2\n",
      "Took to collect: 7.578919887542725\n",
      "Took to train: 6.462629079818726\n",
      "\n",
      " Cycle 30 2\n",
      "Took to collect: 7.424855709075928\n",
      "Took to train: 6.460638761520386\n",
      "\n",
      " Cycle 31 2\n",
      "Took to collect: 8.193749189376831\n",
      "Took to train: 6.400171518325806\n",
      "\n",
      " Cycle 32 2\n",
      "Took to collect: 7.297546625137329\n",
      "Took to train: 6.3679282665252686\n",
      "\n",
      " Cycle 33 2\n",
      "Took to collect: 6.59264612197876\n",
      "Took to train: 6.39761757850647\n",
      "\n",
      " Cycle 34 2\n",
      "Took to collect: 7.431231498718262\n",
      "Took to train: 6.428794622421265\n",
      "\n",
      " Cycle 35 2\n",
      "Took to collect: 8.847899913787842\n",
      "Took to train: 6.412635326385498\n",
      "\n",
      " Cycle 36 2\n",
      "Took to collect: 6.353816986083984\n",
      "Took to train: 6.259913682937622\n",
      "\n",
      " Cycle 37 2\n",
      "Took to collect: 8.259444952011108\n",
      "Took to train: 6.349552392959595\n",
      "\n",
      " Cycle 38 2\n",
      "Took to collect: 7.352632284164429\n",
      "Took to train: 6.368481397628784\n",
      "\n",
      " Cycle 39 2\n",
      "Took to collect: 9.639080047607422\n",
      "Took to train: 6.456319808959961\n",
      "\n",
      " Cycle 40 2\n",
      "Took to collect: 9.41268515586853\n",
      "Took to train: 6.424348592758179\n",
      "\n",
      " Cycle 41 2\n",
      "Took to collect: 8.834399700164795\n",
      "Took to train: 6.392066955566406\n",
      "\n",
      " Cycle 42 2\n",
      "Took to collect: 10.162764549255371\n",
      "Took to train: 6.390915870666504\n",
      "\n",
      " Cycle 43 2\n",
      "Took to collect: 8.750602960586548\n",
      "Took to train: 6.391582727432251\n",
      "\n",
      " Cycle 44 2\n",
      "Took to collect: 7.904271125793457\n",
      "Took to train: 6.442305326461792\n",
      "\n",
      " Cycle 45 2\n",
      "Took to collect: 9.206295490264893\n",
      "Took to train: 6.40814995765686\n",
      "\n",
      " Cycle 46 2\n",
      "Took to collect: 10.251550912857056\n",
      "Took to train: 6.291089057922363\n",
      "\n",
      " Cycle 47 2\n",
      "Took to collect: 7.088399887084961\n",
      "Took to train: 6.241328477859497\n",
      "\n",
      " Cycle 48 2\n",
      "Took to collect: 7.277716159820557\n",
      "Took to train: 6.261274814605713\n",
      "\n",
      " Cycle 49 2\n",
      "Took to collect: 7.577998161315918\n",
      "Took to train: 6.26528787612915\n",
      "\n",
      " Cycle 50 2\n",
      "Took to collect: 7.395328760147095\n",
      "Took to train: 6.376768589019775\n",
      "\n",
      " Cycle 51 2\n",
      "Took to collect: 7.087375640869141\n",
      "Took to train: 6.435588121414185\n",
      "\n",
      " Cycle 52 2\n",
      "Took to collect: 7.8543055057525635\n",
      "Took to train: 6.4234700202941895\n",
      "\n",
      " Cycle 53 2\n",
      "Took to collect: 7.273439884185791\n",
      "Took to train: 6.404580593109131\n",
      "\n",
      " Cycle 54 2\n",
      "Took to collect: 7.881852626800537\n",
      "Took to train: 6.449639320373535\n",
      "\n",
      " Cycle 55 2\n",
      "Took to collect: 7.848927021026611\n",
      "Took to train: 6.412760496139526\n",
      "\n",
      " Cycle 56 2\n",
      "Took to collect: 7.214181661605835\n",
      "Took to train: 6.409571647644043\n",
      "\n",
      " Cycle 57 2\n",
      "Took to collect: 7.405313968658447\n",
      "Took to train: 6.429601430892944\n",
      "\n",
      " Cycle 58 2\n",
      "Took to collect: 7.748652458190918\n",
      "Took to train: 6.390204906463623\n",
      "\n",
      " Cycle 59 2\n",
      "Took to collect: 8.487640619277954\n",
      "Took to train: 6.363391399383545\n",
      "\n",
      " Cycle 60 2\n",
      "Took to collect: 7.800084829330444\n",
      "Took to train: 6.369358777999878\n",
      "\n",
      " Cycle 61 2\n",
      "Took to collect: 7.190864086151123\n",
      "Took to train: 6.358530521392822\n",
      "\n",
      " Cycle 62 2\n",
      "Took to collect: 7.338046312332153\n",
      "Took to train: 6.432912349700928\n",
      "\n",
      " Cycle 63 2\n",
      "Took to collect: 7.44363808631897\n",
      "Took to train: 6.454578876495361\n",
      "\n",
      " Cycle 64 2\n",
      "Took to collect: 7.925287485122681\n",
      "Took to train: 6.2946624755859375\n",
      "\n",
      " Cycle 65 2\n",
      "Took to collect: 8.979982376098633\n",
      "Took to train: 6.396714687347412\n",
      "\n",
      " Cycle 66 2\n",
      "Took to collect: 7.364437818527222\n",
      "Took to train: 6.426310300827026\n",
      "\n",
      " Cycle 67 2\n",
      "Took to collect: 8.170418500900269\n",
      "Took to train: 6.400782108306885\n",
      "\n",
      " Cycle 68 2\n",
      "Took to collect: 7.975404739379883\n",
      "Took to train: 6.365391492843628\n",
      "\n",
      " Cycle 69 2\n",
      "Took to collect: 7.356414556503296\n",
      "Took to train: 6.421285152435303\n",
      "\n",
      " Cycle 70 2\n",
      "Took to collect: 8.252639770507812\n",
      "Took to train: 6.386637449264526\n",
      "\n",
      " Cycle 71 2\n",
      "Took to collect: 8.541662216186523\n",
      "Took to train: 6.440093994140625\n",
      "\n",
      " Cycle 72 2\n",
      "Took to collect: 8.206001996994019\n",
      "Took to train: 6.424225330352783\n",
      "\n",
      " Cycle 73 2\n",
      "Took to collect: 7.699647903442383\n",
      "Took to train: 6.42280125617981\n",
      "\n",
      " Cycle 74 2\n",
      "Took to collect: 7.902118921279907\n",
      "Took to train: 6.391447305679321\n",
      "\n",
      " Cycle 75 2\n",
      "Took to collect: 7.998539209365845\n",
      "Took to train: 6.361911058425903\n",
      "\n",
      " Cycle 76 2\n",
      "Took to collect: 7.477217197418213\n",
      "Took to train: 6.4864466190338135\n",
      "\n",
      " Cycle 77 2\n",
      "Took to collect: 8.09187912940979\n",
      "Took to train: 6.317187786102295\n",
      "\n",
      " Cycle 78 2\n",
      "Took to collect: 7.917186975479126\n",
      "Took to train: 6.473861217498779\n",
      "\n",
      " Cycle 79 2\n",
      "Took to collect: 8.162178754806519\n",
      "Took to train: 6.434286594390869\n",
      "\n",
      " Cycle 80 2\n",
      "Took to collect: 7.056930303573608\n",
      "Took to train: 6.359600305557251\n",
      "\n",
      " Cycle 81 2\n",
      "Took to collect: 7.784149885177612\n",
      "Took to train: 6.342263460159302\n",
      "\n",
      " Cycle 82 2\n",
      "Took to collect: 7.86267876625061\n",
      "Took to train: 6.241594552993774\n",
      "\n",
      " Cycle 83 2\n",
      "Took to collect: 8.525558948516846\n",
      "Took to train: 6.4265570640563965\n",
      "\n",
      " Cycle 84 2\n",
      "Took to collect: 8.317780017852783\n",
      "Took to train: 6.29151177406311\n",
      "\n",
      " Cycle 85 2\n",
      "Took to collect: 8.58341932296753\n",
      "Took to train: 6.248221397399902\n",
      "\n",
      " Cycle 86 2\n",
      "Took to collect: 8.85698127746582\n",
      "Took to train: 6.262537956237793\n",
      "\n",
      " Cycle 87 2\n",
      "Took to collect: 8.272854804992676\n",
      "Took to train: 6.348792314529419\n",
      "\n",
      " Cycle 88 2\n",
      "Took to collect: 6.904688119888306\n",
      "Took to train: 6.23832368850708\n",
      "\n",
      " Cycle 89 2\n",
      "Took to collect: 4.96689248085022\n",
      "Took to train: 6.220518350601196\n",
      "\n",
      " Cycle 90 2\n",
      "Took to collect: 7.754598617553711\n",
      "Took to train: 6.2180070877075195\n",
      "\n",
      " Cycle 91 2\n",
      "Took to collect: 6.6241395473480225\n",
      "Took to train: 6.342966794967651\n",
      "\n",
      " Cycle 92 2\n",
      "Took to collect: 4.2931365966796875\n",
      "Took to train: 6.336740493774414\n",
      "\n",
      " Cycle 93 2\n",
      "Took to collect: 6.993608236312866\n",
      "Took to train: 6.270902156829834\n",
      "\n",
      " Cycle 94 2\n",
      "Took to collect: 8.076678037643433\n",
      "Took to train: 6.488157033920288\n",
      "\n",
      " Cycle 95 2\n",
      "Took to collect: 7.678782939910889\n",
      "Took to train: 6.443046808242798\n",
      "\n",
      " Cycle 96 2\n",
      "Took to collect: 7.909694194793701\n",
      "Took to train: 6.4117591381073\n",
      "\n",
      " Cycle 97 2\n",
      "Took to collect: 8.294812679290771\n",
      "Took to train: 6.316061019897461\n",
      "\n",
      " Cycle 98 2\n",
      "Took to collect: 7.314226388931274\n",
      "Took to train: 6.302264213562012\n",
      "\n",
      " Cycle 99 2\n",
      "Took to collect: 7.52176833152771\n",
      "Took to train: 6.436664342880249\n",
      "Time collect avg cycle: 7.851759285926819\n",
      "Time train avg cycle: 6.369511399269104\n",
      "Total avg cycle: 14.232182376384735\n",
      "Ending epoch\n",
      "2020-10-25 22:45:56.192132 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 2 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  --------------\n",
      "trainer/num train calls                            0\n",
      "trainer/QF1 Loss                                   0.179165\n",
      "trainer/QF2 Loss                                   0.166625\n",
      "trainer/Policy Loss                               27.009\n",
      "trainer/Q1 Predictions Mean                      -27.17\n",
      "trainer/Q1 Predictions Std                        10.6872\n",
      "trainer/Q1 Predictions Max                        -5.41869\n",
      "trainer/Q1 Predictions Min                       -44.0121\n",
      "trainer/Q2 Predictions Mean                      -27.2017\n",
      "trainer/Q2 Predictions Std                        10.6853\n",
      "trainer/Q2 Predictions Max                        -5.63256\n",
      "trainer/Q2 Predictions Min                       -43.9703\n",
      "trainer/Q Targets Mean                           -27.265\n",
      "trainer/Q Targets Std                             10.6987\n",
      "trainer/Q Targets Max                             -5.32688\n",
      "trainer/Q Targets Min                            -43.8946\n",
      "trainer/Log Pis Mean                               3.04396\n",
      "trainer/Log Pis Std                                2.14598\n",
      "trainer/Log Pis Max                                9.50894\n",
      "trainer/Log Pis Min                               -3.30825\n",
      "trainer/policy/mean Mean                          -0.243995\n",
      "trainer/policy/mean Std                            0.706159\n",
      "trainer/policy/mean Max                            0.99332\n",
      "trainer/policy/mean Min                           -0.991755\n",
      "trainer/policy/normal/std Mean                     0.391615\n",
      "trainer/policy/normal/std Std                      0.175825\n",
      "trainer/policy/normal/std Max                      0.84712\n",
      "trainer/policy/normal/std Min                      0.116875\n",
      "trainer/policy/normal/log_std Mean                -1.05336\n",
      "trainer/policy/normal/log_std Std                  0.501531\n",
      "trainer/policy/normal/log_std Max                 -0.165913\n",
      "trainer/policy/normal/log_std Min                 -2.14665\n",
      "trainer/Alpha                                      0.0153202\n",
      "trainer/Alpha Loss                                 0.183684\n",
      "exploration/num steps total                    31000\n",
      "exploration/num paths total                      620\n",
      "exploration/path length Mean                      50\n",
      "exploration/path length Std                        0\n",
      "exploration/path length Max                       50\n",
      "exploration/path length Min                       50\n",
      "exploration/Rewards Mean                          -1\n",
      "exploration/Rewards Std                            0\n",
      "exploration/Rewards Max                           -1\n",
      "exploration/Rewards Min                           -1\n",
      "exploration/Returns Mean                         -50\n",
      "exploration/Returns Std                            0\n",
      "exploration/Returns Max                          -50\n",
      "exploration/Returns Min                          -50\n",
      "exploration/Actions Mean                          -0.614161\n",
      "exploration/Actions Std                            0.562939\n",
      "exploration/Actions Max                            0.999625\n",
      "exploration/Actions Min                           -0.999537\n",
      "exploration/Num Paths                            200\n",
      "exploration/Average Returns                      -50\n",
      "exploration/env_infos/final/is_success Mean        0\n",
      "exploration/env_infos/final/is_success Std         0\n",
      "exploration/env_infos/final/is_success Max         0\n",
      "exploration/env_infos/final/is_success Min         0\n",
      "exploration/env_infos/initial/is_success Mean      0\n",
      "exploration/env_infos/initial/is_success Std       0\n",
      "exploration/env_infos/initial/is_success Max       0\n",
      "exploration/env_infos/initial/is_success Min       0\n",
      "exploration/env_infos/is_success Mean              0\n",
      "exploration/env_infos/is_success Std               0\n",
      "exploration/env_infos/is_success Max               0\n",
      "exploration/env_infos/is_success Min               0\n",
      "evaluation/num steps total                      1500\n",
      "evaluation/num paths total                        30\n",
      "evaluation/path length Mean                       50\n",
      "evaluation/path length Std                         0\n",
      "evaluation/path length Max                        50\n",
      "evaluation/path length Min                        50\n",
      "evaluation/Rewards Mean                           -1\n",
      "evaluation/Rewards Std                             0\n",
      "evaluation/Rewards Max                            -1\n",
      "evaluation/Rewards Min                            -1\n",
      "evaluation/Returns Mean                          -50\n",
      "evaluation/Returns Std                             0\n",
      "evaluation/Returns Max                           -50\n",
      "evaluation/Returns Min                           -50\n",
      "evaluation/Actions Mean                           -0.634065\n",
      "evaluation/Actions Std                             0.495048\n",
      "evaluation/Actions Max                             0.981441\n",
      "evaluation/Actions Min                            -0.986598\n",
      "evaluation/Num Paths                              10\n",
      "evaluation/Average Returns                       -50\n",
      "evaluation/env_infos/final/is_success Mean         0\n",
      "evaluation/env_infos/final/is_success Std          0\n",
      "evaluation/env_infos/final/is_success Max          0\n",
      "evaluation/env_infos/final/is_success Min          0\n",
      "evaluation/env_infos/initial/is_success Mean       0\n",
      "evaluation/env_infos/initial/is_success Std        0\n",
      "evaluation/env_infos/initial/is_success Max        0\n",
      "evaluation/env_infos/initial/is_success Min        0\n",
      "evaluation/env_infos/is_success Mean               0\n",
      "evaluation/env_infos/is_success Std                0\n",
      "evaluation/env_infos/is_success Max                0\n",
      "evaluation/env_infos/is_success Min                0\n",
      "time/data storing (s)                              1.06599\n",
      "time/evaluation sampling (s)                      40.7108\n",
      "time/exploration sampling (s)                    785.195\n",
      "time/logging (s)                                   0.0277116\n",
      "time/sac training (s)                            198.789\n",
      "time/saving (s)                                    0.0138981\n",
      "time/training (s)                                  0.00675411\n",
      "time/epoch (s)                                  1025.81\n",
      "time/total (s)                                  4032.67\n",
      "Epoch                                              2\n",
      "---------------------------------------------  --------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 3\n",
      "\n",
      " Cycle 0 3\n",
      "Took to collect: 6.8816375732421875\n",
      "Took to train: 6.391027212142944\n",
      "\n",
      " Cycle 1 3\n",
      "Took to collect: 7.578719139099121\n",
      "Took to train: 6.388027191162109\n",
      "\n",
      " Cycle 2 3\n",
      "Took to collect: 6.270808696746826\n",
      "Took to train: 6.4067702293396\n",
      "\n",
      " Cycle 3 3\n",
      "Took to collect: 8.26673674583435\n",
      "Took to train: 6.372979402542114\n",
      "\n",
      " Cycle 4 3\n",
      "Took to collect: 7.751536846160889\n",
      "Took to train: 6.396013975143433\n",
      "\n",
      " Cycle 5 3\n",
      "Took to collect: 5.857409715652466\n",
      "Took to train: 6.393409252166748\n",
      "\n",
      " Cycle 6 3\n",
      "Took to collect: 6.714452743530273\n",
      "Took to train: 6.396484375\n",
      "\n",
      " Cycle 7 3\n",
      "Took to collect: 6.093170642852783\n",
      "Took to train: 6.297417402267456\n",
      "\n",
      " Cycle 8 3\n",
      "Took to collect: 6.878756523132324\n",
      "Took to train: 6.2717156410217285\n",
      "\n",
      " Cycle 9 3\n",
      "Took to collect: 4.975650787353516\n",
      "Took to train: 6.407140731811523\n",
      "\n",
      " Cycle 10 3\n",
      "Took to collect: 4.633472204208374\n",
      "Took to train: 6.4572718143463135\n",
      "\n",
      " Cycle 11 3\n",
      "Took to collect: 4.594238042831421\n",
      "Took to train: 6.4178466796875\n",
      "\n",
      " Cycle 12 3\n",
      "Took to collect: 6.721173524856567\n",
      "Took to train: 6.4371337890625\n",
      "\n",
      " Cycle 13 3\n",
      "Took to collect: 4.107687711715698\n",
      "Took to train: 6.430782794952393\n",
      "\n",
      " Cycle 14 3\n",
      "Took to collect: 5.245650291442871\n",
      "Took to train: 6.29846715927124\n",
      "\n",
      " Cycle 15 3\n",
      "Took to collect: 4.835118770599365\n",
      "Took to train: 6.46007776260376\n",
      "\n",
      " Cycle 16 3\n",
      "Took to collect: 4.372642517089844\n",
      "Took to train: 6.4726402759552\n",
      "\n",
      " Cycle 17 3\n",
      "Took to collect: 4.317566633224487\n",
      "Took to train: 6.4286932945251465\n",
      "\n",
      " Cycle 18 3\n",
      "Took to collect: 4.17228364944458\n",
      "Took to train: 6.394667863845825\n",
      "\n",
      " Cycle 19 3\n",
      "Took to collect: 4.237605333328247\n",
      "Took to train: 6.437693357467651\n",
      "\n",
      " Cycle 20 3\n",
      "Took to collect: 4.699151277542114\n",
      "Took to train: 6.422064304351807\n",
      "\n",
      " Cycle 21 3\n",
      "Took to collect: 4.1449408531188965\n",
      "Took to train: 6.400805473327637\n",
      "\n",
      " Cycle 22 3\n",
      "Took to collect: 4.222630500793457\n",
      "Took to train: 6.442805767059326\n",
      "\n",
      " Cycle 23 3\n",
      "Took to collect: 4.235684394836426\n",
      "Took to train: 6.390420198440552\n",
      "\n",
      " Cycle 24 3\n",
      "Took to collect: 5.42563796043396\n",
      "Took to train: 6.391921043395996\n",
      "\n",
      " Cycle 25 3\n",
      "Took to collect: 4.145067930221558\n",
      "Took to train: 6.377633333206177\n",
      "\n",
      " Cycle 26 3\n",
      "Took to collect: 4.210954427719116\n",
      "Took to train: 6.364994525909424\n",
      "\n",
      " Cycle 27 3\n",
      "Took to collect: 4.171623706817627\n",
      "Took to train: 6.361844301223755\n",
      "\n",
      " Cycle 28 3\n",
      "Took to collect: 4.718162775039673\n",
      "Took to train: 6.3771703243255615\n",
      "\n",
      " Cycle 29 3\n",
      "Took to collect: 4.001266241073608\n",
      "Took to train: 6.4108641147613525\n",
      "\n",
      " Cycle 30 3\n",
      "Took to collect: 4.3701512813568115\n",
      "Took to train: 6.455243110656738\n",
      "\n",
      " Cycle 31 3\n",
      "Took to collect: 3.9353079795837402\n",
      "Took to train: 6.432245254516602\n",
      "\n",
      " Cycle 32 3\n",
      "Took to collect: 4.5165181159973145\n",
      "Took to train: 6.329152822494507\n",
      "\n",
      " Cycle 33 3\n",
      "Took to collect: 4.293993711471558\n",
      "Took to train: 6.379671096801758\n",
      "\n",
      " Cycle 34 3\n",
      "Took to collect: 4.6889708042144775\n",
      "Took to train: 6.44112229347229\n",
      "\n",
      " Cycle 35 3\n",
      "Took to collect: 4.41919469833374\n",
      "Took to train: 6.379877805709839\n",
      "\n",
      " Cycle 36 3\n",
      "Took to collect: 4.26284646987915\n",
      "Took to train: 6.390478849411011\n",
      "\n",
      " Cycle 37 3\n",
      "Took to collect: 4.422396659851074\n",
      "Took to train: 6.37993049621582\n",
      "\n",
      " Cycle 38 3\n",
      "Took to collect: 4.338027000427246\n",
      "Took to train: 6.36713433265686\n",
      "\n",
      " Cycle 39 3\n",
      "Took to collect: 4.567992448806763\n",
      "Took to train: 6.389732837677002\n",
      "\n",
      " Cycle 40 3\n",
      "Took to collect: 4.328061819076538\n",
      "Took to train: 6.418044090270996\n",
      "\n",
      " Cycle 41 3\n",
      "Took to collect: 4.4488115310668945\n",
      "Took to train: 6.435455083847046\n",
      "\n",
      " Cycle 42 3\n",
      "Took to collect: 5.6343042850494385\n",
      "Took to train: 6.369914293289185\n",
      "\n",
      " Cycle 43 3\n",
      "Took to collect: 4.225295305252075\n",
      "Took to train: 6.337012767791748\n",
      "\n",
      " Cycle 44 3\n",
      "Took to collect: 4.7198004722595215\n",
      "Took to train: 6.244161367416382\n",
      "\n",
      " Cycle 45 3\n",
      "Took to collect: 4.735548257827759\n",
      "Took to train: 6.319768190383911\n",
      "\n",
      " Cycle 46 3\n",
      "Took to collect: 4.169849634170532\n",
      "Took to train: 6.391512393951416\n",
      "\n",
      " Cycle 47 3\n",
      "Took to collect: 4.214443206787109\n",
      "Took to train: 6.397605895996094\n",
      "\n",
      " Cycle 48 3\n",
      "Took to collect: 4.530869483947754\n",
      "Took to train: 6.470186471939087\n",
      "\n",
      " Cycle 49 3\n",
      "Took to collect: 4.323119401931763\n",
      "Took to train: 6.4340431690216064\n",
      "\n",
      " Cycle 50 3\n",
      "Took to collect: 4.656017065048218\n",
      "Took to train: 6.331752777099609\n",
      "\n",
      " Cycle 51 3\n",
      "Took to collect: 4.489161491394043\n",
      "Took to train: 6.356048583984375\n",
      "\n",
      " Cycle 52 3\n",
      "Took to collect: 4.767641544342041\n",
      "Took to train: 6.3042380809783936\n",
      "\n",
      " Cycle 53 3\n",
      "Took to collect: 4.839544057846069\n",
      "Took to train: 6.438033580780029\n",
      "\n",
      " Cycle 54 3\n",
      "Took to collect: 5.77838921546936\n",
      "Took to train: 6.381347417831421\n",
      "\n",
      " Cycle 55 3\n",
      "Took to collect: 4.789287328720093\n",
      "Took to train: 6.389739513397217\n",
      "\n",
      " Cycle 56 3\n",
      "Took to collect: 5.0835347175598145\n",
      "Took to train: 6.364645481109619\n",
      "\n",
      " Cycle 57 3\n",
      "Took to collect: 3.902904987335205\n",
      "Took to train: 6.465356111526489\n",
      "\n",
      " Cycle 58 3\n",
      "Took to collect: 4.671441555023193\n",
      "Took to train: 6.376479148864746\n",
      "\n",
      " Cycle 59 3\n",
      "Took to collect: 5.389667510986328\n",
      "Took to train: 6.378983736038208\n",
      "\n",
      " Cycle 60 3\n",
      "Took to collect: 4.369171380996704\n",
      "Took to train: 6.48722505569458\n",
      "\n",
      " Cycle 61 3\n",
      "Took to collect: 5.005743980407715\n",
      "Took to train: 6.376112222671509\n",
      "\n",
      " Cycle 62 3\n",
      "Took to collect: 4.530462980270386\n",
      "Took to train: 6.364926338195801\n",
      "\n",
      " Cycle 63 3\n",
      "Took to collect: 4.740819931030273\n",
      "Took to train: 6.366025924682617\n",
      "\n",
      " Cycle 64 3\n",
      "Took to collect: 4.549484014511108\n",
      "Took to train: 6.310757875442505\n",
      "\n",
      " Cycle 65 3\n",
      "Took to collect: 4.370160818099976\n",
      "Took to train: 6.361076354980469\n",
      "\n",
      " Cycle 66 3\n",
      "Took to collect: 6.338231801986694\n",
      "Took to train: 6.3877809047698975\n",
      "\n",
      " Cycle 67 3\n",
      "Took to collect: 4.781279802322388\n",
      "Took to train: 6.489247798919678\n",
      "\n",
      " Cycle 68 3\n",
      "Took to collect: 4.313371896743774\n",
      "Took to train: 6.379270076751709\n",
      "\n",
      " Cycle 69 3\n",
      "Took to collect: 4.851131916046143\n",
      "Took to train: 6.469181299209595\n",
      "\n",
      " Cycle 70 3\n",
      "Took to collect: 5.613354921340942\n",
      "Took to train: 6.403833389282227\n",
      "\n",
      " Cycle 71 3\n",
      "Took to collect: 5.141896724700928\n",
      "Took to train: 6.433204650878906\n",
      "\n",
      " Cycle 72 3\n",
      "Took to collect: 5.3956458568573\n",
      "Took to train: 6.442572832107544\n",
      "\n",
      " Cycle 73 3\n",
      "Took to collect: 5.384479761123657\n",
      "Took to train: 6.448553562164307\n",
      "\n",
      " Cycle 74 3\n",
      "Took to collect: 6.561356067657471\n",
      "Took to train: 6.447898626327515\n",
      "\n",
      " Cycle 75 3\n",
      "Took to collect: 6.059859752655029\n",
      "Took to train: 6.3969502449035645\n",
      "\n",
      " Cycle 76 3\n",
      "Took to collect: 5.216936111450195\n",
      "Took to train: 6.456900119781494\n",
      "\n",
      " Cycle 77 3\n",
      "Took to collect: 4.958886623382568\n",
      "Took to train: 6.4115166664123535\n",
      "\n",
      " Cycle 78 3\n",
      "Took to collect: 4.925984144210815\n",
      "Took to train: 6.44047212600708\n",
      "\n",
      " Cycle 79 3\n",
      "Took to collect: 5.348337888717651\n",
      "Took to train: 6.338740587234497\n",
      "\n",
      " Cycle 80 3\n",
      "Took to collect: 5.8841469287872314\n",
      "Took to train: 6.418449878692627\n",
      "\n",
      " Cycle 81 3\n",
      "Took to collect: 4.689993619918823\n",
      "Took to train: 6.450978755950928\n",
      "\n",
      " Cycle 82 3\n",
      "Took to collect: 6.199646949768066\n",
      "Took to train: 6.413470506668091\n",
      "\n",
      " Cycle 83 3\n",
      "Took to collect: 6.530519723892212\n",
      "Took to train: 6.398352146148682\n",
      "\n",
      " Cycle 84 3\n",
      "Took to collect: 5.958218574523926\n",
      "Took to train: 6.39389181137085\n",
      "\n",
      " Cycle 85 3\n",
      "Took to collect: 6.02002215385437\n",
      "Took to train: 6.395704746246338\n",
      "\n",
      " Cycle 86 3\n",
      "Took to collect: 7.071946859359741\n",
      "Took to train: 6.234063148498535\n",
      "\n",
      " Cycle 87 3\n",
      "Took to collect: 6.005856513977051\n",
      "Took to train: 6.349161148071289\n",
      "\n",
      " Cycle 88 3\n",
      "Took to collect: 5.389683485031128\n",
      "Took to train: 6.484673023223877\n",
      "\n",
      " Cycle 89 3\n",
      "Took to collect: 5.058983325958252\n",
      "Took to train: 6.448972225189209\n",
      "\n",
      " Cycle 90 3\n",
      "Took to collect: 6.5398595333099365\n",
      "Took to train: 6.471550703048706\n",
      "\n",
      " Cycle 91 3\n",
      "Took to collect: 5.349474906921387\n",
      "Took to train: 6.468072175979614\n",
      "\n",
      " Cycle 92 3\n",
      "Took to collect: 5.881649017333984\n",
      "Took to train: 6.488288164138794\n",
      "\n",
      " Cycle 93 3\n",
      "Took to collect: 6.445975065231323\n",
      "Took to train: 6.444112062454224\n",
      "\n",
      " Cycle 94 3\n",
      "Took to collect: 6.029491662979126\n",
      "Took to train: 6.472571134567261\n",
      "\n",
      " Cycle 95 3\n",
      "Took to collect: 5.220736026763916\n",
      "Took to train: 6.462373733520508\n",
      "\n",
      " Cycle 96 3\n",
      "Took to collect: 6.123420000076294\n",
      "Took to train: 6.4453041553497314\n",
      "\n",
      " Cycle 97 3\n",
      "Took to collect: 5.266915559768677\n",
      "Took to train: 6.420366048812866\n",
      "\n",
      " Cycle 98 3\n",
      "Took to collect: 6.144514560699463\n",
      "Took to train: 6.453740835189819\n",
      "\n",
      " Cycle 99 3\n",
      "Took to collect: 5.534684658050537\n",
      "Took to train: 6.400424242019653\n",
      "Time collect avg cycle: 5.157968657016754\n",
      "Time train avg cycle: 6.401724679470062\n",
      "Total avg cycle: 11.570543432235718\n",
      "Ending epoch\n",
      "2020-10-25 23:05:46.077526 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 3 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged tensorboard\n",
      "---------------------------------------------  --------------\n",
      "trainer/num train calls                            0\n",
      "trainer/QF1 Loss                                   0.281873\n",
      "trainer/QF2 Loss                                   0.177954\n",
      "trainer/Policy Loss                               33.6167\n",
      "trainer/Q1 Predictions Mean                      -33.8831\n",
      "trainer/Q1 Predictions Std                        18.2256\n",
      "trainer/Q1 Predictions Max                        -0.41819\n",
      "trainer/Q1 Predictions Min                       -64.6907\n",
      "trainer/Q2 Predictions Mean                      -33.6577\n",
      "trainer/Q2 Predictions Std                        18.222\n",
      "trainer/Q2 Predictions Max                        -0.872741\n",
      "trainer/Q2 Predictions Min                       -64.2432\n",
      "trainer/Q Targets Mean                           -33.6341\n",
      "trainer/Q Targets Std                             18.1948\n",
      "trainer/Q Targets Max                             -1.22225\n",
      "trainer/Q Targets Min                            -65.1168\n",
      "trainer/Log Pis Mean                               2.75631\n",
      "trainer/Log Pis Std                                2.05744\n",
      "trainer/Log Pis Max                                9.03182\n",
      "trainer/Log Pis Min                               -4.06916\n",
      "trainer/policy/mean Mean                          -0.371279\n",
      "trainer/policy/mean Std                            0.634921\n",
      "trainer/policy/mean Max                            0.996794\n",
      "trainer/policy/mean Min                           -0.992178\n",
      "trainer/policy/normal/std Mean                     0.390345\n",
      "trainer/policy/normal/std Std                      0.18684\n",
      "trainer/policy/normal/std Max                      1.31918\n",
      "trainer/policy/normal/std Min                      0.112764\n",
      "trainer/policy/normal/log_std Mean                -1.05662\n",
      "trainer/policy/normal/log_std Std                  0.48956\n",
      "trainer/policy/normal/log_std Max                  0.277008\n",
      "trainer/policy/normal/log_std Min                 -2.18245\n",
      "trainer/Alpha                                      0.015131\n",
      "trainer/Alpha Loss                                -1.02131\n",
      "exploration/num steps total                    41000\n",
      "exploration/num paths total                      820\n",
      "exploration/path length Mean                      50\n",
      "exploration/path length Std                        0\n",
      "exploration/path length Max                       50\n",
      "exploration/path length Min                       50\n",
      "exploration/Rewards Mean                          -1\n",
      "exploration/Rewards Std                            0\n",
      "exploration/Rewards Max                           -1\n",
      "exploration/Rewards Min                           -1\n",
      "exploration/Returns Mean                         -50\n",
      "exploration/Returns Std                            0\n",
      "exploration/Returns Max                          -50\n",
      "exploration/Returns Min                          -50\n",
      "exploration/Actions Mean                          -0.547561\n",
      "exploration/Actions Std                            0.50764\n",
      "exploration/Actions Max                            0.999593\n",
      "exploration/Actions Min                           -0.999741\n",
      "exploration/Num Paths                            200\n",
      "exploration/Average Returns                      -50\n",
      "exploration/env_infos/final/is_success Mean        0\n",
      "exploration/env_infos/final/is_success Std         0\n",
      "exploration/env_infos/final/is_success Max         0\n",
      "exploration/env_infos/final/is_success Min         0\n",
      "exploration/env_infos/initial/is_success Mean      0\n",
      "exploration/env_infos/initial/is_success Std       0\n",
      "exploration/env_infos/initial/is_success Max       0\n",
      "exploration/env_infos/initial/is_success Min       0\n",
      "exploration/env_infos/is_success Mean              0\n",
      "exploration/env_infos/is_success Std               0\n",
      "exploration/env_infos/is_success Max               0\n",
      "exploration/env_infos/is_success Min               0\n",
      "evaluation/num steps total                      2000\n",
      "evaluation/num paths total                        40\n",
      "evaluation/path length Mean                       50\n",
      "evaluation/path length Std                         0\n",
      "evaluation/path length Max                        50\n",
      "evaluation/path length Min                        50\n",
      "evaluation/Rewards Mean                           -1\n",
      "evaluation/Rewards Std                             0\n",
      "evaluation/Rewards Max                            -1\n",
      "evaluation/Rewards Min                            -1\n",
      "evaluation/Returns Mean                          -50\n",
      "evaluation/Returns Std                             0\n",
      "evaluation/Returns Max                           -50\n",
      "evaluation/Returns Min                           -50\n",
      "evaluation/Actions Mean                           -0.337851\n",
      "evaluation/Actions Std                             0.611907\n",
      "evaluation/Actions Max                             0.973768\n",
      "evaluation/Actions Min                            -0.979643\n",
      "evaluation/Num Paths                              10\n",
      "evaluation/Average Returns                       -50\n",
      "evaluation/env_infos/final/is_success Mean         0\n",
      "evaluation/env_infos/final/is_success Std          0\n",
      "evaluation/env_infos/final/is_success Max          0\n",
      "evaluation/env_infos/final/is_success Min          0\n",
      "evaluation/env_infos/initial/is_success Mean       0\n",
      "evaluation/env_infos/initial/is_success Std        0\n",
      "evaluation/env_infos/initial/is_success Max        0\n",
      "evaluation/env_infos/initial/is_success Min        0\n",
      "evaluation/env_infos/is_success Mean               0\n",
      "evaluation/env_infos/is_success Std                0\n",
      "evaluation/env_infos/is_success Max                0\n",
      "evaluation/env_infos/is_success Min                0\n",
      "time/data storing (s)                              1.05975\n",
      "time/evaluation sampling (s)                      32.7701\n",
      "time/exploration sampling (s)                    515.816\n",
      "time/logging (s)                                   0.0276999\n",
      "time/sac training (s)                            200.391\n",
      "time/saving (s)                                    0.0139892\n",
      "time/training (s)                                  0.00694522\n",
      "time/epoch (s)                                   750.085\n",
      "time/total (s)                                  5222.35\n",
      "Epoch                                              3\n",
      "---------------------------------------------  --------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 4\n",
      "\n",
      " Cycle 0 4\n",
      "Took to collect: 5.750122547149658\n",
      "Took to train: 6.392027378082275\n",
      "\n",
      " Cycle 1 4\n",
      "Took to collect: 5.439856767654419\n",
      "Took to train: 6.449259996414185\n",
      "\n",
      " Cycle 2 4\n",
      "Took to collect: 7.258933067321777\n",
      "Took to train: 6.271183013916016\n",
      "\n",
      " Cycle 3 4\n",
      "Took to collect: 5.679517984390259\n",
      "Took to train: 6.307566165924072\n",
      "\n",
      " Cycle 4 4\n",
      "Took to collect: 6.3461315631866455\n",
      "Took to train: 6.394615173339844\n",
      "\n",
      " Cycle 5 4\n",
      "Took to collect: 5.139474153518677\n",
      "Took to train: 6.392528533935547\n",
      "\n",
      " Cycle 6 4\n",
      "Took to collect: 6.5071985721588135\n",
      "Took to train: 6.3778862953186035\n",
      "\n",
      " Cycle 7 4\n",
      "Took to collect: 5.808589935302734\n",
      "Took to train: 6.392947673797607\n",
      "\n",
      " Cycle 8 4\n",
      "Took to collect: 6.797284364700317\n",
      "Took to train: 6.300863027572632\n",
      "\n",
      " Cycle 9 4\n",
      "Took to collect: 6.605602264404297\n",
      "Took to train: 6.3546059131622314\n",
      "\n",
      " Cycle 10 4\n",
      "Took to collect: 6.811574697494507\n",
      "Took to train: 6.36138916015625\n",
      "\n",
      " Cycle 11 4\n",
      "Took to collect: 6.435282945632935\n",
      "Took to train: 6.273708343505859\n",
      "\n",
      " Cycle 12 4\n",
      "Took to collect: 6.4169042110443115\n",
      "Took to train: 6.366302013397217\n",
      "\n",
      " Cycle 13 4\n",
      "Took to collect: 6.485491514205933\n",
      "Took to train: 6.295579671859741\n",
      "\n",
      " Cycle 14 4\n",
      "Took to collect: 9.237015724182129\n",
      "Took to train: 6.274112701416016\n",
      "\n",
      " Cycle 15 4\n",
      "Took to collect: 6.144442796707153\n",
      "Took to train: 6.275339841842651\n",
      "\n",
      " Cycle 16 4\n",
      "Took to collect: 5.245497703552246\n",
      "Took to train: 6.2695558071136475\n",
      "\n",
      " Cycle 17 4\n",
      "Took to collect: 6.073503017425537\n",
      "Took to train: 6.2853007316589355\n",
      "\n",
      " Cycle 18 4\n",
      "Took to collect: 7.746734380722046\n",
      "Took to train: 6.271890878677368\n",
      "\n",
      " Cycle 19 4\n",
      "Took to collect: 7.233075380325317\n",
      "Took to train: 6.389444351196289\n",
      "\n",
      " Cycle 20 4\n",
      "Took to collect: 7.560105323791504\n",
      "Took to train: 6.453631639480591\n",
      "\n",
      " Cycle 21 4\n",
      "Took to collect: 7.538333415985107\n",
      "Took to train: 6.40629506111145\n",
      "\n",
      " Cycle 22 4\n",
      "Took to collect: 5.823491096496582\n",
      "Took to train: 6.395660400390625\n",
      "\n",
      " Cycle 23 4\n",
      "Took to collect: 5.1627888679504395\n",
      "Took to train: 6.406263828277588\n",
      "\n",
      " Cycle 24 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 8.166178941726685\n",
      "Took to train: 6.392406463623047\n",
      "\n",
      " Cycle 25 4\n",
      "Took to collect: 6.634437561035156\n",
      "Took to train: 6.381677865982056\n",
      "\n",
      " Cycle 26 4\n",
      "Took to collect: 6.827716112136841\n",
      "Took to train: 6.305774927139282\n",
      "\n",
      " Cycle 27 4\n",
      "Took to collect: 7.336405992507935\n",
      "Took to train: 6.264813423156738\n",
      "\n",
      " Cycle 28 4\n",
      "Took to collect: 8.470120906829834\n",
      "Took to train: 6.254846572875977\n",
      "\n",
      " Cycle 29 4\n",
      "Took to collect: 5.561644792556763\n",
      "Took to train: 6.269361257553101\n",
      "\n",
      " Cycle 30 4\n",
      "Took to collect: 5.777942180633545\n",
      "Took to train: 6.372816801071167\n",
      "\n",
      " Cycle 31 4\n",
      "Took to collect: 6.68860936164856\n",
      "Took to train: 6.446988582611084\n",
      "\n",
      " Cycle 32 4\n",
      "Took to collect: 7.8159754276275635\n",
      "Took to train: 6.286881685256958\n",
      "\n",
      " Cycle 33 4\n",
      "Took to collect: 6.199070692062378\n",
      "Took to train: 6.383894681930542\n",
      "\n",
      " Cycle 34 4\n",
      "Took to collect: 6.05861234664917\n",
      "Took to train: 6.439537525177002\n",
      "\n",
      " Cycle 35 4\n",
      "Took to collect: 6.592063665390015\n",
      "Took to train: 6.448574781417847\n",
      "\n",
      " Cycle 36 4\n",
      "Took to collect: 7.036657333374023\n",
      "Took to train: 6.43714165687561\n",
      "\n",
      " Cycle 37 4\n",
      "Took to collect: 7.435297250747681\n",
      "Took to train: 6.439823389053345\n",
      "\n",
      " Cycle 38 4\n",
      "Took to collect: 6.605703115463257\n",
      "Took to train: 6.391885042190552\n",
      "\n",
      " Cycle 39 4\n",
      "Took to collect: 6.8203206062316895\n",
      "Took to train: 6.351686477661133\n",
      "\n",
      " Cycle 40 4\n",
      "Took to collect: 6.302644491195679\n",
      "Took to train: 6.451824188232422\n",
      "\n",
      " Cycle 41 4\n",
      "Took to collect: 7.419194936752319\n",
      "Took to train: 6.47346043586731\n",
      "\n",
      " Cycle 42 4\n",
      "Took to collect: 5.475260019302368\n",
      "Took to train: 6.4333906173706055\n",
      "\n",
      " Cycle 43 4\n",
      "Took to collect: 6.760091781616211\n",
      "Took to train: 6.440062046051025\n",
      "\n",
      " Cycle 44 4\n",
      "Took to collect: 7.22653865814209\n",
      "Took to train: 6.376204967498779\n",
      "\n",
      " Cycle 45 4\n",
      "Took to collect: 8.202493906021118\n",
      "Took to train: 6.453903675079346\n",
      "\n",
      " Cycle 46 4\n",
      "Took to collect: 7.727112293243408\n",
      "Took to train: 6.431317329406738\n",
      "\n",
      " Cycle 47 4\n",
      "Took to collect: 6.573690176010132\n",
      "Took to train: 6.370193958282471\n",
      "\n",
      " Cycle 48 4\n",
      "Took to collect: 6.624910593032837\n",
      "Took to train: 6.249140024185181\n",
      "\n",
      " Cycle 49 4\n",
      "Took to collect: 8.551517009735107\n",
      "Took to train: 6.3664751052856445\n",
      "\n",
      " Cycle 50 4\n",
      "Took to collect: 7.575994491577148\n",
      "Took to train: 6.353851556777954\n",
      "\n",
      " Cycle 51 4\n",
      "Took to collect: 8.406500577926636\n",
      "Took to train: 6.369927406311035\n",
      "\n",
      " Cycle 52 4\n",
      "Took to collect: 7.592378854751587\n",
      "Took to train: 6.384244203567505\n",
      "\n",
      " Cycle 53 4\n",
      "Took to collect: 7.147300958633423\n",
      "Took to train: 6.342491626739502\n",
      "\n",
      " Cycle 54 4\n",
      "Took to collect: 9.080689191818237\n",
      "Took to train: 6.33866286277771\n",
      "\n",
      " Cycle 55 4\n",
      "Took to collect: 6.425349473953247\n",
      "Took to train: 6.359640836715698\n",
      "\n",
      " Cycle 56 4\n",
      "Took to collect: 8.220998525619507\n",
      "Took to train: 6.362831115722656\n",
      "\n",
      " Cycle 57 4\n",
      "Took to collect: 7.028539419174194\n",
      "Took to train: 6.381864309310913\n",
      "\n",
      " Cycle 58 4\n",
      "Took to collect: 7.734809637069702\n",
      "Took to train: 6.494775295257568\n",
      "\n",
      " Cycle 59 4\n",
      "Took to collect: 8.520637035369873\n",
      "Took to train: 6.476497650146484\n",
      "\n",
      " Cycle 60 4\n",
      "Took to collect: 8.08098316192627\n",
      "Took to train: 6.491218090057373\n",
      "\n",
      " Cycle 61 4\n",
      "Took to collect: 7.560286998748779\n",
      "Took to train: 6.478569984436035\n",
      "\n",
      " Cycle 62 4\n",
      "Took to collect: 8.230894088745117\n",
      "Took to train: 6.484745979309082\n",
      "\n",
      " Cycle 63 4\n",
      "Took to collect: 5.808486700057983\n",
      "Took to train: 6.507940769195557\n",
      "\n",
      " Cycle 64 4\n",
      "Took to collect: 8.340093612670898\n",
      "Took to train: 6.462421178817749\n",
      "\n",
      " Cycle 65 4\n",
      "Took to collect: 8.262710094451904\n",
      "Took to train: 6.429571866989136\n",
      "\n",
      " Cycle 66 4\n",
      "Took to collect: 6.78689980506897\n",
      "Took to train: 6.440094232559204\n",
      "\n",
      " Cycle 67 4\n",
      "Took to collect: 6.577274322509766\n",
      "Took to train: 6.468498945236206\n",
      "\n",
      " Cycle 68 4\n",
      "Took to collect: 7.576169013977051\n",
      "Took to train: 6.4877519607543945\n",
      "\n",
      " Cycle 69 4\n",
      "Took to collect: 7.748664140701294\n",
      "Took to train: 6.480640411376953\n",
      "\n",
      " Cycle 70 4\n",
      "Took to collect: 6.864809036254883\n",
      "Took to train: 6.490825891494751\n",
      "\n",
      " Cycle 71 4\n",
      "Took to collect: 6.808469533920288\n",
      "Took to train: 6.375002861022949\n",
      "\n",
      " Cycle 72 4\n",
      "Took to collect: 7.861628293991089\n",
      "Took to train: 6.403129577636719\n",
      "\n",
      " Cycle 73 4\n",
      "Took to collect: 10.596543788909912\n",
      "Took to train: 6.382549524307251\n",
      "\n",
      " Cycle 74 4\n",
      "Took to collect: 7.329503536224365\n",
      "Took to train: 6.45006799697876\n",
      "\n",
      " Cycle 75 4\n",
      "Took to collect: 6.964555740356445\n",
      "Took to train: 6.456866025924683\n",
      "\n",
      " Cycle 76 4\n",
      "Took to collect: 8.273011684417725\n",
      "Took to train: 6.404441595077515\n",
      "\n",
      " Cycle 77 4\n",
      "Took to collect: 7.455963134765625\n",
      "Took to train: 6.388676166534424\n",
      "\n",
      " Cycle 78 4\n",
      "Took to collect: 7.025654315948486\n",
      "Took to train: 6.450916051864624\n",
      "\n",
      " Cycle 79 4\n",
      "Took to collect: 6.279400587081909\n",
      "Took to train: 6.4149980545043945\n",
      "\n",
      " Cycle 80 4\n",
      "Took to collect: 6.992636203765869\n",
      "Took to train: 6.436477184295654\n",
      "\n",
      " Cycle 81 4\n",
      "Took to collect: 8.138587236404419\n",
      "Took to train: 6.453074216842651\n",
      "\n",
      " Cycle 82 4\n",
      "Took to collect: 7.677699089050293\n",
      "Took to train: 6.411635160446167\n",
      "\n",
      " Cycle 83 4\n",
      "Took to collect: 7.2477922439575195\n",
      "Took to train: 6.393596410751343\n",
      "\n",
      " Cycle 84 4\n",
      "Took to collect: 7.050969123840332\n",
      "Took to train: 6.326045751571655\n",
      "\n",
      " Cycle 85 4\n",
      "Took to collect: 7.64363169670105\n",
      "Took to train: 6.3811845779418945\n",
      "\n",
      " Cycle 86 4\n",
      "Took to collect: 6.703439235687256\n",
      "Took to train: 6.372073173522949\n",
      "\n",
      " Cycle 87 4\n",
      "Took to collect: 7.57763409614563\n",
      "Took to train: 6.376678466796875\n",
      "\n",
      " Cycle 88 4\n",
      "Took to collect: 10.002115726470947\n",
      "Took to train: 6.232952833175659\n",
      "\n",
      " Cycle 89 4\n",
      "Took to collect: 7.441477060317993\n",
      "Took to train: 6.40632438659668\n",
      "\n",
      " Cycle 90 4\n",
      "Took to collect: 8.100494146347046\n",
      "Took to train: 6.460625171661377\n",
      "\n",
      " Cycle 91 4\n",
      "Took to collect: 5.982419967651367\n",
      "Took to train: 6.463942527770996\n",
      "\n",
      " Cycle 92 4\n",
      "Took to collect: 6.328259468078613\n",
      "Took to train: 6.327340126037598\n",
      "\n",
      " Cycle 93 4\n",
      "Took to collect: 7.088322401046753\n",
      "Took to train: 6.35703706741333\n",
      "\n",
      " Cycle 94 4\n",
      "Took to collect: 7.203620910644531\n",
      "Took to train: 6.331083536148071\n",
      "\n",
      " Cycle 95 4\n",
      "Took to collect: 7.2480244636535645\n",
      "Took to train: 6.361966609954834\n",
      "\n",
      " Cycle 96 4\n",
      "Took to collect: 6.129060506820679\n",
      "Took to train: 6.344017028808594\n",
      "\n",
      " Cycle 97 4\n",
      "Took to collect: 7.58512806892395\n",
      "Took to train: 6.3845648765563965\n",
      "\n",
      " Cycle 98 4\n",
      "Took to collect: 7.511036396026611\n",
      "Took to train: 6.38301157951355\n",
      "\n",
      " Cycle 99 4\n",
      "Took to collect: 7.1517674922943115\n",
      "Took to train: 6.375357389450073\n",
      "Time collect avg cycle: 7.111064777374268\n",
      "Time train avg cycle: 6.386647431850434\n",
      "Total avg cycle: 13.508549439907075\n",
      "Ending epoch\n",
      "2020-10-25 23:28:45.665567 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 4 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  --------------\n",
      "trainer/num train calls                            0\n",
      "trainer/QF1 Loss                                   0.266319\n",
      "trainer/QF2 Loss                                   0.267113\n",
      "trainer/Policy Loss                               35.784\n",
      "trainer/Q1 Predictions Mean                      -35.7127\n",
      "trainer/Q1 Predictions Std                        25.2148\n",
      "trainer/Q1 Predictions Max                         4.30989\n",
      "trainer/Q1 Predictions Min                       -77.5018\n",
      "trainer/Q2 Predictions Mean                      -35.9648\n",
      "trainer/Q2 Predictions Std                        25.1533\n",
      "trainer/Q2 Predictions Max                         4.39433\n",
      "trainer/Q2 Predictions Min                       -77.6916\n",
      "trainer/Q Targets Mean                           -35.8377\n",
      "trainer/Q Targets Std                             25.2627\n",
      "trainer/Q Targets Max                              4.27653\n",
      "trainer/Q Targets Min                            -77.7117\n",
      "trainer/Log Pis Mean                               2.89465\n",
      "trainer/Log Pis Std                                1.97097\n",
      "trainer/Log Pis Max                                8.97635\n",
      "trainer/Log Pis Min                               -4.86705\n",
      "trainer/policy/mean Mean                          -0.385716\n",
      "trainer/policy/mean Std                            0.613817\n",
      "trainer/policy/mean Max                            0.988385\n",
      "trainer/policy/mean Min                           -0.993728\n",
      "trainer/policy/normal/std Mean                     0.347727\n",
      "trainer/policy/normal/std Std                      0.180714\n",
      "trainer/policy/normal/std Max                      1.08436\n",
      "trainer/policy/normal/std Min                      0.084982\n",
      "trainer/policy/normal/log_std Mean                -1.19511\n",
      "trainer/policy/normal/log_std Std                  0.535706\n",
      "trainer/policy/normal/log_std Max                  0.0809887\n",
      "trainer/policy/normal/log_std Min                 -2.46532\n",
      "trainer/Alpha                                      0.0140606\n",
      "trainer/Alpha Loss                                -0.449265\n",
      "exploration/num steps total                    51000\n",
      "exploration/num paths total                     1020\n",
      "exploration/path length Mean                      50\n",
      "exploration/path length Std                        0\n",
      "exploration/path length Max                       50\n",
      "exploration/path length Min                       50\n",
      "exploration/Rewards Mean                          -1\n",
      "exploration/Rewards Std                            0\n",
      "exploration/Rewards Max                           -1\n",
      "exploration/Rewards Min                           -1\n",
      "exploration/Returns Mean                         -50\n",
      "exploration/Returns Std                            0\n",
      "exploration/Returns Max                          -50\n",
      "exploration/Returns Min                          -50\n",
      "exploration/Actions Mean                          -0.271498\n",
      "exploration/Actions Std                            0.629064\n",
      "exploration/Actions Max                            0.999596\n",
      "exploration/Actions Min                           -0.999751\n",
      "exploration/Num Paths                            200\n",
      "exploration/Average Returns                      -50\n",
      "exploration/env_infos/final/is_success Mean        0\n",
      "exploration/env_infos/final/is_success Std         0\n",
      "exploration/env_infos/final/is_success Max         0\n",
      "exploration/env_infos/final/is_success Min         0\n",
      "exploration/env_infos/initial/is_success Mean      0\n",
      "exploration/env_infos/initial/is_success Std       0\n",
      "exploration/env_infos/initial/is_success Max       0\n",
      "exploration/env_infos/initial/is_success Min       0\n",
      "exploration/env_infos/is_success Mean              0\n",
      "exploration/env_infos/is_success Std               0\n",
      "exploration/env_infos/is_success Max               0\n",
      "exploration/env_infos/is_success Min               0\n",
      "evaluation/num steps total                      2500\n",
      "evaluation/num paths total                        50\n",
      "evaluation/path length Mean                       50\n",
      "evaluation/path length Std                         0\n",
      "evaluation/path length Max                        50\n",
      "evaluation/path length Min                        50\n",
      "evaluation/Rewards Mean                           -1\n",
      "evaluation/Rewards Std                             0\n",
      "evaluation/Rewards Max                            -1\n",
      "evaluation/Rewards Min                            -1\n",
      "evaluation/Returns Mean                          -50\n",
      "evaluation/Returns Std                             0\n",
      "evaluation/Returns Max                           -50\n",
      "evaluation/Returns Min                           -50\n",
      "evaluation/Actions Mean                           -0.742149\n",
      "evaluation/Actions Std                             0.378385\n",
      "evaluation/Actions Max                             0.976991\n",
      "evaluation/Actions Min                            -0.98012\n",
      "evaluation/Num Paths                              10\n",
      "evaluation/Average Returns                       -50\n",
      "evaluation/env_infos/final/is_success Mean         0\n",
      "evaluation/env_infos/final/is_success Std          0\n",
      "evaluation/env_infos/final/is_success Max          0\n",
      "evaluation/env_infos/final/is_success Min          0\n",
      "evaluation/env_infos/initial/is_success Mean       0\n",
      "evaluation/env_infos/initial/is_success Std        0\n",
      "evaluation/env_infos/initial/is_success Max        0\n",
      "evaluation/env_infos/initial/is_success Min        0\n",
      "evaluation/env_infos/is_success Mean               0\n",
      "evaluation/env_infos/is_success Std                0\n",
      "evaluation/env_infos/is_success Max                0\n",
      "evaluation/env_infos/is_success Min                0\n",
      "time/data storing (s)                              1.05789\n",
      "time/evaluation sampling (s)                      28.6718\n",
      "time/exploration sampling (s)                    711.126\n",
      "time/logging (s)                                   0.0276274\n",
      "time/sac training (s)                            199.795\n",
      "time/saving (s)                                    0.0139848\n",
      "time/training (s)                                  0.00701328\n",
      "time/epoch (s)                                   940.7\n",
      "time/total (s)                                  6601.75\n",
      "Epoch                                              4\n",
      "---------------------------------------------  --------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 5\n",
      "\n",
      " Cycle 0 5\n",
      "Took to collect: 8.022904396057129\n",
      "Took to train: 6.382785081863403\n",
      "\n",
      " Cycle 1 5\n",
      "Took to collect: 6.377535104751587\n",
      "Took to train: 6.496437072753906\n",
      "\n",
      " Cycle 2 5\n",
      "Took to collect: 7.5762104988098145\n",
      "Took to train: 6.397416114807129\n",
      "\n",
      " Cycle 3 5\n",
      "Took to collect: 7.803011894226074\n",
      "Took to train: 6.5101823806762695\n",
      "\n",
      " Cycle 4 5\n",
      "Took to collect: 8.792606830596924\n",
      "Took to train: 6.51055908203125\n",
      "\n",
      " Cycle 5 5\n",
      "Took to collect: 8.610930681228638\n",
      "Took to train: 6.511339902877808\n",
      "\n",
      " Cycle 6 5\n",
      "Took to collect: 8.009580135345459\n",
      "Took to train: 6.452605247497559\n",
      "\n",
      " Cycle 7 5\n",
      "Took to collect: 7.44317364692688\n",
      "Took to train: 6.377874374389648\n",
      "\n",
      " Cycle 8 5\n",
      "Took to collect: 7.547881603240967\n",
      "Took to train: 6.376993179321289\n",
      "\n",
      " Cycle 9 5\n",
      "Took to collect: 7.114753484725952\n",
      "Took to train: 6.36780571937561\n",
      "\n",
      " Cycle 10 5\n",
      "Took to collect: 9.031633615493774\n",
      "Took to train: 6.379451274871826\n",
      "\n",
      " Cycle 11 5\n",
      "Took to collect: 6.9437878131866455\n",
      "Took to train: 6.459311485290527\n",
      "\n",
      " Cycle 12 5\n",
      "Took to collect: 7.136340618133545\n",
      "Took to train: 6.480064630508423\n",
      "\n",
      " Cycle 13 5\n",
      "Took to collect: 6.5187013149261475\n",
      "Took to train: 6.449819803237915\n",
      "\n",
      " Cycle 14 5\n",
      "Took to collect: 7.731724739074707\n",
      "Took to train: 6.460532188415527\n",
      "\n",
      " Cycle 15 5\n",
      "Took to collect: 6.765922784805298\n",
      "Took to train: 6.441713571548462\n",
      "\n",
      " Cycle 16 5\n",
      "Took to collect: 8.407161235809326\n",
      "Took to train: 6.439897537231445\n",
      "\n",
      " Cycle 17 5\n",
      "Took to collect: 6.088455677032471\n",
      "Took to train: 6.246947765350342\n",
      "\n",
      " Cycle 18 5\n",
      "Took to collect: 7.5074849128723145\n",
      "Took to train: 6.328503131866455\n",
      "\n",
      " Cycle 19 5\n",
      "Took to collect: 6.744929313659668\n",
      "Took to train: 6.382981300354004\n",
      "\n",
      " Cycle 20 5\n",
      "Took to collect: 8.6096830368042\n",
      "Took to train: 6.396247148513794\n",
      "\n",
      " Cycle 21 5\n",
      "Took to collect: 7.8891541957855225\n",
      "Took to train: 6.444319248199463\n",
      "\n",
      " Cycle 22 5\n",
      "Took to collect: 7.558923244476318\n",
      "Took to train: 6.479923486709595\n",
      "\n",
      " Cycle 23 5\n",
      "Took to collect: 6.658611536026001\n",
      "Took to train: 6.4771199226379395\n",
      "\n",
      " Cycle 24 5\n",
      "Took to collect: 7.661708116531372\n",
      "Took to train: 6.395507335662842\n",
      "\n",
      " Cycle 25 5\n",
      "Took to collect: 6.80262565612793\n",
      "Took to train: 6.490575790405273\n",
      "\n",
      " Cycle 26 5\n",
      "Took to collect: 8.55547046661377\n",
      "Took to train: 6.473583459854126\n",
      "\n",
      " Cycle 27 5\n",
      "Took to collect: 8.786901235580444\n",
      "Took to train: 6.476311206817627\n",
      "\n",
      " Cycle 28 5\n",
      "Took to collect: 7.807934761047363\n",
      "Took to train: 6.439671039581299\n",
      "\n",
      " Cycle 29 5\n",
      "Took to collect: 8.649466276168823\n",
      "Took to train: 6.349055051803589\n",
      "\n",
      " Cycle 30 5\n",
      "Took to collect: 6.610480308532715\n",
      "Took to train: 6.44954514503479\n",
      "\n",
      " Cycle 31 5\n",
      "Took to collect: 8.443986177444458\n",
      "Took to train: 6.478073835372925\n",
      "\n",
      " Cycle 32 5\n",
      "Took to collect: 6.627743721008301\n",
      "Took to train: 6.497266054153442\n",
      "\n",
      " Cycle 33 5\n",
      "Took to collect: 5.9066481590271\n",
      "Took to train: 6.344622373580933\n",
      "\n",
      " Cycle 34 5\n",
      "Took to collect: 6.620063781738281\n",
      "Took to train: 6.3513710498809814\n",
      "\n",
      " Cycle 35 5\n",
      "Took to collect: 7.564807176589966\n",
      "Took to train: 6.429698467254639\n",
      "\n",
      " Cycle 36 5\n",
      "Took to collect: 7.036719083786011\n",
      "Took to train: 6.426845550537109\n",
      "\n",
      " Cycle 37 5\n",
      "Took to collect: 9.116971492767334\n",
      "Took to train: 6.396422624588013\n",
      "\n",
      " Cycle 38 5\n",
      "Took to collect: 8.461296081542969\n",
      "Took to train: 6.451983213424683\n",
      "\n",
      " Cycle 39 5\n",
      "Took to collect: 8.230080604553223\n",
      "Took to train: 6.462428092956543\n",
      "\n",
      " Cycle 40 5\n",
      "Took to collect: 6.723380088806152\n",
      "Took to train: 6.445380210876465\n",
      "\n",
      " Cycle 41 5\n",
      "Took to collect: 9.063633441925049\n",
      "Took to train: 6.390766620635986\n",
      "\n",
      " Cycle 42 5\n",
      "Took to collect: 8.00587272644043\n",
      "Took to train: 6.368934392929077\n",
      "\n",
      " Cycle 43 5\n",
      "Took to collect: 7.670843124389648\n",
      "Took to train: 6.3884437084198\n",
      "\n",
      " Cycle 44 5\n",
      "Took to collect: 8.689689636230469\n",
      "Took to train: 6.393812894821167\n",
      "\n",
      " Cycle 45 5\n",
      "Took to collect: 7.665296316146851\n",
      "Took to train: 6.387707710266113\n",
      "\n",
      " Cycle 46 5\n",
      "Took to collect: 6.090402603149414\n",
      "Took to train: 6.379631757736206\n",
      "\n",
      " Cycle 47 5\n",
      "Took to collect: 7.665802717208862\n",
      "Took to train: 6.372720241546631\n",
      "\n",
      " Cycle 48 5\n",
      "Took to collect: 7.727941036224365\n",
      "Took to train: 6.356518268585205\n",
      "\n",
      " Cycle 49 5\n",
      "Took to collect: 9.4556143283844\n",
      "Took to train: 6.32589864730835\n",
      "\n",
      " Cycle 50 5\n",
      "Took to collect: 7.409155368804932\n",
      "Took to train: 6.396226644515991\n",
      "\n",
      " Cycle 51 5\n",
      "Took to collect: 7.288471221923828\n",
      "Took to train: 6.378925561904907\n",
      "\n",
      " Cycle 52 5\n",
      "Took to collect: 7.1731908321380615\n",
      "Took to train: 6.412211179733276\n",
      "\n",
      " Cycle 53 5\n",
      "Took to collect: 7.585623025894165\n",
      "Took to train: 6.340718984603882\n",
      "\n",
      " Cycle 54 5\n",
      "Took to collect: 6.941513538360596\n",
      "Took to train: 6.449806451797485\n",
      "\n",
      " Cycle 55 5\n",
      "Took to collect: 6.190934181213379\n",
      "Took to train: 6.417935371398926\n",
      "\n",
      " Cycle 56 5\n",
      "Took to collect: 8.573759078979492\n",
      "Took to train: 6.439988136291504\n",
      "\n",
      " Cycle 57 5\n",
      "Took to collect: 7.647381544113159\n",
      "Took to train: 6.417731761932373\n",
      "\n",
      " Cycle 58 5\n",
      "Took to collect: 8.42992115020752\n",
      "Took to train: 6.462003707885742\n",
      "\n",
      " Cycle 59 5\n",
      "Took to collect: 7.614445209503174\n",
      "Took to train: 6.419346809387207\n",
      "\n",
      " Cycle 60 5\n",
      "Took to collect: 6.91029167175293\n",
      "Took to train: 6.449488401412964\n",
      "\n",
      " Cycle 61 5\n",
      "Took to collect: 7.381011962890625\n",
      "Took to train: 6.448201656341553\n",
      "\n",
      " Cycle 62 5\n",
      "Took to collect: 6.397252559661865\n",
      "Took to train: 6.456663370132446\n",
      "\n",
      " Cycle 63 5\n",
      "Took to collect: 6.4253785610198975\n",
      "Took to train: 6.453079700469971\n",
      "\n",
      " Cycle 64 5\n",
      "Took to collect: 7.0700788497924805\n",
      "Took to train: 6.453610420227051\n",
      "\n",
      " Cycle 65 5\n",
      "Took to collect: 6.163841009140015\n",
      "Took to train: 6.285735845565796\n",
      "\n",
      " Cycle 66 5\n",
      "Took to collect: 5.789959192276001\n",
      "Took to train: 6.2239670753479\n",
      "\n",
      " Cycle 67 5\n",
      "Took to collect: 7.780656814575195\n",
      "Took to train: 6.23775053024292\n",
      "\n",
      " Cycle 68 5\n",
      "Took to collect: 7.529496908187866\n",
      "Took to train: 6.235576868057251\n",
      "\n",
      " Cycle 69 5\n",
      "Took to collect: 7.196652412414551\n",
      "Took to train: 6.390589475631714\n",
      "\n",
      " Cycle 70 5\n",
      "Took to collect: 7.259825706481934\n",
      "Took to train: 6.437540531158447\n",
      "\n",
      " Cycle 71 5\n",
      "Took to collect: 9.099960565567017\n",
      "Took to train: 6.439422845840454\n",
      "\n",
      " Cycle 72 5\n",
      "Took to collect: 8.273347854614258\n",
      "Took to train: 6.432992458343506\n",
      "\n",
      " Cycle 73 5\n",
      "Took to collect: 7.436420679092407\n",
      "Took to train: 6.397716999053955\n",
      "\n",
      " Cycle 74 5\n",
      "Took to collect: 9.800442457199097\n",
      "Took to train: 6.450136184692383\n",
      "\n",
      " Cycle 75 5\n",
      "Took to collect: 7.852402448654175\n",
      "Took to train: 6.446451425552368\n",
      "\n",
      " Cycle 76 5\n",
      "Took to collect: 7.53252387046814\n",
      "Took to train: 6.428201675415039\n",
      "\n",
      " Cycle 77 5\n",
      "Took to collect: 6.492366313934326\n",
      "Took to train: 6.393995523452759\n",
      "\n",
      " Cycle 78 5\n",
      "Took to collect: 7.555148124694824\n",
      "Took to train: 6.4055495262146\n",
      "\n",
      " Cycle 79 5\n",
      "Took to collect: 8.158568382263184\n",
      "Took to train: 6.457351446151733\n",
      "\n",
      " Cycle 80 5\n",
      "Took to collect: 7.832966089248657\n",
      "Took to train: 6.433383226394653\n",
      "\n",
      " Cycle 81 5\n",
      "Took to collect: 8.02326488494873\n",
      "Took to train: 6.421536207199097\n",
      "\n",
      " Cycle 82 5\n",
      "Took to collect: 8.239903926849365\n",
      "Took to train: 6.426048994064331\n",
      "\n",
      " Cycle 83 5\n",
      "Took to collect: 8.7789146900177\n",
      "Took to train: 6.435896158218384\n",
      "\n",
      " Cycle 84 5\n",
      "Took to collect: 7.000768423080444\n",
      "Took to train: 6.396373987197876\n",
      "\n",
      " Cycle 85 5\n",
      "Took to collect: 7.72841477394104\n",
      "Took to train: 6.324693918228149\n",
      "\n",
      " Cycle 86 5\n",
      "Took to collect: 10.396960496902466\n",
      "Took to train: 6.259740591049194\n",
      "\n",
      " Cycle 87 5\n",
      "Took to collect: 8.141179084777832\n",
      "Took to train: 6.347018003463745\n",
      "\n",
      " Cycle 88 5\n",
      "Took to collect: 7.455294609069824\n",
      "Took to train: 6.412176132202148\n",
      "\n",
      " Cycle 89 5\n",
      "Took to collect: 6.510968446731567\n",
      "Took to train: 6.3652074337005615\n",
      "\n",
      " Cycle 90 5\n",
      "Took to collect: 6.430121898651123\n",
      "Took to train: 6.34293794631958\n",
      "\n",
      " Cycle 91 5\n",
      "Took to collect: 7.144346714019775\n",
      "Took to train: 6.404497861862183\n",
      "\n",
      " Cycle 92 5\n",
      "Took to collect: 8.13935661315918\n",
      "Took to train: 6.407490968704224\n",
      "\n",
      " Cycle 93 5\n",
      "Took to collect: 7.79195761680603\n",
      "Took to train: 6.38834547996521\n",
      "\n",
      " Cycle 94 5\n",
      "Took to collect: 5.617849588394165\n",
      "Took to train: 6.398654937744141\n",
      "\n",
      " Cycle 95 5\n",
      "Took to collect: 8.7978515625\n",
      "Took to train: 6.43319034576416\n",
      "\n",
      " Cycle 96 5\n",
      "Took to collect: 8.050101280212402\n",
      "Took to train: 6.314562797546387\n",
      "\n",
      " Cycle 97 5\n",
      "Took to collect: 8.348865270614624\n",
      "Took to train: 6.248334884643555\n",
      "\n",
      " Cycle 98 5\n",
      "Took to collect: 7.049563646316528\n",
      "Took to train: 6.356567144393921\n",
      "\n",
      " Cycle 99 5\n",
      "Took to collect: 7.322798490524292\n",
      "Took to train: 6.320037364959717\n",
      "Time collect avg cycle: 7.602939510345459\n",
      "Time train avg cycle: 6.404692163467407\n",
      "Total avg cycle: 14.01862229347229\n",
      "Ending epoch\n",
      "2020-10-25 23:52:46.216210 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 5 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged tensorboard\n",
      "---------------------------------------------  --------------\n",
      "trainer/num train calls                            0\n",
      "trainer/QF1 Loss                                   0.296329\n",
      "trainer/QF2 Loss                                   0.251944\n",
      "trainer/Policy Loss                               44.6531\n",
      "trainer/Q1 Predictions Mean                      -44.7767\n",
      "trainer/Q1 Predictions Std                        27.3312\n",
      "trainer/Q1 Predictions Max                         5.61688\n",
      "trainer/Q1 Predictions Min                       -86.5631\n",
      "trainer/Q2 Predictions Mean                      -44.5855\n",
      "trainer/Q2 Predictions Std                        27.3948\n",
      "trainer/Q2 Predictions Max                         6.09559\n",
      "trainer/Q2 Predictions Min                       -86.6543\n",
      "trainer/Q Targets Mean                           -44.6444\n",
      "trainer/Q Targets Std                             27.3358\n",
      "trainer/Q Targets Max                              6.16327\n",
      "trainer/Q Targets Min                            -86.685\n",
      "trainer/Log Pis Mean                               3.00129\n",
      "trainer/Log Pis Std                                2.27048\n",
      "trainer/Log Pis Max                               11.6632\n",
      "trainer/Log Pis Min                               -6.29451\n",
      "trainer/policy/mean Mean                          -0.247319\n",
      "trainer/policy/mean Std                            0.686295\n",
      "trainer/policy/mean Max                            0.998388\n",
      "trainer/policy/mean Min                           -0.993354\n",
      "trainer/policy/normal/std Mean                     0.367016\n",
      "trainer/policy/normal/std Std                      0.193534\n",
      "trainer/policy/normal/std Max                      1.58202\n",
      "trainer/policy/normal/std Min                      0.0721219\n",
      "trainer/policy/normal/log_std Mean                -1.15807\n",
      "trainer/policy/normal/log_std Std                  0.583937\n",
      "trainer/policy/normal/log_std Max                  0.458702\n",
      "trainer/policy/normal/log_std Min                 -2.6294\n",
      "trainer/Alpha                                      0.0130314\n",
      "trainer/Alpha Loss                                 0.00560305\n",
      "exploration/num steps total                    61000\n",
      "exploration/num paths total                     1220\n",
      "exploration/path length Mean                      50\n",
      "exploration/path length Std                        0\n",
      "exploration/path length Max                       50\n",
      "exploration/path length Min                       50\n",
      "exploration/Rewards Mean                          -1\n",
      "exploration/Rewards Std                            0\n",
      "exploration/Rewards Max                           -1\n",
      "exploration/Rewards Min                           -1\n",
      "exploration/Returns Mean                         -50\n",
      "exploration/Returns Std                            0\n",
      "exploration/Returns Max                          -50\n",
      "exploration/Returns Min                          -50\n",
      "exploration/Actions Mean                          -0.241716\n",
      "exploration/Actions Std                            0.632991\n",
      "exploration/Actions Max                            0.99899\n",
      "exploration/Actions Min                           -0.999781\n",
      "exploration/Num Paths                            200\n",
      "exploration/Average Returns                      -50\n",
      "exploration/env_infos/final/is_success Mean        0\n",
      "exploration/env_infos/final/is_success Std         0\n",
      "exploration/env_infos/final/is_success Max         0\n",
      "exploration/env_infos/final/is_success Min         0\n",
      "exploration/env_infos/initial/is_success Mean      0\n",
      "exploration/env_infos/initial/is_success Std       0\n",
      "exploration/env_infos/initial/is_success Max       0\n",
      "exploration/env_infos/initial/is_success Min       0\n",
      "exploration/env_infos/is_success Mean              0\n",
      "exploration/env_infos/is_success Std               0\n",
      "exploration/env_infos/is_success Max               0\n",
      "exploration/env_infos/is_success Min               0\n",
      "evaluation/num steps total                      3000\n",
      "evaluation/num paths total                        60\n",
      "evaluation/path length Mean                       50\n",
      "evaluation/path length Std                         0\n",
      "evaluation/path length Max                        50\n",
      "evaluation/path length Min                        50\n",
      "evaluation/Rewards Mean                           -1\n",
      "evaluation/Rewards Std                             0\n",
      "evaluation/Rewards Max                            -1\n",
      "evaluation/Rewards Min                            -1\n",
      "evaluation/Returns Mean                          -50\n",
      "evaluation/Returns Std                             0\n",
      "evaluation/Returns Max                           -50\n",
      "evaluation/Returns Min                           -50\n",
      "evaluation/Actions Mean                           -0.220682\n",
      "evaluation/Actions Std                             0.502438\n",
      "evaluation/Actions Max                             0.977451\n",
      "evaluation/Actions Min                            -0.97246\n",
      "evaluation/Num Paths                              10\n",
      "evaluation/Average Returns                       -50\n",
      "evaluation/env_infos/final/is_success Mean         0\n",
      "evaluation/env_infos/final/is_success Std          0\n",
      "evaluation/env_infos/final/is_success Max          0\n",
      "evaluation/env_infos/final/is_success Min          0\n",
      "evaluation/env_infos/initial/is_success Mean       0\n",
      "evaluation/env_infos/initial/is_success Std        0\n",
      "evaluation/env_infos/initial/is_success Max        0\n",
      "evaluation/env_infos/initial/is_success Min        0\n",
      "evaluation/env_infos/is_success Mean               0\n",
      "evaluation/env_infos/is_success Std                0\n",
      "evaluation/env_infos/is_success Max                0\n",
      "evaluation/env_infos/is_success Min                0\n",
      "time/data storing (s)                              1.07292\n",
      "time/evaluation sampling (s)                      38.627\n",
      "time/exploration sampling (s)                    760.314\n",
      "time/logging (s)                                   0.0282008\n",
      "time/sac training (s)                            199.975\n",
      "time/saving (s)                                    0.0139046\n",
      "time/training (s)                                  0.0070298\n",
      "time/epoch (s)                                  1000.04\n",
      "time/total (s)                                  8042.1\n",
      "Epoch                                              5\n",
      "---------------------------------------------  --------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 6\n",
      "\n",
      " Cycle 0 6\n",
      "Took to collect: 7.992031097412109\n",
      "Took to train: 6.416091680526733\n",
      "\n",
      " Cycle 1 6\n",
      "Took to collect: 6.981486558914185\n",
      "Took to train: 6.4388267993927\n",
      "\n",
      " Cycle 2 6\n",
      "Took to collect: 7.173452615737915\n",
      "Took to train: 6.4229841232299805\n",
      "\n",
      " Cycle 3 6\n",
      "Took to collect: 8.67429518699646\n",
      "Took to train: 6.451839208602905\n",
      "\n",
      " Cycle 4 6\n",
      "Took to collect: 7.901007413864136\n",
      "Took to train: 6.432514667510986\n",
      "\n",
      " Cycle 5 6\n",
      "Took to collect: 8.858726739883423\n",
      "Took to train: 6.406152248382568\n",
      "\n",
      " Cycle 6 6\n",
      "Took to collect: 8.236596584320068\n",
      "Took to train: 6.378308296203613\n",
      "\n",
      " Cycle 7 6\n",
      "Took to collect: 7.792206287384033\n",
      "Took to train: 6.381587982177734\n",
      "\n",
      " Cycle 8 6\n",
      "Took to collect: 7.404316663742065\n",
      "Took to train: 6.37483024597168\n",
      "\n",
      " Cycle 9 6\n",
      "Took to collect: 6.437479019165039\n",
      "Took to train: 6.377853155136108\n",
      "\n",
      " Cycle 10 6\n",
      "Took to collect: 6.468187570571899\n",
      "Took to train: 6.393282890319824\n",
      "\n",
      " Cycle 11 6\n",
      "Took to collect: 7.698132038116455\n",
      "Took to train: 6.507292985916138\n",
      "\n",
      " Cycle 12 6\n",
      "Took to collect: 8.246716260910034\n",
      "Took to train: 6.375765562057495\n",
      "\n",
      " Cycle 13 6\n",
      "Took to collect: 6.5497963428497314\n",
      "Took to train: 6.371809005737305\n",
      "\n",
      " Cycle 14 6\n",
      "Took to collect: 7.399265766143799\n",
      "Took to train: 6.395754814147949\n",
      "\n",
      " Cycle 15 6\n",
      "Took to collect: 7.551916599273682\n",
      "Took to train: 6.401050329208374\n",
      "\n",
      " Cycle 16 6\n",
      "Took to collect: 6.905200958251953\n",
      "Took to train: 6.41740870475769\n",
      "\n",
      " Cycle 17 6\n",
      "Took to collect: 9.048502445220947\n",
      "Took to train: 6.4682769775390625\n",
      "\n",
      " Cycle 18 6\n",
      "Took to collect: 8.525791883468628\n",
      "Took to train: 6.4236133098602295\n",
      "\n",
      " Cycle 19 6\n",
      "Took to collect: 6.984417200088501\n",
      "Took to train: 6.500321388244629\n",
      "\n",
      " Cycle 20 6\n",
      "Took to collect: 8.285517692565918\n",
      "Took to train: 6.387967348098755\n",
      "\n",
      " Cycle 21 6\n",
      "Took to collect: 7.189899921417236\n",
      "Took to train: 6.357616186141968\n",
      "\n",
      " Cycle 22 6\n",
      "Took to collect: 8.968242645263672\n",
      "Took to train: 6.35595178604126\n",
      "\n",
      " Cycle 23 6\n",
      "Took to collect: 7.954924821853638\n",
      "Took to train: 6.418604612350464\n",
      "\n",
      " Cycle 24 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 8.364529132843018\n",
      "Took to train: 6.427243709564209\n",
      "\n",
      " Cycle 25 6\n",
      "Took to collect: 8.255252599716187\n",
      "Took to train: 6.458320617675781\n",
      "\n",
      " Cycle 26 6\n",
      "Took to collect: 7.69274640083313\n",
      "Took to train: 6.433045148849487\n",
      "\n",
      " Cycle 27 6\n",
      "Took to collect: 8.426696062088013\n",
      "Took to train: 6.394248962402344\n",
      "\n",
      " Cycle 28 6\n",
      "Took to collect: 7.924075365066528\n",
      "Took to train: 6.392160177230835\n",
      "\n",
      " Cycle 29 6\n",
      "Took to collect: 7.787863492965698\n",
      "Took to train: 6.384238958358765\n",
      "\n",
      " Cycle 30 6\n",
      "Took to collect: 6.185301065444946\n",
      "Took to train: 6.394068956375122\n",
      "\n",
      " Cycle 31 6\n",
      "Took to collect: 8.925130844116211\n",
      "Took to train: 6.378125429153442\n",
      "\n",
      " Cycle 32 6\n",
      "Took to collect: 8.045480728149414\n",
      "Took to train: 6.388134956359863\n",
      "\n",
      " Cycle 33 6\n",
      "Took to collect: 6.863437175750732\n",
      "Took to train: 6.273620367050171\n",
      "\n",
      " Cycle 34 6\n",
      "Took to collect: 8.999557733535767\n",
      "Took to train: 6.2980828285217285\n",
      "\n",
      " Cycle 35 6\n",
      "Took to collect: 9.055666446685791\n",
      "Took to train: 6.299675226211548\n",
      "\n",
      " Cycle 36 6\n",
      "Took to collect: 7.861929178237915\n",
      "Took to train: 6.385915040969849\n",
      "\n",
      " Cycle 37 6\n",
      "Took to collect: 7.341236591339111\n",
      "Took to train: 6.406727075576782\n",
      "\n",
      " Cycle 38 6\n",
      "Took to collect: 9.569497108459473\n",
      "Took to train: 6.3794472217559814\n",
      "\n",
      " Cycle 39 6\n",
      "Took to collect: 8.145233154296875\n",
      "Took to train: 6.440536260604858\n",
      "\n",
      " Cycle 40 6\n",
      "Took to collect: 7.36961555480957\n",
      "Took to train: 6.396048069000244\n",
      "\n",
      " Cycle 41 6\n",
      "Took to collect: 7.384006023406982\n",
      "Took to train: 6.39502215385437\n",
      "\n",
      " Cycle 42 6\n",
      "Took to collect: 7.10423731803894\n",
      "Took to train: 6.38669490814209\n",
      "\n",
      " Cycle 43 6\n",
      "Took to collect: 7.4154791831970215\n",
      "Took to train: 6.395020961761475\n",
      "\n",
      " Cycle 44 6\n",
      "Took to collect: 8.034266948699951\n",
      "Took to train: 6.392560005187988\n",
      "\n",
      " Cycle 45 6\n",
      "Took to collect: 7.930955648422241\n",
      "Took to train: 6.391659736633301\n",
      "\n",
      " Cycle 46 6\n",
      "Took to collect: 8.803845882415771\n",
      "Took to train: 6.452202796936035\n",
      "\n",
      " Cycle 47 6\n",
      "Took to collect: 6.254211664199829\n",
      "Took to train: 6.4017791748046875\n",
      "\n",
      " Cycle 48 6\n",
      "Took to collect: 9.307774066925049\n",
      "Took to train: 6.286587238311768\n",
      "\n",
      " Cycle 49 6\n",
      "Took to collect: 5.97675633430481\n",
      "Took to train: 6.258096933364868\n",
      "\n",
      " Cycle 50 6\n",
      "Took to collect: 6.839998483657837\n",
      "Took to train: 6.413672685623169\n",
      "\n",
      " Cycle 51 6\n",
      "Took to collect: 8.420477151870728\n",
      "Took to train: 6.416489601135254\n",
      "\n",
      " Cycle 52 6\n",
      "Took to collect: 7.986804723739624\n",
      "Took to train: 6.365654468536377\n",
      "\n",
      " Cycle 53 6\n",
      "Took to collect: 6.070645809173584\n",
      "Took to train: 6.448562383651733\n",
      "\n",
      " Cycle 54 6\n",
      "Took to collect: 7.375694513320923\n",
      "Took to train: 6.396328687667847\n",
      "\n",
      " Cycle 55 6\n",
      "Took to collect: 9.660754442214966\n",
      "Took to train: 6.375004529953003\n",
      "\n",
      " Cycle 56 6\n",
      "Took to collect: 7.758314609527588\n",
      "Took to train: 6.416722297668457\n",
      "\n",
      " Cycle 57 6\n",
      "Took to collect: 7.530639410018921\n",
      "Took to train: 6.43152117729187\n",
      "\n",
      " Cycle 58 6\n",
      "Took to collect: 8.676175355911255\n",
      "Took to train: 6.318890333175659\n",
      "\n",
      " Cycle 59 6\n",
      "Took to collect: 8.449100971221924\n",
      "Took to train: 6.28095006942749\n",
      "\n",
      " Cycle 60 6\n",
      "Took to collect: 7.697660446166992\n",
      "Took to train: 6.274949312210083\n",
      "\n",
      " Cycle 61 6\n",
      "Took to collect: 7.791023254394531\n",
      "Took to train: 6.269256353378296\n",
      "\n",
      " Cycle 62 6\n",
      "Took to collect: 8.049760103225708\n",
      "Took to train: 6.271551609039307\n",
      "\n",
      " Cycle 63 6\n",
      "Took to collect: 6.565606594085693\n",
      "Took to train: 6.272707462310791\n",
      "\n",
      " Cycle 64 6\n",
      "Took to collect: 7.122116565704346\n",
      "Took to train: 6.299015283584595\n",
      "\n",
      " Cycle 65 6\n",
      "Took to collect: 7.732079982757568\n",
      "Took to train: 6.340495347976685\n",
      "\n",
      " Cycle 66 6\n",
      "Took to collect: 8.166586875915527\n",
      "Took to train: 6.292050361633301\n",
      "\n",
      " Cycle 67 6\n",
      "Took to collect: 8.067317247390747\n",
      "Took to train: 6.452777862548828\n",
      "\n",
      " Cycle 68 6\n",
      "Took to collect: 6.818335771560669\n",
      "Took to train: 6.483533620834351\n",
      "\n",
      " Cycle 69 6\n",
      "Took to collect: 7.637597560882568\n",
      "Took to train: 6.469776391983032\n",
      "\n",
      " Cycle 70 6\n",
      "Took to collect: 4.80643630027771\n",
      "Took to train: 6.3787665367126465\n",
      "\n",
      " Cycle 71 6\n",
      "Took to collect: 7.7934534549713135\n",
      "Took to train: 6.466832637786865\n",
      "\n",
      " Cycle 72 6\n",
      "Took to collect: 7.92505669593811\n",
      "Took to train: 6.452820539474487\n",
      "\n",
      " Cycle 73 6\n",
      "Took to collect: 6.577316761016846\n",
      "Took to train: 6.393436908721924\n",
      "\n",
      " Cycle 74 6\n",
      "Took to collect: 9.082198143005371\n",
      "Took to train: 6.4126551151275635\n",
      "\n",
      " Cycle 75 6\n",
      "Took to collect: 7.036890745162964\n",
      "Took to train: 6.429104804992676\n",
      "\n",
      " Cycle 76 6\n",
      "Took to collect: 6.858139753341675\n",
      "Took to train: 6.444385528564453\n",
      "\n",
      " Cycle 77 6\n",
      "Took to collect: 7.617233753204346\n",
      "Took to train: 6.436057806015015\n",
      "\n",
      " Cycle 78 6\n",
      "Took to collect: 8.304651975631714\n",
      "Took to train: 6.426744699478149\n",
      "\n",
      " Cycle 79 6\n",
      "Took to collect: 7.448323488235474\n",
      "Took to train: 6.445425748825073\n",
      "\n",
      " Cycle 80 6\n",
      "Took to collect: 8.10738205909729\n",
      "Took to train: 6.371456861495972\n",
      "\n",
      " Cycle 81 6\n",
      "Took to collect: 7.109836101531982\n",
      "Took to train: 6.366287469863892\n",
      "\n",
      " Cycle 82 6\n",
      "Took to collect: 7.582014322280884\n",
      "Took to train: 6.442570686340332\n",
      "\n",
      " Cycle 83 6\n",
      "Took to collect: 6.603559494018555\n",
      "Took to train: 6.4186179637908936\n",
      "\n",
      " Cycle 84 6\n",
      "Took to collect: 7.1104958057403564\n",
      "Took to train: 6.445430278778076\n",
      "\n",
      " Cycle 85 6\n",
      "Took to collect: 8.281033992767334\n",
      "Took to train: 6.44747257232666\n",
      "\n",
      " Cycle 86 6\n",
      "Took to collect: 7.767341136932373\n",
      "Took to train: 6.37351655960083\n",
      "\n",
      " Cycle 87 6\n",
      "Took to collect: 7.109874725341797\n",
      "Took to train: 6.268151521682739\n",
      "\n",
      " Cycle 88 6\n",
      "Took to collect: 8.164931774139404\n",
      "Took to train: 6.213547229766846\n",
      "\n",
      " Cycle 89 6\n",
      "Took to collect: 5.027937889099121\n",
      "Took to train: 6.396538257598877\n",
      "\n",
      " Cycle 90 6\n",
      "Took to collect: 6.660926580429077\n",
      "Took to train: 6.449709892272949\n",
      "\n",
      " Cycle 91 6\n",
      "Took to collect: 6.60181999206543\n",
      "Took to train: 6.437920808792114\n",
      "\n",
      " Cycle 92 6\n",
      "Took to collect: 9.162960529327393\n",
      "Took to train: 6.416121006011963\n",
      "\n",
      " Cycle 93 6\n",
      "Took to collect: 6.498483896255493\n",
      "Took to train: 6.408534049987793\n",
      "\n",
      " Cycle 94 6\n",
      "Took to collect: 6.587180852890015\n",
      "Took to train: 6.426462173461914\n",
      "\n",
      " Cycle 95 6\n",
      "Took to collect: 6.108747959136963\n",
      "Took to train: 6.393831014633179\n",
      "\n",
      " Cycle 96 6\n",
      "Took to collect: 5.079291343688965\n",
      "Took to train: 6.4027979373931885\n",
      "\n",
      " Cycle 97 6\n",
      "Took to collect: 5.257115125656128\n",
      "Took to train: 6.456566572189331\n",
      "\n",
      " Cycle 98 6\n",
      "Took to collect: 8.390328645706177\n",
      "Took to train: 6.4567835330963135\n",
      "\n",
      " Cycle 99 6\n",
      "Took to collect: 6.185102701187134\n",
      "Took to train: 6.377596378326416\n",
      "Time collect avg cycle: 7.575156478881836\n",
      "Time train avg cycle: 6.39291020154953\n",
      "Total avg cycle: 13.97919042110443\n",
      "Ending epoch\n",
      "2020-10-26 00:16:48.234585 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 6 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  --------------\n",
      "trainer/num train calls                            0\n",
      "trainer/QF1 Loss                                   0.319898\n",
      "trainer/QF2 Loss                                   0.40745\n",
      "trainer/Policy Loss                               48.2656\n",
      "trainer/Q1 Predictions Mean                      -48.3803\n",
      "trainer/Q1 Predictions Std                        29.8622\n",
      "trainer/Q1 Predictions Max                         4.12948\n",
      "trainer/Q1 Predictions Min                       -92.0997\n",
      "trainer/Q2 Predictions Mean                      -48.0901\n",
      "trainer/Q2 Predictions Std                        29.9004\n",
      "trainer/Q2 Predictions Max                         4.838\n",
      "trainer/Q2 Predictions Min                       -92.115\n",
      "trainer/Q Targets Mean                           -48.3268\n",
      "trainer/Q Targets Std                             29.8881\n",
      "trainer/Q Targets Max                              4.16481\n",
      "trainer/Q Targets Min                            -92.1738\n",
      "trainer/Log Pis Mean                               2.77032\n",
      "trainer/Log Pis Std                                2.34703\n",
      "trainer/Log Pis Max                                8.21324\n",
      "trainer/Log Pis Min                               -4.38848\n",
      "trainer/policy/mean Mean                          -0.361439\n",
      "trainer/policy/mean Std                            0.635191\n",
      "trainer/policy/mean Max                            0.996605\n",
      "trainer/policy/mean Min                           -0.993814\n",
      "trainer/policy/normal/std Mean                     0.362145\n",
      "trainer/policy/normal/std Std                      0.188401\n",
      "trainer/policy/normal/std Max                      1.02058\n",
      "trainer/policy/normal/std Min                      0.0759844\n",
      "trainer/policy/normal/log_std Mean                -1.17473\n",
      "trainer/policy/normal/log_std Std                  0.593735\n",
      "trainer/policy/normal/log_std Max                  0.0203672\n",
      "trainer/policy/normal/log_std Min                 -2.57723\n",
      "trainer/Alpha                                      0.0135363\n",
      "trainer/Alpha Loss                                -0.988162\n",
      "exploration/num steps total                    71000\n",
      "exploration/num paths total                     1420\n",
      "exploration/path length Mean                      50\n",
      "exploration/path length Std                        0\n",
      "exploration/path length Max                       50\n",
      "exploration/path length Min                       50\n",
      "exploration/Rewards Mean                          -1\n",
      "exploration/Rewards Std                            0\n",
      "exploration/Rewards Max                           -1\n",
      "exploration/Rewards Min                           -1\n",
      "exploration/Returns Mean                         -50\n",
      "exploration/Returns Std                            0\n",
      "exploration/Returns Max                          -50\n",
      "exploration/Returns Min                          -50\n",
      "exploration/Actions Mean                          -0.263053\n",
      "exploration/Actions Std                            0.615526\n",
      "exploration/Actions Max                            0.999967\n",
      "exploration/Actions Min                           -0.999598\n",
      "exploration/Num Paths                            200\n",
      "exploration/Average Returns                      -50\n",
      "exploration/env_infos/final/is_success Mean        0\n",
      "exploration/env_infos/final/is_success Std         0\n",
      "exploration/env_infos/final/is_success Max         0\n",
      "exploration/env_infos/final/is_success Min         0\n",
      "exploration/env_infos/initial/is_success Mean      0\n",
      "exploration/env_infos/initial/is_success Std       0\n",
      "exploration/env_infos/initial/is_success Max       0\n",
      "exploration/env_infos/initial/is_success Min       0\n",
      "exploration/env_infos/is_success Mean              0\n",
      "exploration/env_infos/is_success Std               0\n",
      "exploration/env_infos/is_success Max               0\n",
      "exploration/env_infos/is_success Min               0\n",
      "evaluation/num steps total                      3500\n",
      "evaluation/num paths total                        70\n",
      "evaluation/path length Mean                       50\n",
      "evaluation/path length Std                         0\n",
      "evaluation/path length Max                        50\n",
      "evaluation/path length Min                        50\n",
      "evaluation/Rewards Mean                           -1\n",
      "evaluation/Rewards Std                             0\n",
      "evaluation/Rewards Max                            -1\n",
      "evaluation/Rewards Min                            -1\n",
      "evaluation/Returns Mean                          -50\n",
      "evaluation/Returns Std                             0\n",
      "evaluation/Returns Max                           -50\n",
      "evaluation/Returns Min                           -50\n",
      "evaluation/Actions Mean                           -0.257335\n",
      "evaluation/Actions Std                             0.556726\n",
      "evaluation/Actions Max                             0.970226\n",
      "evaluation/Actions Min                            -0.979395\n",
      "evaluation/Num Paths                              10\n",
      "evaluation/Average Returns                       -50\n",
      "evaluation/env_infos/final/is_success Mean         0\n",
      "evaluation/env_infos/final/is_success Std          0\n",
      "evaluation/env_infos/final/is_success Max          0\n",
      "evaluation/env_infos/final/is_success Min          0\n",
      "evaluation/env_infos/initial/is_success Mean       0\n",
      "evaluation/env_infos/initial/is_success Std        0\n",
      "evaluation/env_infos/initial/is_success Max        0\n",
      "evaluation/env_infos/initial/is_success Min        0\n",
      "evaluation/env_infos/is_success Mean               0\n",
      "evaluation/env_infos/is_success Std                0\n",
      "evaluation/env_infos/is_success Max                0\n",
      "evaluation/env_infos/is_success Min                0\n",
      "time/data storing (s)                              1.08656\n",
      "time/evaluation sampling (s)                      44.037\n",
      "time/exploration sampling (s)                    757.535\n",
      "time/logging (s)                                   0.0271405\n",
      "time/sac training (s)                            200.037\n",
      "time/saving (s)                                    0.0138959\n",
      "time/training (s)                                  0.00708806\n",
      "time/epoch (s)                                  1002.74\n",
      "time/total (s)                                  9483.92\n",
      "Epoch                                              6\n",
      "---------------------------------------------  --------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 7\n",
      "\n",
      " Cycle 0 7\n",
      "Took to collect: 8.224472522735596\n",
      "Took to train: 6.361845254898071\n",
      "\n",
      " Cycle 1 7\n",
      "Took to collect: 7.762125492095947\n",
      "Took to train: 6.267694711685181\n",
      "\n",
      " Cycle 2 7\n",
      "Took to collect: 7.625533819198608\n",
      "Took to train: 6.2167723178863525\n",
      "\n",
      " Cycle 3 7\n",
      "Took to collect: 6.602720499038696\n",
      "Took to train: 6.246254205703735\n",
      "\n",
      " Cycle 4 7\n",
      "Took to collect: 7.874759197235107\n",
      "Took to train: 6.240511417388916\n",
      "\n",
      " Cycle 5 7\n",
      "Took to collect: 6.442364454269409\n",
      "Took to train: 6.334553241729736\n",
      "\n",
      " Cycle 6 7\n",
      "Took to collect: 8.705546855926514\n",
      "Took to train: 6.304264068603516\n",
      "\n",
      " Cycle 7 7\n",
      "Took to collect: 6.575777530670166\n",
      "Took to train: 6.265427827835083\n",
      "\n",
      " Cycle 8 7\n",
      "Took to collect: 7.370816469192505\n",
      "Took to train: 6.209517955780029\n",
      "\n",
      " Cycle 9 7\n",
      "Took to collect: 8.092352867126465\n",
      "Took to train: 6.193127632141113\n",
      "\n",
      " Cycle 10 7\n",
      "Took to collect: 7.394428253173828\n",
      "Took to train: 6.185221910476685\n",
      "\n",
      " Cycle 11 7\n",
      "Took to collect: 8.929436445236206\n",
      "Took to train: 6.202918291091919\n",
      "\n",
      " Cycle 12 7\n",
      "Took to collect: 6.650039434432983\n",
      "Took to train: 6.276580333709717\n",
      "\n",
      " Cycle 13 7\n",
      "Took to collect: 5.2943291664123535\n",
      "Took to train: 6.223061800003052\n",
      "\n",
      " Cycle 14 7\n",
      "Took to collect: 7.476410388946533\n",
      "Took to train: 6.2833192348480225\n",
      "\n",
      " Cycle 15 7\n",
      "Took to collect: 6.2913689613342285\n",
      "Took to train: 6.208313941955566\n",
      "\n",
      " Cycle 16 7\n",
      "Took to collect: 7.945938587188721\n",
      "Took to train: 6.306375026702881\n",
      "\n",
      " Cycle 17 7\n",
      "Took to collect: 6.18467116355896\n",
      "Took to train: 6.360175132751465\n",
      "\n",
      " Cycle 18 7\n",
      "Took to collect: 5.540203809738159\n",
      "Took to train: 6.372526407241821\n",
      "\n",
      " Cycle 19 7\n",
      "Took to collect: 7.4150238037109375\n",
      "Took to train: 6.314117193222046\n",
      "\n",
      " Cycle 20 7\n",
      "Took to collect: 5.9886109828948975\n",
      "Took to train: 6.341894626617432\n",
      "\n",
      " Cycle 21 7\n",
      "Took to collect: 6.974708318710327\n",
      "Took to train: 6.339233160018921\n",
      "\n",
      " Cycle 22 7\n",
      "Took to collect: 5.614419937133789\n",
      "Took to train: 6.36643385887146\n",
      "\n",
      " Cycle 23 7\n",
      "Took to collect: 7.784879446029663\n",
      "Took to train: 6.297103404998779\n",
      "\n",
      " Cycle 24 7\n",
      "Took to collect: 4.912960529327393\n",
      "Took to train: 6.2783708572387695\n",
      "\n",
      " Cycle 25 7\n",
      "Took to collect: 7.11913275718689\n",
      "Took to train: 6.1923136711120605\n",
      "\n",
      " Cycle 26 7\n",
      "Took to collect: 6.6046812534332275\n",
      "Took to train: 6.207155704498291\n",
      "\n",
      " Cycle 27 7\n",
      "Took to collect: 6.5280327796936035\n",
      "Took to train: 6.277996301651001\n",
      "\n",
      " Cycle 28 7\n",
      "Took to collect: 3.2905349731445312\n",
      "Took to train: 6.296566009521484\n",
      "\n",
      " Cycle 29 7\n",
      "Took to collect: 6.1383514404296875\n",
      "Took to train: 6.287477731704712\n",
      "\n",
      " Cycle 30 7\n",
      "Took to collect: 6.066607475280762\n",
      "Took to train: 6.354992389678955\n",
      "\n",
      " Cycle 31 7\n",
      "Took to collect: 8.909741163253784\n",
      "Took to train: 6.365523099899292\n",
      "\n",
      " Cycle 32 7\n",
      "Took to collect: 8.085952281951904\n",
      "Took to train: 6.3583714962005615\n",
      "\n",
      " Cycle 33 7\n",
      "Took to collect: 5.964402437210083\n",
      "Took to train: 6.2414233684539795\n",
      "\n",
      " Cycle 34 7\n",
      "Took to collect: 5.040406227111816\n",
      "Took to train: 6.3263185024261475\n",
      "\n",
      " Cycle 35 7\n",
      "Took to collect: 6.630462169647217\n",
      "Took to train: 6.35931134223938\n",
      "\n",
      " Cycle 36 7\n",
      "Took to collect: 7.3684282302856445\n",
      "Took to train: 6.31743049621582\n",
      "\n",
      " Cycle 37 7\n",
      "Took to collect: 6.890875816345215\n",
      "Took to train: 6.3257622718811035\n",
      "\n",
      " Cycle 38 7\n",
      "Took to collect: 4.635265588760376\n",
      "Took to train: 6.356563091278076\n",
      "\n",
      " Cycle 39 7\n",
      "Took to collect: 7.0254738330841064\n",
      "Took to train: 6.342843770980835\n",
      "\n",
      " Cycle 40 7\n",
      "Took to collect: 7.122303009033203\n",
      "Took to train: 6.335975408554077\n",
      "\n",
      " Cycle 41 7\n",
      "Took to collect: 6.171095371246338\n",
      "Took to train: 6.343797922134399\n",
      "\n",
      " Cycle 42 7\n",
      "Took to collect: 6.628609895706177\n",
      "Took to train: 6.313528537750244\n",
      "\n",
      " Cycle 43 7\n",
      "Took to collect: 4.938604354858398\n",
      "Took to train: 6.343287229537964\n",
      "\n",
      " Cycle 44 7\n",
      "Took to collect: 3.238133430480957\n",
      "Took to train: 6.303958415985107\n",
      "\n",
      " Cycle 45 7\n",
      "Took to collect: 6.700636148452759\n",
      "Took to train: 6.301605224609375\n",
      "\n",
      " Cycle 46 7\n",
      "Took to collect: 6.8194921016693115\n",
      "Took to train: 6.331194877624512\n",
      "\n",
      " Cycle 47 7\n",
      "Took to collect: 6.521725416183472\n",
      "Took to train: 6.33332371711731\n",
      "\n",
      " Cycle 48 7\n",
      "Took to collect: 4.703614234924316\n",
      "Took to train: 6.330127477645874\n",
      "\n",
      " Cycle 49 7\n",
      "Took to collect: 6.552263259887695\n",
      "Took to train: 6.349791049957275\n",
      "\n",
      " Cycle 50 7\n",
      "Took to collect: 7.041991233825684\n",
      "Took to train: 6.320626497268677\n",
      "\n",
      " Cycle 51 7\n",
      "Took to collect: 4.71527624130249\n",
      "Took to train: 6.281231880187988\n",
      "\n",
      " Cycle 52 7\n",
      "Took to collect: 6.652664661407471\n",
      "Took to train: 6.273682355880737\n",
      "\n",
      " Cycle 53 7\n",
      "Took to collect: 5.087019681930542\n",
      "Took to train: 6.280383348464966\n",
      "\n",
      " Cycle 54 7\n",
      "Took to collect: 8.016819953918457\n",
      "Took to train: 6.3331310749053955\n",
      "\n",
      " Cycle 55 7\n",
      "Took to collect: 5.71934175491333\n",
      "Took to train: 6.338347911834717\n",
      "\n",
      " Cycle 56 7\n",
      "Took to collect: 6.744952440261841\n",
      "Took to train: 6.328117847442627\n",
      "\n",
      " Cycle 57 7\n",
      "Took to collect: 5.254674673080444\n",
      "Took to train: 6.276157855987549\n",
      "\n",
      " Cycle 58 7\n",
      "Took to collect: 4.926940202713013\n",
      "Took to train: 6.322787523269653\n",
      "\n",
      " Cycle 59 7\n",
      "Took to collect: 6.129875421524048\n",
      "Took to train: 6.247807264328003\n",
      "\n",
      " Cycle 60 7\n",
      "Took to collect: 3.762327194213867\n",
      "Took to train: 6.227832794189453\n",
      "\n",
      " Cycle 61 7\n",
      "Took to collect: 5.618285655975342\n",
      "Took to train: 6.276142597198486\n",
      "\n",
      " Cycle 62 7\n",
      "Took to collect: 6.026475191116333\n",
      "Took to train: 6.2080254554748535\n",
      "\n",
      " Cycle 63 7\n",
      "Took to collect: 4.876703977584839\n",
      "Took to train: 6.262538909912109\n",
      "\n",
      " Cycle 64 7\n",
      "Took to collect: 4.005597114562988\n",
      "Took to train: 6.276209592819214\n",
      "\n",
      " Cycle 65 7\n",
      "Took to collect: 3.1567864418029785\n",
      "Took to train: 6.2782135009765625\n",
      "\n",
      " Cycle 66 7\n",
      "Took to collect: 3.7562880516052246\n",
      "Took to train: 6.331311464309692\n",
      "\n",
      " Cycle 67 7\n",
      "Took to collect: 5.766160249710083\n",
      "Took to train: 6.199180364608765\n",
      "\n",
      " Cycle 68 7\n",
      "Took to collect: 3.0170514583587646\n",
      "Took to train: 6.1917243003845215\n",
      "\n",
      " Cycle 69 7\n",
      "Took to collect: 3.8813741207122803\n",
      "Took to train: 6.183427333831787\n",
      "\n",
      " Cycle 70 7\n",
      "Took to collect: 6.100248098373413\n",
      "Took to train: 6.305280685424805\n",
      "\n",
      " Cycle 71 7\n",
      "Took to collect: 6.327347040176392\n",
      "Took to train: 6.350268602371216\n",
      "\n",
      " Cycle 72 7\n",
      "Took to collect: 7.180152177810669\n",
      "Took to train: 6.3025712966918945\n",
      "\n",
      " Cycle 73 7\n",
      "Took to collect: 4.97333288192749\n",
      "Took to train: 6.273403882980347\n",
      "\n",
      " Cycle 74 7\n",
      "Took to collect: 6.267101287841797\n",
      "Took to train: 6.2820000648498535\n",
      "\n",
      " Cycle 75 7\n",
      "Took to collect: 5.50296425819397\n",
      "Took to train: 6.189791202545166\n",
      "\n",
      " Cycle 76 7\n",
      "Took to collect: 8.787550210952759\n",
      "Took to train: 6.182195663452148\n",
      "\n",
      " Cycle 77 7\n",
      "Took to collect: 8.4765145778656\n",
      "Took to train: 6.280523300170898\n",
      "\n",
      " Cycle 78 7\n",
      "Took to collect: 7.8487536907196045\n",
      "Took to train: 6.299731254577637\n",
      "\n",
      " Cycle 79 7\n",
      "Took to collect: 2.829479217529297\n",
      "Took to train: 6.310894966125488\n",
      "\n",
      " Cycle 80 7\n",
      "Took to collect: 4.9314634799957275\n",
      "Took to train: 6.293944835662842\n",
      "\n",
      " Cycle 81 7\n",
      "Took to collect: 6.25941276550293\n",
      "Took to train: 6.260670185089111\n",
      "\n",
      " Cycle 82 7\n",
      "Took to collect: 7.451397895812988\n",
      "Took to train: 6.325002908706665\n",
      "\n",
      " Cycle 83 7\n",
      "Took to collect: 6.6169114112854\n",
      "Took to train: 6.244243144989014\n",
      "\n",
      " Cycle 84 7\n",
      "Took to collect: 7.136091470718384\n",
      "Took to train: 6.166006088256836\n",
      "\n",
      " Cycle 85 7\n",
      "Took to collect: 6.6203086376190186\n",
      "Took to train: 6.177310228347778\n",
      "\n",
      " Cycle 86 7\n",
      "Took to collect: 4.9602484703063965\n",
      "Took to train: 6.13440728187561\n",
      "\n",
      " Cycle 87 7\n",
      "Took to collect: 6.816290616989136\n",
      "Took to train: 6.259592294692993\n",
      "\n",
      " Cycle 88 7\n",
      "Took to collect: 6.804252862930298\n",
      "Took to train: 6.2674336433410645\n",
      "\n",
      " Cycle 89 7\n",
      "Took to collect: 5.89417839050293\n",
      "Took to train: 6.248954772949219\n",
      "\n",
      " Cycle 90 7\n",
      "Took to collect: 6.774164199829102\n",
      "Took to train: 6.2557549476623535\n",
      "\n",
      " Cycle 91 7\n",
      "Took to collect: 5.4923951625823975\n",
      "Took to train: 6.246506452560425\n",
      "\n",
      " Cycle 92 7\n",
      "Took to collect: 4.805170297622681\n",
      "Took to train: 6.268762588500977\n",
      "\n",
      " Cycle 93 7\n",
      "Took to collect: 5.177729606628418\n",
      "Took to train: 6.241857051849365\n",
      "\n",
      " Cycle 94 7\n",
      "Took to collect: 5.487353324890137\n",
      "Took to train: 6.289823532104492\n",
      "\n",
      " Cycle 95 7\n",
      "Took to collect: 4.627438545227051\n",
      "Took to train: 6.289901971817017\n",
      "\n",
      " Cycle 96 7\n",
      "Took to collect: 7.225376605987549\n",
      "Took to train: 6.439889430999756\n",
      "\n",
      " Cycle 97 7\n",
      "Took to collect: 6.234557151794434\n",
      "Took to train: 6.447311162948608\n",
      "\n",
      " Cycle 98 7\n",
      "Took to collect: 6.61755108833313\n",
      "Took to train: 6.431554079055786\n",
      "\n",
      " Cycle 99 7\n",
      "Took to collect: 5.581820726394653\n",
      "Took to train: 6.42568039894104\n",
      "Time collect avg cycle: 6.213328864574432\n",
      "Time train avg cycle: 6.288204007148742\n",
      "Total avg cycle: 12.5123961687088\n",
      "Ending epoch\n",
      "2020-10-26 00:38:13.089401 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 7 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged tensorboard\n",
      "---------------------------------------------  --------------\n",
      "trainer/num train calls                            0\n",
      "trainer/QF1 Loss                                   0.511526\n",
      "trainer/QF2 Loss                                   0.414453\n",
      "trainer/Policy Loss                               52.0567\n",
      "trainer/Q1 Predictions Mean                      -52.1023\n",
      "trainer/Q1 Predictions Std                        29.1551\n",
      "trainer/Q1 Predictions Max                         4.77077\n",
      "trainer/Q1 Predictions Min                       -95.4185\n",
      "trainer/Q2 Predictions Mean                      -52.1463\n",
      "trainer/Q2 Predictions Std                        29.0714\n",
      "trainer/Q2 Predictions Max                         4.70336\n",
      "trainer/Q2 Predictions Min                       -95.3156\n",
      "trainer/Q Targets Mean                           -52.3826\n",
      "trainer/Q Targets Std                             29.1369\n",
      "trainer/Q Targets Max                              4.4835\n",
      "trainer/Q Targets Min                            -95.8393\n",
      "trainer/Log Pis Mean                               2.9872\n",
      "trainer/Log Pis Std                                1.96318\n",
      "trainer/Log Pis Max                                8.37665\n",
      "trainer/Log Pis Min                               -4.2247\n",
      "trainer/policy/mean Mean                          -0.321969\n",
      "trainer/policy/mean Std                            0.630015\n",
      "trainer/policy/mean Max                            0.9916\n",
      "trainer/policy/mean Min                           -0.992068\n",
      "trainer/policy/normal/std Mean                     0.339168\n",
      "trainer/policy/normal/std Std                      0.196602\n",
      "trainer/policy/normal/std Max                      1.24152\n",
      "trainer/policy/normal/std Min                      0.0628477\n",
      "trainer/policy/normal/log_std Mean                -1.28064\n",
      "trainer/policy/normal/log_std Std                  0.668597\n",
      "trainer/policy/normal/log_std Max                  0.216333\n",
      "trainer/policy/normal/log_std Min                 -2.76704\n",
      "trainer/Alpha                                      0.01369\n",
      "trainer/Alpha Loss                                -0.054905\n",
      "exploration/num steps total                    81000\n",
      "exploration/num paths total                     1620\n",
      "exploration/path length Mean                      50\n",
      "exploration/path length Std                        0\n",
      "exploration/path length Max                       50\n",
      "exploration/path length Min                       50\n",
      "exploration/Rewards Mean                          -1\n",
      "exploration/Rewards Std                            0\n",
      "exploration/Rewards Max                           -1\n",
      "exploration/Rewards Min                           -1\n",
      "exploration/Returns Mean                         -50\n",
      "exploration/Returns Std                            0\n",
      "exploration/Returns Max                          -50\n",
      "exploration/Returns Min                          -50\n",
      "exploration/Actions Mean                          -0.21587\n",
      "exploration/Actions Std                            0.607666\n",
      "exploration/Actions Max                            0.99977\n",
      "exploration/Actions Min                           -0.999396\n",
      "exploration/Num Paths                            200\n",
      "exploration/Average Returns                      -50\n",
      "exploration/env_infos/final/is_success Mean        0\n",
      "exploration/env_infos/final/is_success Std         0\n",
      "exploration/env_infos/final/is_success Max         0\n",
      "exploration/env_infos/final/is_success Min         0\n",
      "exploration/env_infos/initial/is_success Mean      0\n",
      "exploration/env_infos/initial/is_success Std       0\n",
      "exploration/env_infos/initial/is_success Max       0\n",
      "exploration/env_infos/initial/is_success Min       0\n",
      "exploration/env_infos/is_success Mean              0\n",
      "exploration/env_infos/is_success Std               0\n",
      "exploration/env_infos/is_success Max               0\n",
      "exploration/env_infos/is_success Min               0\n",
      "evaluation/num steps total                      4000\n",
      "evaluation/num paths total                        80\n",
      "evaluation/path length Mean                       50\n",
      "evaluation/path length Std                         0\n",
      "evaluation/path length Max                        50\n",
      "evaluation/path length Min                        50\n",
      "evaluation/Rewards Mean                           -1\n",
      "evaluation/Rewards Std                             0\n",
      "evaluation/Rewards Max                            -1\n",
      "evaluation/Rewards Min                            -1\n",
      "evaluation/Returns Mean                          -50\n",
      "evaluation/Returns Std                             0\n",
      "evaluation/Returns Max                           -50\n",
      "evaluation/Returns Min                           -50\n",
      "evaluation/Actions Mean                           -0.266816\n",
      "evaluation/Actions Std                             0.595472\n",
      "evaluation/Actions Max                             0.959116\n",
      "evaluation/Actions Min                            -0.973745\n",
      "evaluation/Num Paths                              10\n",
      "evaluation/Average Returns                       -50\n",
      "evaluation/env_infos/final/is_success Mean         0\n",
      "evaluation/env_infos/final/is_success Std          0\n",
      "evaluation/env_infos/final/is_success Max          0\n",
      "evaluation/env_infos/final/is_success Min          0\n",
      "evaluation/env_infos/initial/is_success Mean       0\n",
      "evaluation/env_infos/initial/is_success Std        0\n",
      "evaluation/env_infos/initial/is_success Max        0\n",
      "evaluation/env_infos/initial/is_success Min        0\n",
      "evaluation/env_infos/is_success Mean               0\n",
      "evaluation/env_infos/is_success Std                0\n",
      "evaluation/env_infos/is_success Max                0\n",
      "evaluation/env_infos/is_success Min                0\n",
      "time/data storing (s)                              1.06058\n",
      "time/evaluation sampling (s)                      33.5528\n",
      "time/exploration sampling (s)                    621.352\n",
      "time/logging (s)                                   0.027552\n",
      "time/sac training (s)                            199.585\n",
      "time/saving (s)                                    0.0140254\n",
      "time/training (s)                                  0.00698527\n",
      "time/epoch (s)                                   855.599\n",
      "time/total (s)                                 10768.6\n",
      "Epoch                                              7\n",
      "---------------------------------------------  --------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 8\n",
      "\n",
      " Cycle 0 8\n",
      "Took to collect: 5.657307386398315\n",
      "Took to train: 6.380004644393921\n",
      "\n",
      " Cycle 1 8\n",
      "Took to collect: 5.903614282608032\n",
      "Took to train: 6.262122869491577\n",
      "\n",
      " Cycle 2 8\n",
      "Took to collect: 7.331869840621948\n",
      "Took to train: 6.410474538803101\n",
      "\n",
      " Cycle 3 8\n",
      "Took to collect: 6.916329383850098\n",
      "Took to train: 6.446635007858276\n",
      "\n",
      " Cycle 4 8\n",
      "Took to collect: 7.762207508087158\n",
      "Took to train: 6.445937395095825\n",
      "\n",
      " Cycle 5 8\n",
      "Took to collect: 5.349001884460449\n",
      "Took to train: 6.443307399749756\n",
      "\n",
      " Cycle 6 8\n",
      "Took to collect: 7.144917011260986\n",
      "Took to train: 6.306459665298462\n",
      "\n",
      " Cycle 7 8\n",
      "Took to collect: 6.797327280044556\n",
      "Took to train: 6.439741849899292\n",
      "\n",
      " Cycle 8 8\n",
      "Took to collect: 5.417027473449707\n",
      "Took to train: 6.413382291793823\n",
      "\n",
      " Cycle 9 8\n",
      "Took to collect: 5.606420516967773\n",
      "Took to train: 6.475744247436523\n",
      "\n",
      " Cycle 10 8\n",
      "Took to collect: 6.4753429889678955\n",
      "Took to train: 6.473606824874878\n",
      "\n",
      " Cycle 11 8\n",
      "Took to collect: 7.23946213722229\n",
      "Took to train: 6.455943822860718\n",
      "\n",
      " Cycle 12 8\n",
      "Took to collect: 5.66950798034668\n",
      "Took to train: 6.47704005241394\n",
      "\n",
      " Cycle 13 8\n",
      "Took to collect: 6.911626100540161\n",
      "Took to train: 6.452710866928101\n",
      "\n",
      " Cycle 14 8\n",
      "Took to collect: 6.74906325340271\n",
      "Took to train: 6.498104572296143\n",
      "\n",
      " Cycle 15 8\n",
      "Took to collect: 6.337451457977295\n",
      "Took to train: 6.468511581420898\n",
      "\n",
      " Cycle 16 8\n",
      "Took to collect: 7.596646308898926\n",
      "Took to train: 6.384193420410156\n",
      "\n",
      " Cycle 17 8\n",
      "Took to collect: 6.620222806930542\n",
      "Took to train: 6.434577226638794\n",
      "\n",
      " Cycle 18 8\n",
      "Took to collect: 6.815033435821533\n",
      "Took to train: 6.48257303237915\n",
      "\n",
      " Cycle 19 8\n",
      "Took to collect: 8.153330087661743\n",
      "Took to train: 6.4629738330841064\n",
      "\n",
      " Cycle 20 8\n",
      "Took to collect: 6.2010626792907715\n",
      "Took to train: 6.359883546829224\n",
      "\n",
      " Cycle 21 8\n",
      "Took to collect: 6.2239251136779785\n",
      "Took to train: 6.47941780090332\n",
      "\n",
      " Cycle 22 8\n",
      "Took to collect: 7.063168525695801\n",
      "Took to train: 6.466883182525635\n",
      "\n",
      " Cycle 23 8\n",
      "Took to collect: 6.813611745834351\n",
      "Took to train: 6.454675674438477\n",
      "\n",
      " Cycle 24 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 6.723588466644287\n",
      "Took to train: 6.4642112255096436\n",
      "\n",
      " Cycle 25 8\n",
      "Took to collect: 6.956075668334961\n",
      "Took to train: 6.263781547546387\n",
      "\n",
      " Cycle 26 8\n",
      "Took to collect: 5.356457710266113\n",
      "Took to train: 6.254621267318726\n",
      "\n",
      " Cycle 27 8\n",
      "Took to collect: 6.54100489616394\n",
      "Took to train: 6.2602784633636475\n",
      "\n",
      " Cycle 28 8\n",
      "Took to collect: 6.0510828495025635\n",
      "Took to train: 6.264583587646484\n",
      "\n",
      " Cycle 29 8\n",
      "Took to collect: 7.3231728076934814\n",
      "Took to train: 6.2437450885772705\n",
      "\n",
      " Cycle 30 8\n",
      "Took to collect: 6.520709037780762\n",
      "Took to train: 6.349926233291626\n",
      "\n",
      " Cycle 31 8\n",
      "Took to collect: 6.342936277389526\n",
      "Took to train: 6.419996023178101\n",
      "\n",
      " Cycle 32 8\n",
      "Took to collect: 6.017102003097534\n",
      "Took to train: 6.364902973175049\n",
      "\n",
      " Cycle 33 8\n",
      "Took to collect: 5.556997537612915\n",
      "Took to train: 6.27348256111145\n",
      "\n",
      " Cycle 34 8\n",
      "Took to collect: 6.27440619468689\n",
      "Took to train: 6.2460291385650635\n",
      "\n",
      " Cycle 35 8\n",
      "Took to collect: 5.290837049484253\n",
      "Took to train: 6.386098861694336\n",
      "\n",
      " Cycle 36 8\n",
      "Took to collect: 6.5619120597839355\n",
      "Took to train: 6.404773235321045\n",
      "\n",
      " Cycle 37 8\n",
      "Took to collect: 5.1696617603302\n",
      "Took to train: 6.425093173980713\n",
      "\n",
      " Cycle 38 8\n",
      "Took to collect: 5.079853296279907\n",
      "Took to train: 6.426955223083496\n",
      "\n",
      " Cycle 39 8\n",
      "Took to collect: 5.994068384170532\n",
      "Took to train: 6.478687524795532\n",
      "\n",
      " Cycle 40 8\n",
      "Took to collect: 6.343665838241577\n",
      "Took to train: 6.466749429702759\n",
      "\n",
      " Cycle 41 8\n",
      "Took to collect: 5.782292366027832\n",
      "Took to train: 6.423604965209961\n",
      "\n",
      " Cycle 42 8\n",
      "Took to collect: 7.472667455673218\n",
      "Took to train: 6.5065178871154785\n",
      "\n",
      " Cycle 43 8\n",
      "Took to collect: 6.8407580852508545\n",
      "Took to train: 6.431397199630737\n",
      "\n",
      " Cycle 44 8\n",
      "Took to collect: 5.450254917144775\n",
      "Took to train: 6.4143760204315186\n",
      "\n",
      " Cycle 45 8\n",
      "Took to collect: 5.825342893600464\n",
      "Took to train: 6.485265016555786\n",
      "\n",
      " Cycle 46 8\n",
      "Took to collect: 5.958286285400391\n",
      "Took to train: 6.367308616638184\n",
      "\n",
      " Cycle 47 8\n",
      "Took to collect: 6.153452157974243\n",
      "Took to train: 6.327208042144775\n",
      "\n",
      " Cycle 48 8\n",
      "Took to collect: 6.04505181312561\n",
      "Took to train: 6.312288522720337\n",
      "\n",
      " Cycle 49 8\n",
      "Took to collect: 6.764979839324951\n",
      "Took to train: 6.318817615509033\n",
      "\n",
      " Cycle 50 8\n",
      "Took to collect: 5.312544107437134\n",
      "Took to train: 6.495474100112915\n",
      "\n",
      " Cycle 51 8\n",
      "Took to collect: 7.719841241836548\n",
      "Took to train: 6.3750059604644775\n",
      "\n",
      " Cycle 52 8\n",
      "Took to collect: 6.068904638290405\n",
      "Took to train: 6.459223985671997\n",
      "\n",
      " Cycle 53 8\n",
      "Took to collect: 7.4437737464904785\n",
      "Took to train: 6.45428204536438\n",
      "\n",
      " Cycle 54 8\n",
      "Took to collect: 8.012869834899902\n",
      "Took to train: 6.370599746704102\n",
      "\n",
      " Cycle 55 8\n",
      "Took to collect: 7.5422141551971436\n",
      "Took to train: 6.373007535934448\n",
      "\n",
      " Cycle 56 8\n",
      "Took to collect: 5.4950947761535645\n",
      "Took to train: 6.355389595031738\n",
      "\n",
      " Cycle 57 8\n",
      "Took to collect: 7.273584842681885\n",
      "Took to train: 6.444097518920898\n",
      "\n",
      " Cycle 58 8\n",
      "Took to collect: 7.631048202514648\n",
      "Took to train: 6.487566947937012\n",
      "\n",
      " Cycle 59 8\n",
      "Took to collect: 7.007704734802246\n",
      "Took to train: 6.476036787033081\n",
      "\n",
      " Cycle 60 8\n",
      "Took to collect: 7.319133043289185\n",
      "Took to train: 6.510655879974365\n",
      "\n",
      " Cycle 61 8\n",
      "Took to collect: 6.137035131454468\n",
      "Took to train: 6.463922739028931\n",
      "\n",
      " Cycle 62 8\n",
      "Took to collect: 6.616166591644287\n",
      "Took to train: 6.40417742729187\n",
      "\n",
      " Cycle 63 8\n",
      "Took to collect: 7.290330648422241\n",
      "Took to train: 6.47243332862854\n",
      "\n",
      " Cycle 64 8\n",
      "Took to collect: 6.87924337387085\n",
      "Took to train: 6.327041149139404\n",
      "\n",
      " Cycle 65 8\n",
      "Took to collect: 6.9426679611206055\n",
      "Took to train: 6.438429355621338\n",
      "\n",
      " Cycle 66 8\n",
      "Took to collect: 8.28718090057373\n",
      "Took to train: 6.377275228500366\n",
      "\n",
      " Cycle 67 8\n",
      "Took to collect: 6.474812269210815\n",
      "Took to train: 6.370605707168579\n",
      "\n",
      " Cycle 68 8\n",
      "Took to collect: 6.563514709472656\n",
      "Took to train: 6.364537954330444\n",
      "\n",
      " Cycle 69 8\n",
      "Took to collect: 7.066534519195557\n",
      "Took to train: 6.372433662414551\n",
      "\n",
      " Cycle 70 8\n",
      "Took to collect: 8.927241563796997\n",
      "Took to train: 6.369580030441284\n",
      "\n",
      " Cycle 71 8\n",
      "Took to collect: 6.660315752029419\n",
      "Took to train: 6.363973379135132\n",
      "\n",
      " Cycle 72 8\n",
      "Took to collect: 7.653095245361328\n",
      "Took to train: 6.37280535697937\n",
      "\n",
      " Cycle 73 8\n",
      "Took to collect: 5.996222734451294\n",
      "Took to train: 6.391504764556885\n",
      "\n",
      " Cycle 74 8\n",
      "Took to collect: 7.701689004898071\n",
      "Took to train: 6.387896299362183\n",
      "\n",
      " Cycle 75 8\n",
      "Took to collect: 7.293880224227905\n",
      "Took to train: 6.364468336105347\n",
      "\n",
      " Cycle 76 8\n",
      "Took to collect: 6.627948522567749\n",
      "Took to train: 6.36557412147522\n",
      "\n",
      " Cycle 77 8\n",
      "Took to collect: 7.839097499847412\n",
      "Took to train: 6.374252796173096\n",
      "\n",
      " Cycle 78 8\n",
      "Took to collect: 6.827637195587158\n",
      "Took to train: 6.365447044372559\n",
      "\n",
      " Cycle 79 8\n",
      "Took to collect: 7.45749831199646\n",
      "Took to train: 6.362525939941406\n",
      "\n",
      " Cycle 80 8\n",
      "Took to collect: 6.893136262893677\n",
      "Took to train: 6.374666929244995\n",
      "\n",
      " Cycle 81 8\n",
      "Took to collect: 8.157546997070312\n",
      "Took to train: 6.376779556274414\n",
      "\n",
      " Cycle 82 8\n",
      "Took to collect: 9.236660957336426\n",
      "Took to train: 6.374274253845215\n",
      "\n",
      " Cycle 83 8\n",
      "Took to collect: 7.388819932937622\n",
      "Took to train: 6.325432538986206\n",
      "\n",
      " Cycle 84 8\n",
      "Took to collect: 7.248785972595215\n",
      "Took to train: 6.309185028076172\n",
      "\n",
      " Cycle 85 8\n",
      "Took to collect: 7.878702402114868\n",
      "Took to train: 6.35381007194519\n",
      "\n",
      " Cycle 86 8\n",
      "Took to collect: 8.920541763305664\n",
      "Took to train: 6.369402885437012\n",
      "\n",
      " Cycle 87 8\n",
      "Took to collect: 7.086543321609497\n",
      "Took to train: 6.442365884780884\n",
      "\n",
      " Cycle 88 8\n",
      "Took to collect: 7.636194705963135\n",
      "Took to train: 6.44150710105896\n",
      "\n",
      " Cycle 89 8\n",
      "Took to collect: 6.992788314819336\n",
      "Took to train: 6.274352312088013\n",
      "\n",
      " Cycle 90 8\n",
      "Took to collect: 6.707031726837158\n",
      "Took to train: 6.298807621002197\n",
      "\n",
      " Cycle 91 8\n",
      "Took to collect: 5.9110424518585205\n",
      "Took to train: 6.3338422775268555\n",
      "\n",
      " Cycle 92 8\n",
      "Took to collect: 6.851929664611816\n",
      "Took to train: 6.352458953857422\n",
      "\n",
      " Cycle 93 8\n",
      "Took to collect: 6.5934131145477295\n",
      "Took to train: 6.325974464416504\n",
      "\n",
      " Cycle 94 8\n",
      "Took to collect: 5.767565488815308\n",
      "Took to train: 6.354950189590454\n",
      "\n",
      " Cycle 95 8\n",
      "Took to collect: 7.663913726806641\n",
      "Took to train: 6.337432861328125\n",
      "\n",
      " Cycle 96 8\n",
      "Took to collect: 6.340943336486816\n",
      "Took to train: 6.334192991256714\n",
      "\n",
      " Cycle 97 8\n",
      "Took to collect: 6.976039409637451\n",
      "Took to train: 6.271473407745361\n",
      "\n",
      " Cycle 98 8\n",
      "Took to collect: 6.76472020149231\n",
      "Took to train: 6.269788026809692\n",
      "\n",
      " Cycle 99 8\n",
      "Took to collect: 7.660055875778198\n",
      "Took to train: 6.318443536758423\n",
      "Time collect avg cycle: 6.758972959518433\n",
      "Time train avg cycle: 6.38904970407486\n",
      "Total avg cycle: 13.15903167963028\n",
      "Ending epoch\n",
      "2020-10-26 01:00:42.191835 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 8 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  --------------\n",
      "trainer/num train calls                            0\n",
      "trainer/QF1 Loss                                   0.386705\n",
      "trainer/QF2 Loss                                   0.394921\n",
      "trainer/Policy Loss                               50.9779\n",
      "trainer/Q1 Predictions Mean                      -51.0141\n",
      "trainer/Q1 Predictions Std                        29.9148\n",
      "trainer/Q1 Predictions Max                         4.62464\n",
      "trainer/Q1 Predictions Min                       -98.2758\n",
      "trainer/Q2 Predictions Mean                      -50.9905\n",
      "trainer/Q2 Predictions Std                        30.0213\n",
      "trainer/Q2 Predictions Max                         5.15532\n",
      "trainer/Q2 Predictions Min                       -98.3231\n",
      "trainer/Q Targets Mean                           -51.1828\n",
      "trainer/Q Targets Std                             30.008\n",
      "trainer/Q Targets Max                              4.77051\n",
      "trainer/Q Targets Min                            -98.3717\n",
      "trainer/Log Pis Mean                               3.10619\n",
      "trainer/Log Pis Std                                1.94676\n",
      "trainer/Log Pis Max                               12.0026\n",
      "trainer/Log Pis Min                               -2.43981\n",
      "trainer/policy/mean Mean                          -0.350174\n",
      "trainer/policy/mean Std                            0.630729\n",
      "trainer/policy/mean Max                            0.998175\n",
      "trainer/policy/mean Min                           -0.996233\n",
      "trainer/policy/normal/std Mean                     0.353082\n",
      "trainer/policy/normal/std Std                      0.19609\n",
      "trainer/policy/normal/std Max                      1.24922\n",
      "trainer/policy/normal/std Min                      0.0626934\n",
      "trainer/policy/normal/log_std Mean                -1.24051\n",
      "trainer/policy/normal/log_std Std                  0.68377\n",
      "trainer/policy/normal/log_std Max                  0.222518\n",
      "trainer/policy/normal/log_std Min                 -2.7695\n",
      "trainer/Alpha                                      0.0128626\n",
      "trainer/Alpha Loss                                 0.462286\n",
      "exploration/num steps total                    91000\n",
      "exploration/num paths total                     1820\n",
      "exploration/path length Mean                      50\n",
      "exploration/path length Std                        0\n",
      "exploration/path length Max                       50\n",
      "exploration/path length Min                       50\n",
      "exploration/Rewards Mean                          -1\n",
      "exploration/Rewards Std                            0\n",
      "exploration/Rewards Max                           -1\n",
      "exploration/Rewards Min                           -1\n",
      "exploration/Returns Mean                         -50\n",
      "exploration/Returns Std                            0\n",
      "exploration/Returns Max                          -50\n",
      "exploration/Returns Min                          -50\n",
      "exploration/Actions Mean                          -0.247624\n",
      "exploration/Actions Std                            0.522136\n",
      "exploration/Actions Max                            0.998553\n",
      "exploration/Actions Min                           -0.999165\n",
      "exploration/Num Paths                            200\n",
      "exploration/Average Returns                      -50\n",
      "exploration/env_infos/final/is_success Mean        0\n",
      "exploration/env_infos/final/is_success Std         0\n",
      "exploration/env_infos/final/is_success Max         0\n",
      "exploration/env_infos/final/is_success Min         0\n",
      "exploration/env_infos/initial/is_success Mean      0\n",
      "exploration/env_infos/initial/is_success Std       0\n",
      "exploration/env_infos/initial/is_success Max       0\n",
      "exploration/env_infos/initial/is_success Min       0\n",
      "exploration/env_infos/is_success Mean              0\n",
      "exploration/env_infos/is_success Std               0\n",
      "exploration/env_infos/is_success Max               0\n",
      "exploration/env_infos/is_success Min               0\n",
      "evaluation/num steps total                      4500\n",
      "evaluation/num paths total                        90\n",
      "evaluation/path length Mean                       50\n",
      "evaluation/path length Std                         0\n",
      "evaluation/path length Max                        50\n",
      "evaluation/path length Min                        50\n",
      "evaluation/Rewards Mean                           -1\n",
      "evaluation/Rewards Std                             0\n",
      "evaluation/Rewards Max                            -1\n",
      "evaluation/Rewards Min                            -1\n",
      "evaluation/Returns Mean                          -50\n",
      "evaluation/Returns Std                             0\n",
      "evaluation/Returns Max                           -50\n",
      "evaluation/Returns Min                           -50\n",
      "evaluation/Actions Mean                           -0.204655\n",
      "evaluation/Actions Std                             0.410426\n",
      "evaluation/Actions Max                             0.916414\n",
      "evaluation/Actions Min                            -0.971932\n",
      "evaluation/Num Paths                              10\n",
      "evaluation/Average Returns                       -50\n",
      "evaluation/env_infos/final/is_success Mean         0\n",
      "evaluation/env_infos/final/is_success Std          0\n",
      "evaluation/env_infos/final/is_success Max          0\n",
      "evaluation/env_infos/final/is_success Min          0\n",
      "evaluation/env_infos/initial/is_success Mean       0\n",
      "evaluation/env_infos/initial/is_success Std        0\n",
      "evaluation/env_infos/initial/is_success Max        0\n",
      "evaluation/env_infos/initial/is_success Min        0\n",
      "evaluation/env_infos/is_success Mean               0\n",
      "evaluation/env_infos/is_success Std                0\n",
      "evaluation/env_infos/is_success Max                0\n",
      "evaluation/env_infos/is_success Min                0\n",
      "time/data storing (s)                              1.07521\n",
      "time/evaluation sampling (s)                      33.1369\n",
      "time/exploration sampling (s)                    675.917\n",
      "time/logging (s)                                   0.0308752\n",
      "time/sac training (s)                            200.118\n",
      "time/saving (s)                                    0.0141694\n",
      "time/training (s)                                  0.00692845\n",
      "time/epoch (s)                                   910.299\n",
      "time/total (s)                                 12117.5\n",
      "Epoch                                              8\n",
      "---------------------------------------------  --------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 9\n",
      "\n",
      " Cycle 0 9\n",
      "Took to collect: 6.516175031661987\n",
      "Took to train: 6.310072183609009\n",
      "\n",
      " Cycle 1 9\n",
      "Took to collect: 7.200659513473511\n",
      "Took to train: 6.324473857879639\n",
      "\n",
      " Cycle 2 9\n",
      "Took to collect: 6.475503206253052\n",
      "Took to train: 6.316471099853516\n",
      "\n",
      " Cycle 3 9\n",
      "Took to collect: 7.2371666431427\n",
      "Took to train: 6.38728141784668\n",
      "\n",
      " Cycle 4 9\n",
      "Took to collect: 7.753743410110474\n",
      "Took to train: 6.486732006072998\n",
      "\n",
      " Cycle 5 9\n",
      "Took to collect: 6.767641544342041\n",
      "Took to train: 6.425897836685181\n",
      "\n",
      " Cycle 6 9\n",
      "Took to collect: 6.9507410526275635\n",
      "Took to train: 6.4378662109375\n",
      "\n",
      " Cycle 7 9\n",
      "Took to collect: 6.301671743392944\n",
      "Took to train: 6.420526027679443\n",
      "\n",
      " Cycle 8 9\n",
      "Took to collect: 6.080132007598877\n",
      "Took to train: 6.435054779052734\n",
      "\n",
      " Cycle 9 9\n",
      "Took to collect: 6.046260595321655\n",
      "Took to train: 6.392782926559448\n",
      "\n",
      " Cycle 10 9\n",
      "Took to collect: 5.518664598464966\n",
      "Took to train: 6.442728757858276\n",
      "\n",
      " Cycle 11 9\n",
      "Took to collect: 6.449340343475342\n",
      "Took to train: 6.444403648376465\n",
      "\n",
      " Cycle 12 9\n",
      "Took to collect: 7.449380397796631\n",
      "Took to train: 6.429368734359741\n",
      "\n",
      " Cycle 13 9\n",
      "Took to collect: 5.666597604751587\n",
      "Took to train: 6.442745923995972\n",
      "\n",
      " Cycle 14 9\n",
      "Took to collect: 6.047834396362305\n",
      "Took to train: 6.281012296676636\n",
      "\n",
      " Cycle 15 9\n",
      "Took to collect: 6.960450649261475\n",
      "Took to train: 6.395854473114014\n",
      "\n",
      " Cycle 16 9\n",
      "Took to collect: 6.599644422531128\n",
      "Took to train: 6.447006702423096\n",
      "\n",
      " Cycle 17 9\n",
      "Took to collect: 7.515339136123657\n",
      "Took to train: 6.431430339813232\n",
      "\n",
      " Cycle 18 9\n",
      "Took to collect: 8.085903882980347\n",
      "Took to train: 6.451182126998901\n",
      "\n",
      " Cycle 19 9\n",
      "Took to collect: 6.695602893829346\n",
      "Took to train: 6.45162296295166\n",
      "\n",
      " Cycle 20 9\n",
      "Took to collect: 7.340029954910278\n",
      "Took to train: 6.474997520446777\n",
      "\n",
      " Cycle 21 9\n",
      "Took to collect: 5.535768985748291\n",
      "Took to train: 6.4555864334106445\n",
      "\n",
      " Cycle 22 9\n",
      "Took to collect: 7.779166221618652\n",
      "Took to train: 6.4635910987854\n",
      "\n",
      " Cycle 23 9\n",
      "Took to collect: 7.229171276092529\n",
      "Took to train: 6.462008237838745\n",
      "\n",
      " Cycle 24 9\n",
      "Took to collect: 7.084625244140625\n",
      "Took to train: 6.340355396270752\n",
      "\n",
      " Cycle 25 9\n",
      "Took to collect: 7.9593281745910645\n",
      "Took to train: 6.249103784561157\n",
      "\n",
      " Cycle 26 9\n",
      "Took to collect: 8.102312326431274\n",
      "Took to train: 6.321563005447388\n",
      "\n",
      " Cycle 27 9\n",
      "Took to collect: 7.172423839569092\n",
      "Took to train: 6.256951570510864\n",
      "\n",
      " Cycle 28 9\n",
      "Took to collect: 5.953130483627319\n",
      "Took to train: 6.283834218978882\n",
      "\n",
      " Cycle 29 9\n",
      "Took to collect: 5.271177291870117\n",
      "Took to train: 6.32407808303833\n",
      "\n",
      " Cycle 30 9\n",
      "Took to collect: 5.7125914096832275\n",
      "Took to train: 6.287631988525391\n",
      "\n",
      " Cycle 31 9\n",
      "Took to collect: 6.2522053718566895\n",
      "Took to train: 6.256941795349121\n",
      "\n",
      " Cycle 32 9\n",
      "Took to collect: 6.727711915969849\n",
      "Took to train: 6.249096870422363\n",
      "\n",
      " Cycle 33 9\n",
      "Took to collect: 5.992591381072998\n",
      "Took to train: 6.2513673305511475\n",
      "\n",
      " Cycle 34 9\n",
      "Took to collect: 8.018406629562378\n",
      "Took to train: 6.283750534057617\n",
      "\n",
      " Cycle 35 9\n",
      "Took to collect: 7.221080303192139\n",
      "Took to train: 6.374018669128418\n",
      "\n",
      " Cycle 36 9\n",
      "Took to collect: 6.5203094482421875\n",
      "Took to train: 6.326929569244385\n",
      "\n",
      " Cycle 37 9\n",
      "Took to collect: 6.066188812255859\n",
      "Took to train: 6.313524961471558\n",
      "\n",
      " Cycle 38 9\n",
      "Took to collect: 6.676769733428955\n",
      "Took to train: 6.258149147033691\n",
      "\n",
      " Cycle 39 9\n",
      "Took to collect: 7.435771226882935\n",
      "Took to train: 6.26864218711853\n",
      "\n",
      " Cycle 40 9\n",
      "Took to collect: 5.721778154373169\n",
      "Took to train: 6.318218946456909\n",
      "\n",
      " Cycle 41 9\n",
      "Took to collect: 6.043280601501465\n",
      "Took to train: 6.260805130004883\n",
      "\n",
      " Cycle 42 9\n",
      "Took to collect: 6.764888048171997\n",
      "Took to train: 6.288583278656006\n",
      "\n",
      " Cycle 43 9\n",
      "Took to collect: 6.775298595428467\n",
      "Took to train: 6.3056862354278564\n",
      "\n",
      " Cycle 44 9\n",
      "Took to collect: 5.7779035568237305\n",
      "Took to train: 6.3055739402771\n",
      "\n",
      " Cycle 45 9\n",
      "Took to collect: 6.823947906494141\n",
      "Took to train: 6.253979444503784\n",
      "\n",
      " Cycle 46 9\n",
      "Took to collect: 7.30168890953064\n",
      "Took to train: 6.28718376159668\n",
      "\n",
      " Cycle 47 9\n",
      "Took to collect: 6.065399885177612\n",
      "Took to train: 6.251899719238281\n",
      "\n",
      " Cycle 48 9\n",
      "Took to collect: 7.1766579151153564\n",
      "Took to train: 6.2484130859375\n",
      "\n",
      " Cycle 49 9\n",
      "Took to collect: 5.1088080406188965\n",
      "Took to train: 6.342152118682861\n",
      "\n",
      " Cycle 50 9\n",
      "Took to collect: 8.239384889602661\n",
      "Took to train: 6.37652325630188\n",
      "\n",
      " Cycle 51 9\n",
      "Took to collect: 7.479412317276001\n",
      "Took to train: 6.377012252807617\n",
      "\n",
      " Cycle 52 9\n",
      "Took to collect: 6.379415273666382\n",
      "Took to train: 6.415162563323975\n",
      "\n",
      " Cycle 53 9\n",
      "Took to collect: 6.022079706192017\n",
      "Took to train: 6.426368236541748\n",
      "\n",
      " Cycle 54 9\n",
      "Took to collect: 6.4021382331848145\n",
      "Took to train: 6.407485723495483\n",
      "\n",
      " Cycle 55 9\n",
      "Took to collect: 6.742074012756348\n",
      "Took to train: 6.420646905899048\n",
      "\n",
      " Cycle 56 9\n",
      "Took to collect: 6.76381254196167\n",
      "Took to train: 6.437075853347778\n",
      "\n",
      " Cycle 57 9\n",
      "Took to collect: 7.129678726196289\n",
      "Took to train: 6.469288349151611\n",
      "\n",
      " Cycle 58 9\n",
      "Took to collect: 6.505274295806885\n",
      "Took to train: 6.447835206985474\n",
      "\n",
      " Cycle 59 9\n",
      "Took to collect: 5.584579229354858\n",
      "Took to train: 6.4311583042144775\n",
      "\n",
      " Cycle 60 9\n",
      "Took to collect: 6.701566457748413\n",
      "Took to train: 6.422858953475952\n",
      "\n",
      " Cycle 61 9\n",
      "Took to collect: 5.385223388671875\n",
      "Took to train: 6.45417857170105\n",
      "\n",
      " Cycle 62 9\n",
      "Took to collect: 6.073583364486694\n",
      "Took to train: 6.436446189880371\n",
      "\n",
      " Cycle 63 9\n",
      "Took to collect: 6.5554094314575195\n",
      "Took to train: 6.434712171554565\n",
      "\n",
      " Cycle 64 9\n",
      "Took to collect: 7.1356353759765625\n",
      "Took to train: 6.434581756591797\n",
      "\n",
      " Cycle 65 9\n",
      "Took to collect: 5.649044036865234\n",
      "Took to train: 6.415290594100952\n",
      "\n",
      " Cycle 66 9\n",
      "Took to collect: 5.915025472640991\n",
      "Took to train: 6.430876970291138\n",
      "\n",
      " Cycle 67 9\n",
      "Took to collect: 6.705389738082886\n",
      "Took to train: 6.406470537185669\n",
      "\n",
      " Cycle 68 9\n",
      "Took to collect: 7.4050750732421875\n",
      "Took to train: 6.381934881210327\n",
      "\n",
      " Cycle 69 9\n",
      "Took to collect: 6.4586217403411865\n",
      "Took to train: 6.421886205673218\n",
      "\n",
      " Cycle 70 9\n",
      "Took to collect: 5.691522598266602\n",
      "Took to train: 6.444986820220947\n",
      "\n",
      " Cycle 71 9\n",
      "Took to collect: 6.34001088142395\n",
      "Took to train: 6.265675783157349\n",
      "\n",
      " Cycle 72 9\n",
      "Took to collect: 7.310580253601074\n",
      "Took to train: 6.263587236404419\n",
      "\n",
      " Cycle 73 9\n",
      "Took to collect: 6.516141653060913\n",
      "Took to train: 6.251631736755371\n",
      "\n",
      " Cycle 74 9\n",
      "Took to collect: 8.035562515258789\n",
      "Took to train: 6.2627458572387695\n",
      "\n",
      " Cycle 75 9\n",
      "Took to collect: 6.541316747665405\n",
      "Took to train: 6.2536704540252686\n",
      "\n",
      " Cycle 76 9\n",
      "Took to collect: 7.10063624382019\n",
      "Took to train: 6.3302905559539795\n",
      "\n",
      " Cycle 77 9\n",
      "Took to collect: 6.222249507904053\n",
      "Took to train: 6.414419412612915\n",
      "\n",
      " Cycle 78 9\n",
      "Took to collect: 5.824009656906128\n",
      "Took to train: 6.436063051223755\n",
      "\n",
      " Cycle 79 9\n",
      "Took to collect: 6.514682769775391\n",
      "Took to train: 6.437406301498413\n",
      "\n",
      " Cycle 80 9\n",
      "Took to collect: 6.417464733123779\n",
      "Took to train: 6.447240114212036\n",
      "\n",
      " Cycle 81 9\n",
      "Took to collect: 6.736240386962891\n",
      "Took to train: 6.409275531768799\n",
      "\n",
      " Cycle 82 9\n",
      "Took to collect: 5.999260902404785\n",
      "Took to train: 6.431924819946289\n",
      "\n",
      " Cycle 83 9\n",
      "Took to collect: 7.946638822555542\n",
      "Took to train: 6.449754476547241\n",
      "\n",
      " Cycle 84 9\n",
      "Took to collect: 6.921733856201172\n",
      "Took to train: 6.418570041656494\n",
      "\n",
      " Cycle 85 9\n",
      "Took to collect: 6.930292844772339\n",
      "Took to train: 6.434713840484619\n",
      "\n",
      " Cycle 86 9\n",
      "Took to collect: 5.646319150924683\n",
      "Took to train: 6.437960147857666\n",
      "\n",
      " Cycle 87 9\n",
      "Took to collect: 7.537161111831665\n",
      "Took to train: 6.4271955490112305\n",
      "\n",
      " Cycle 88 9\n",
      "Took to collect: 6.354266881942749\n",
      "Took to train: 6.4519734382629395\n",
      "\n",
      " Cycle 89 9\n",
      "Took to collect: 7.929952383041382\n",
      "Took to train: 6.361467123031616\n",
      "\n",
      " Cycle 90 9\n",
      "Took to collect: 6.151391983032227\n",
      "Took to train: 6.324121475219727\n",
      "\n",
      " Cycle 91 9\n",
      "Took to collect: 6.271286725997925\n",
      "Took to train: 6.408459424972534\n",
      "\n",
      " Cycle 92 9\n",
      "Took to collect: 9.327436208724976\n",
      "Took to train: 6.368986368179321\n",
      "\n",
      " Cycle 93 9\n",
      "Took to collect: 7.66143536567688\n",
      "Took to train: 6.29310941696167\n",
      "\n",
      " Cycle 94 9\n",
      "Took to collect: 6.860589981079102\n",
      "Took to train: 6.236624479293823\n",
      "\n",
      " Cycle 95 9\n",
      "Took to collect: 4.810271263122559\n",
      "Took to train: 6.398236036300659\n",
      "\n",
      " Cycle 96 9\n",
      "Took to collect: 6.847001552581787\n",
      "Took to train: 6.406614780426025\n",
      "\n",
      " Cycle 97 9\n",
      "Took to collect: 7.582728862762451\n",
      "Took to train: 6.458073616027832\n",
      "\n",
      " Cycle 98 9\n",
      "Took to collect: 6.448165416717529\n",
      "Took to train: 6.449931621551514\n",
      "\n",
      " Cycle 99 9\n",
      "Took to collect: 4.963491201400757\n",
      "Took to train: 6.549685001373291\n",
      "Time collect avg cycle: 6.666011304855346\n",
      "Time train avg cycle: 6.374913203716278\n",
      "Total avg cycle: 13.051884393692017\n",
      "Ending epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-26 01:22:59.158803 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 9 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.375017\n",
      "trainer/QF2 Loss                                    0.382991\n",
      "trainer/Policy Loss                                53.8638\n",
      "trainer/Q1 Predictions Mean                       -53.7918\n",
      "trainer/Q1 Predictions Std                         28.388\n",
      "trainer/Q1 Predictions Max                          4.12282\n",
      "trainer/Q1 Predictions Min                        -99.0366\n",
      "trainer/Q2 Predictions Mean                       -53.9751\n",
      "trainer/Q2 Predictions Std                         28.3988\n",
      "trainer/Q2 Predictions Max                          3.99311\n",
      "trainer/Q2 Predictions Min                        -99.2856\n",
      "trainer/Q Targets Mean                            -53.7809\n",
      "trainer/Q Targets Std                              28.4507\n",
      "trainer/Q Targets Max                               4.2916\n",
      "trainer/Q Targets Min                             -98.9136\n",
      "trainer/Log Pis Mean                                3.1749\n",
      "trainer/Log Pis Std                                 2.06677\n",
      "trainer/Log Pis Max                                 9.25879\n",
      "trainer/Log Pis Min                                -3.8611\n",
      "trainer/policy/mean Mean                           -0.31432\n",
      "trainer/policy/mean Std                             0.63509\n",
      "trainer/policy/mean Max                             0.987487\n",
      "trainer/policy/mean Min                            -0.993969\n",
      "trainer/policy/normal/std Mean                      0.346366\n",
      "trainer/policy/normal/std Std                       0.200716\n",
      "trainer/policy/normal/std Max                       1.21534\n",
      "trainer/policy/normal/std Min                       0.0636095\n",
      "trainer/policy/normal/log_std Mean                 -1.27637\n",
      "trainer/policy/normal/log_std Std                   0.708749\n",
      "trainer/policy/normal/log_std Max                   0.195024\n",
      "trainer/policy/normal/log_std Min                  -2.75499\n",
      "trainer/Alpha                                       0.0141103\n",
      "trainer/Alpha Loss                                  0.745237\n",
      "exploration/num steps total                    101000\n",
      "exploration/num paths total                      2020\n",
      "exploration/path length Mean                       50\n",
      "exploration/path length Std                         0\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        50\n",
      "exploration/Rewards Mean                           -0.9968\n",
      "exploration/Rewards Std                             0.056478\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.84\n",
      "exploration/Returns Std                             2.25708\n",
      "exploration/Returns Max                           -18\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.226124\n",
      "exploration/Actions Std                             0.529487\n",
      "exploration/Actions Max                             0.9976\n",
      "exploration/Actions Min                            -0.999338\n",
      "exploration/Num Paths                             200\n",
      "exploration/Average Returns                       -49.84\n",
      "exploration/env_infos/final/is_success Mean         0\n",
      "exploration/env_infos/final/is_success Std          0\n",
      "exploration/env_infos/final/is_success Max          0\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0\n",
      "exploration/env_infos/is_success Std                0\n",
      "exploration/env_infos/is_success Max                0\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                       5000\n",
      "evaluation/num paths total                        100\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.237975\n",
      "evaluation/Actions Std                              0.436766\n",
      "evaluation/Actions Max                              0.929084\n",
      "evaluation/Actions Min                             -0.965432\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               1.07032\n",
      "time/evaluation sampling (s)                       31.7133\n",
      "time/exploration sampling (s)                     666.62\n",
      "time/logging (s)                                    0.0323968\n",
      "time/sac training (s)                             198.574\n",
      "time/saving (s)                                     0.0139164\n",
      "time/training (s)                                   0.00688811\n",
      "time/epoch (s)                                    898.032\n",
      "time/total (s)                                  13454.3\n",
      "Epoch                                               9\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 10\n",
      "\n",
      " Cycle 0 10\n",
      "Took to collect: 5.84651780128479\n",
      "Took to train: 6.379130840301514\n",
      "\n",
      " Cycle 1 10\n",
      "Took to collect: 6.76886773109436\n",
      "Took to train: 6.40897536277771\n",
      "\n",
      " Cycle 2 10\n",
      "Took to collect: 5.46548318862915\n",
      "Took to train: 6.360863447189331\n",
      "\n",
      " Cycle 3 10\n",
      "Took to collect: 7.0749571323394775\n",
      "Took to train: 6.3677098751068115\n",
      "\n",
      " Cycle 4 10\n",
      "Took to collect: 6.246808052062988\n",
      "Took to train: 6.435131549835205\n",
      "\n",
      " Cycle 5 10\n",
      "Took to collect: 6.495734453201294\n",
      "Took to train: 6.363970756530762\n",
      "\n",
      " Cycle 6 10\n",
      "Took to collect: 7.546390056610107\n",
      "Took to train: 6.391040086746216\n",
      "\n",
      " Cycle 7 10\n",
      "Took to collect: 7.768112421035767\n",
      "Took to train: 6.414212226867676\n",
      "\n",
      " Cycle 8 10\n",
      "Took to collect: 6.523106336593628\n",
      "Took to train: 6.400171995162964\n",
      "\n",
      " Cycle 9 10\n",
      "Took to collect: 6.506290674209595\n",
      "Took to train: 6.4018025398254395\n",
      "\n",
      " Cycle 10 10\n",
      "Took to collect: 7.656680107116699\n",
      "Took to train: 6.4294164180755615\n",
      "\n",
      " Cycle 11 10\n",
      "Took to collect: 6.222276926040649\n",
      "Took to train: 6.393008232116699\n",
      "\n",
      " Cycle 12 10\n",
      "Took to collect: 5.378105401992798\n",
      "Took to train: 6.459588289260864\n",
      "\n",
      " Cycle 13 10\n",
      "Took to collect: 6.1903111934661865\n",
      "Took to train: 6.479467153549194\n",
      "\n",
      " Cycle 14 10\n",
      "Took to collect: 6.0552778244018555\n",
      "Took to train: 6.38667893409729\n",
      "\n",
      " Cycle 15 10\n",
      "Took to collect: 6.216342926025391\n",
      "Took to train: 6.40794825553894\n",
      "\n",
      " Cycle 16 10\n",
      "Took to collect: 6.221794843673706\n",
      "Took to train: 6.462249994277954\n",
      "\n",
      " Cycle 17 10\n",
      "Took to collect: 6.674403667449951\n",
      "Took to train: 6.434229612350464\n",
      "\n",
      " Cycle 18 10\n",
      "Took to collect: 6.238333225250244\n",
      "Took to train: 6.420517444610596\n",
      "\n",
      " Cycle 19 10\n",
      "Took to collect: 5.961999893188477\n",
      "Took to train: 6.433245420455933\n",
      "\n",
      " Cycle 20 10\n",
      "Took to collect: 6.605085611343384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.4320032596588135\n",
      "\n",
      " Cycle 21 10\n",
      "Took to collect: 6.529794454574585\n",
      "Took to train: 6.350823163986206\n",
      "\n",
      " Cycle 22 10\n",
      "Took to collect: 6.74691915512085\n",
      "Took to train: 6.39523458480835\n",
      "\n",
      " Cycle 23 10\n",
      "Took to collect: 7.6459174156188965\n",
      "Took to train: 6.388567686080933\n",
      "\n",
      " Cycle 24 10\n",
      "Took to collect: 8.496110439300537\n",
      "Took to train: 6.264249563217163\n",
      "\n",
      " Cycle 25 10\n",
      "Took to collect: 8.160200357437134\n",
      "Took to train: 6.3672096729278564\n",
      "\n",
      " Cycle 26 10\n",
      "Took to collect: 6.082669973373413\n",
      "Took to train: 6.430511236190796\n",
      "\n",
      " Cycle 27 10\n",
      "Took to collect: 7.585461854934692\n",
      "Took to train: 6.438119888305664\n",
      "\n",
      " Cycle 28 10\n",
      "Took to collect: 6.608116388320923\n",
      "Took to train: 6.460966348648071\n",
      "\n",
      " Cycle 29 10\n",
      "Took to collect: 6.417550325393677\n",
      "Took to train: 6.4258177280426025\n",
      "\n",
      " Cycle 30 10\n",
      "Took to collect: 6.928022623062134\n",
      "Took to train: 6.439999580383301\n",
      "\n",
      " Cycle 31 10\n",
      "Took to collect: 6.827361106872559\n",
      "Took to train: 6.272341966629028\n",
      "\n",
      " Cycle 32 10\n",
      "Took to collect: 7.31259560585022\n",
      "Took to train: 6.421829700469971\n",
      "\n",
      " Cycle 33 10\n",
      "Took to collect: 7.6103010177612305\n",
      "Took to train: 6.400095462799072\n",
      "\n",
      " Cycle 34 10\n",
      "Took to collect: 7.561482191085815\n",
      "Took to train: 6.452817440032959\n",
      "\n",
      " Cycle 35 10\n",
      "Took to collect: 6.873098850250244\n",
      "Took to train: 6.442308664321899\n",
      "\n",
      " Cycle 36 10\n",
      "Took to collect: 7.384864807128906\n",
      "Took to train: 6.367725372314453\n",
      "\n",
      " Cycle 37 10\n",
      "Took to collect: 8.78070855140686\n",
      "Took to train: 6.3765482902526855\n",
      "\n",
      " Cycle 38 10\n",
      "Took to collect: 6.152326583862305\n",
      "Took to train: 6.311327695846558\n",
      "\n",
      " Cycle 39 10\n",
      "Took to collect: 7.367866039276123\n",
      "Took to train: 6.440337657928467\n",
      "\n",
      " Cycle 40 10\n",
      "Took to collect: 6.719781160354614\n",
      "Took to train: 6.422771215438843\n",
      "\n",
      " Cycle 41 10\n",
      "Took to collect: 5.761419057846069\n",
      "Took to train: 6.476184368133545\n",
      "\n",
      " Cycle 42 10\n",
      "Took to collect: 7.594243288040161\n",
      "Took to train: 6.488811492919922\n",
      "\n",
      " Cycle 43 10\n",
      "Took to collect: 5.351362943649292\n",
      "Took to train: 6.339282989501953\n",
      "\n",
      " Cycle 44 10\n",
      "Took to collect: 7.054843902587891\n",
      "Took to train: 6.32266640663147\n",
      "\n",
      " Cycle 45 10\n",
      "Took to collect: 6.7948689460754395\n",
      "Took to train: 6.315635919570923\n",
      "\n",
      " Cycle 46 10\n",
      "Took to collect: 7.432631969451904\n",
      "Took to train: 6.326923370361328\n",
      "\n",
      " Cycle 47 10\n",
      "Took to collect: 7.362264394760132\n",
      "Took to train: 6.328566074371338\n",
      "\n",
      " Cycle 48 10\n",
      "Took to collect: 6.9474475383758545\n",
      "Took to train: 6.367372751235962\n",
      "\n",
      " Cycle 49 10\n",
      "Took to collect: 6.424298048019409\n",
      "Took to train: 6.442410230636597\n",
      "\n",
      " Cycle 50 10\n",
      "Took to collect: 6.8072967529296875\n",
      "Took to train: 6.45140814781189\n",
      "\n",
      " Cycle 51 10\n",
      "Took to collect: 6.333625555038452\n",
      "Took to train: 6.53421425819397\n",
      "\n",
      " Cycle 52 10\n",
      "Took to collect: 7.021635055541992\n",
      "Took to train: 6.462174892425537\n",
      "\n",
      " Cycle 53 10\n",
      "Took to collect: 7.552490949630737\n",
      "Took to train: 6.329996347427368\n",
      "\n",
      " Cycle 54 10\n",
      "Took to collect: 7.304362535476685\n",
      "Took to train: 6.319490432739258\n",
      "\n",
      " Cycle 55 10\n",
      "Took to collect: 6.127653360366821\n",
      "Took to train: 6.467440366744995\n",
      "\n",
      " Cycle 56 10\n",
      "Took to collect: 7.052754640579224\n",
      "Took to train: 6.456179618835449\n",
      "\n",
      " Cycle 57 10\n",
      "Took to collect: 7.800246953964233\n",
      "Took to train: 6.4796833992004395\n",
      "\n",
      " Cycle 58 10\n",
      "Took to collect: 7.452630281448364\n",
      "Took to train: 6.51938796043396\n",
      "\n",
      " Cycle 59 10\n",
      "Took to collect: 6.465662002563477\n",
      "Took to train: 6.411484956741333\n",
      "\n",
      " Cycle 60 10\n",
      "Took to collect: 6.872634649276733\n",
      "Took to train: 6.451922655105591\n",
      "\n",
      " Cycle 61 10\n",
      "Took to collect: 6.558819532394409\n",
      "Took to train: 6.48622727394104\n",
      "\n",
      " Cycle 62 10\n",
      "Took to collect: 7.185805320739746\n",
      "Took to train: 6.515809774398804\n",
      "\n",
      " Cycle 63 10\n",
      "Took to collect: 6.583050012588501\n",
      "Took to train: 6.471017122268677\n",
      "\n",
      " Cycle 64 10\n",
      "Took to collect: 6.777719497680664\n",
      "Took to train: 6.37427544593811\n",
      "\n",
      " Cycle 65 10\n",
      "Took to collect: 7.057871580123901\n",
      "Took to train: 6.461588382720947\n",
      "\n",
      " Cycle 66 10\n",
      "Took to collect: 7.045575857162476\n",
      "Took to train: 6.531999826431274\n",
      "\n",
      " Cycle 67 10\n",
      "Took to collect: 7.2979254722595215\n",
      "Took to train: 6.479156017303467\n",
      "\n",
      " Cycle 68 10\n",
      "Took to collect: 7.2757110595703125\n",
      "Took to train: 6.494388103485107\n",
      "\n",
      " Cycle 69 10\n",
      "Took to collect: 7.224400758743286\n",
      "Took to train: 6.365604877471924\n",
      "\n",
      " Cycle 70 10\n",
      "Took to collect: 7.695057153701782\n",
      "Took to train: 6.340453147888184\n",
      "\n",
      " Cycle 71 10\n",
      "Took to collect: 6.423695802688599\n",
      "Took to train: 6.402898788452148\n",
      "\n",
      " Cycle 72 10\n",
      "Took to collect: 6.069567680358887\n",
      "Took to train: 6.449006795883179\n",
      "\n",
      " Cycle 73 10\n",
      "Took to collect: 6.716644763946533\n",
      "Took to train: 6.453723669052124\n",
      "\n",
      " Cycle 74 10\n",
      "Took to collect: 7.074558258056641\n",
      "Took to train: 6.390732765197754\n",
      "\n",
      " Cycle 75 10\n",
      "Took to collect: 7.182217121124268\n",
      "Took to train: 6.4411327838897705\n",
      "\n",
      " Cycle 76 10\n",
      "Took to collect: 7.6870763301849365\n",
      "Took to train: 6.267411470413208\n",
      "\n",
      " Cycle 77 10\n",
      "Took to collect: 7.637178897857666\n",
      "Took to train: 6.261157035827637\n",
      "\n",
      " Cycle 78 10\n",
      "Took to collect: 7.767362117767334\n",
      "Took to train: 6.361475944519043\n",
      "\n",
      " Cycle 79 10\n",
      "Took to collect: 6.987408638000488\n",
      "Took to train: 6.388424396514893\n",
      "\n",
      " Cycle 80 10\n",
      "Took to collect: 8.430708885192871\n",
      "Took to train: 6.438530683517456\n",
      "\n",
      " Cycle 81 10\n",
      "Took to collect: 8.103941202163696\n",
      "Took to train: 6.408685922622681\n",
      "\n",
      " Cycle 82 10\n",
      "Took to collect: 7.8259947299957275\n",
      "Took to train: 6.349586248397827\n",
      "\n",
      " Cycle 83 10\n",
      "Took to collect: 8.900026798248291\n",
      "Took to train: 6.421473026275635\n",
      "\n",
      " Cycle 84 10\n",
      "Took to collect: 6.332636833190918\n",
      "Took to train: 6.48142671585083\n",
      "\n",
      " Cycle 85 10\n",
      "Took to collect: 6.95275616645813\n",
      "Took to train: 6.417328357696533\n",
      "\n",
      " Cycle 86 10\n",
      "Took to collect: 8.51073408126831\n",
      "Took to train: 6.427111864089966\n",
      "\n",
      " Cycle 87 10\n",
      "Took to collect: 6.352141618728638\n",
      "Took to train: 6.459237098693848\n",
      "\n",
      " Cycle 88 10\n",
      "Took to collect: 7.998398303985596\n",
      "Took to train: 6.4650962352752686\n",
      "\n",
      " Cycle 89 10\n",
      "Took to collect: 6.971964120864868\n",
      "Took to train: 6.429311037063599\n",
      "\n",
      " Cycle 90 10\n",
      "Took to collect: 6.471114873886108\n",
      "Took to train: 6.447714328765869\n",
      "\n",
      " Cycle 91 10\n",
      "Took to collect: 7.8636474609375\n",
      "Took to train: 6.385619878768921\n",
      "\n",
      " Cycle 92 10\n",
      "Took to collect: 7.308694362640381\n",
      "Took to train: 6.368659019470215\n",
      "\n",
      " Cycle 93 10\n",
      "Took to collect: 7.2703399658203125\n",
      "Took to train: 6.43172812461853\n",
      "\n",
      " Cycle 94 10\n",
      "Took to collect: 7.866006851196289\n",
      "Took to train: 6.418570280075073\n",
      "\n",
      " Cycle 95 10\n",
      "Took to collect: 8.615305185317993\n",
      "Took to train: 6.468265533447266\n",
      "\n",
      " Cycle 96 10\n",
      "Took to collect: 8.009806156158447\n",
      "Took to train: 6.4038519859313965\n",
      "\n",
      " Cycle 97 10\n",
      "Took to collect: 7.0157859325408936\n",
      "Took to train: 6.396125078201294\n",
      "\n",
      " Cycle 98 10\n",
      "Took to collect: 6.737555027008057\n",
      "Took to train: 6.5594658851623535\n",
      "\n",
      " Cycle 99 10\n",
      "Took to collect: 6.792773962020874\n",
      "Took to train: 6.562594652175903\n",
      "Time collect avg cycle: 7.015463795661926\n",
      "Time train avg cycle: 6.414990668296814\n",
      "Total avg cycle: 13.44083432674408\n",
      "Ending epoch\n",
      "2020-10-26 01:45:49.800405 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 10 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.600398\n",
      "trainer/QF2 Loss                                    0.475648\n",
      "trainer/Policy Loss                                50.3007\n",
      "trainer/Q1 Predictions Mean                       -50.3628\n",
      "trainer/Q1 Predictions Std                         32.6691\n",
      "trainer/Q1 Predictions Max                          8.90139\n",
      "trainer/Q1 Predictions Min                       -100.169\n",
      "trainer/Q2 Predictions Mean                       -50.3734\n",
      "trainer/Q2 Predictions Std                         32.5922\n",
      "trainer/Q2 Predictions Max                          8.94602\n",
      "trainer/Q2 Predictions Min                       -100.184\n",
      "trainer/Q Targets Mean                            -50.7321\n",
      "trainer/Q Targets Std                              32.5474\n",
      "trainer/Q Targets Max                               8.41585\n",
      "trainer/Q Targets Min                            -100.174\n",
      "trainer/Log Pis Mean                                3.08094\n",
      "trainer/Log Pis Std                                 2.02107\n",
      "trainer/Log Pis Max                                11.0266\n",
      "trainer/Log Pis Min                                -5.73503\n",
      "trainer/policy/mean Mean                           -0.284688\n",
      "trainer/policy/mean Std                             0.630224\n",
      "trainer/policy/mean Max                             0.983029\n",
      "trainer/policy/mean Min                            -0.992134\n",
      "trainer/policy/normal/std Mean                      0.336411\n",
      "trainer/policy/normal/std Std                       0.199314\n",
      "trainer/policy/normal/std Max                       0.842633\n",
      "trainer/policy/normal/std Min                       0.0567511\n",
      "trainer/policy/normal/log_std Mean                 -1.32609\n",
      "trainer/policy/normal/log_std Std                   0.746003\n",
      "trainer/policy/normal/log_std Max                  -0.171224\n",
      "trainer/policy/normal/log_std Min                  -2.86908\n",
      "trainer/Alpha                                       0.0147222\n",
      "trainer/Alpha Loss                                  0.341436\n",
      "exploration/num steps total                    111000\n",
      "exploration/num paths total                      2220\n",
      "exploration/path length Mean                       50\n",
      "exploration/path length Std                         0\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        50\n",
      "exploration/Rewards Mean                           -0.9999\n",
      "exploration/Rewards Std                             0.0099995\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.995\n",
      "exploration/Returns Std                             0.0705337\n",
      "exploration/Returns Max                           -49\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.206432\n",
      "exploration/Actions Std                             0.537487\n",
      "exploration/Actions Max                             0.999772\n",
      "exploration/Actions Min                            -0.99938\n",
      "exploration/Num Paths                             200\n",
      "exploration/Average Returns                       -49.995\n",
      "exploration/env_infos/final/is_success Mean         0\n",
      "exploration/env_infos/final/is_success Std          0\n",
      "exploration/env_infos/final/is_success Max          0\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0\n",
      "exploration/env_infos/is_success Std                0\n",
      "exploration/env_infos/is_success Max                0\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                       5500\n",
      "evaluation/num paths total                        110\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.232048\n",
      "evaluation/Actions Std                              0.372491\n",
      "evaluation/Actions Max                              0.88969\n",
      "evaluation/Actions Min                             -0.960016\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               1.01228\n",
      "time/evaluation sampling (s)                       26.4901\n",
      "time/exploration sampling (s)                     701.566\n",
      "time/logging (s)                                    0.0277205\n",
      "time/sac training (s)                             199.937\n",
      "time/saving (s)                                     0.0139495\n",
      "time/training (s)                                   0.00709713\n",
      "time/epoch (s)                                    929.054\n",
      "time/total (s)                                  14824.7\n",
      "Epoch                                              10\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 11\n",
      "\n",
      " Cycle 0 11\n",
      "Took to collect: 8.11345386505127\n",
      "Took to train: 6.371265172958374\n",
      "\n",
      " Cycle 1 11\n",
      "Took to collect: 8.570689916610718\n",
      "Took to train: 6.369882583618164\n",
      "\n",
      " Cycle 2 11\n",
      "Took to collect: 8.612208843231201\n",
      "Took to train: 6.3937811851501465\n",
      "\n",
      " Cycle 3 11\n",
      "Took to collect: 6.6236772537231445\n",
      "Took to train: 6.370548963546753\n",
      "\n",
      " Cycle 4 11\n",
      "Took to collect: 6.579682350158691\n",
      "Took to train: 6.374176979064941\n",
      "\n",
      " Cycle 5 11\n",
      "Took to collect: 7.737716197967529\n",
      "Took to train: 6.3846330642700195\n",
      "\n",
      " Cycle 6 11\n",
      "Took to collect: 6.512559413909912\n",
      "Took to train: 6.469099044799805\n",
      "\n",
      " Cycle 7 11\n",
      "Took to collect: 8.359400749206543\n",
      "Took to train: 6.477832555770874\n",
      "\n",
      " Cycle 8 11\n",
      "Took to collect: 7.71984076499939\n",
      "Took to train: 6.419668436050415\n",
      "\n",
      " Cycle 9 11\n",
      "Took to collect: 8.5809965133667\n",
      "Took to train: 6.382514476776123\n",
      "\n",
      " Cycle 10 11\n",
      "Took to collect: 9.153663396835327\n",
      "Took to train: 6.3763158321380615\n",
      "\n",
      " Cycle 11 11\n",
      "Took to collect: 7.2551140785217285\n",
      "Took to train: 6.4085001945495605\n",
      "\n",
      " Cycle 12 11\n",
      "Took to collect: 6.964966773986816\n",
      "Took to train: 6.4102606773376465\n",
      "\n",
      " Cycle 13 11\n",
      "Took to collect: 6.921292781829834\n",
      "Took to train: 6.384034156799316\n",
      "\n",
      " Cycle 14 11\n",
      "Took to collect: 8.912169694900513\n",
      "Took to train: 6.403965711593628\n",
      "\n",
      " Cycle 15 11\n",
      "Took to collect: 8.182258129119873\n",
      "Took to train: 6.384549140930176\n",
      "\n",
      " Cycle 16 11\n",
      "Took to collect: 8.171919822692871\n",
      "Took to train: 6.469918489456177\n",
      "\n",
      " Cycle 17 11\n",
      "Took to collect: 8.571465015411377\n",
      "Took to train: 6.4523725509643555\n",
      "\n",
      " Cycle 18 11\n",
      "Took to collect: 7.823494911193848\n",
      "Took to train: 6.459024667739868\n",
      "\n",
      " Cycle 19 11\n",
      "Took to collect: 8.641172885894775\n",
      "Took to train: 6.475086212158203\n",
      "\n",
      " Cycle 20 11\n",
      "Took to collect: 8.097673892974854\n",
      "Took to train: 6.456064939498901\n",
      "\n",
      " Cycle 21 11\n",
      "Took to collect: 8.441778898239136\n",
      "Took to train: 6.435162544250488\n",
      "\n",
      " Cycle 22 11\n",
      "Took to collect: 8.468578815460205\n",
      "Took to train: 6.4300501346588135\n",
      "\n",
      " Cycle 23 11\n",
      "Took to collect: 8.19579291343689\n",
      "Took to train: 6.4315185546875\n",
      "\n",
      " Cycle 24 11\n",
      "Took to collect: 8.886892795562744\n",
      "Took to train: 6.46867561340332\n",
      "\n",
      " Cycle 25 11\n",
      "Took to collect: 7.799870014190674\n",
      "Took to train: 6.459910869598389\n",
      "\n",
      " Cycle 26 11\n",
      "Took to collect: 8.385150909423828\n",
      "Took to train: 6.452433824539185\n",
      "\n",
      " Cycle 27 11\n",
      "Took to collect: 9.362887620925903\n",
      "Took to train: 6.485529899597168\n",
      "\n",
      " Cycle 28 11\n",
      "Took to collect: 8.146538257598877\n",
      "Took to train: 6.490208148956299\n",
      "\n",
      " Cycle 29 11\n",
      "Took to collect: 8.608258724212646\n",
      "Took to train: 6.492652654647827\n",
      "\n",
      " Cycle 30 11\n",
      "Took to collect: 7.363913536071777\n",
      "Took to train: 6.467504024505615\n",
      "\n",
      " Cycle 31 11\n",
      "Took to collect: 6.90081787109375\n",
      "Took to train: 6.452676773071289\n",
      "\n",
      " Cycle 32 11\n",
      "Took to collect: 7.2469401359558105\n",
      "Took to train: 6.440293073654175\n",
      "\n",
      " Cycle 33 11\n",
      "Took to collect: 7.887060880661011\n",
      "Took to train: 6.4894633293151855\n",
      "\n",
      " Cycle 34 11\n",
      "Took to collect: 7.269002676010132\n",
      "Took to train: 6.475926876068115\n",
      "\n",
      " Cycle 35 11\n",
      "Took to collect: 8.294600009918213\n",
      "Took to train: 6.43474817276001\n",
      "\n",
      " Cycle 36 11\n",
      "Took to collect: 8.360138177871704\n",
      "Took to train: 6.364521741867065\n",
      "\n",
      " Cycle 37 11\n",
      "Took to collect: 7.2190773487091064\n",
      "Took to train: 6.377133131027222\n",
      "\n",
      " Cycle 38 11\n",
      "Took to collect: 8.409364223480225\n",
      "Took to train: 6.399407148361206\n",
      "\n",
      " Cycle 39 11\n",
      "Took to collect: 7.190532922744751\n",
      "Took to train: 6.2510480880737305\n",
      "\n",
      " Cycle 40 11\n",
      "Took to collect: 8.256201267242432\n",
      "Took to train: 6.239267826080322\n",
      "\n",
      " Cycle 41 11\n",
      "Took to collect: 7.89801549911499\n",
      "Took to train: 6.24700927734375\n",
      "\n",
      " Cycle 42 11\n",
      "Took to collect: 7.643122434616089\n",
      "Took to train: 6.321336269378662\n",
      "\n",
      " Cycle 43 11\n",
      "Took to collect: 7.546889066696167\n",
      "Took to train: 6.460287809371948\n",
      "\n",
      " Cycle 44 11\n",
      "Took to collect: 8.111158609390259\n",
      "Took to train: 6.284139394760132\n",
      "\n",
      " Cycle 45 11\n",
      "Took to collect: 8.948045492172241\n",
      "Took to train: 6.4087700843811035\n",
      "\n",
      " Cycle 46 11\n",
      "Took to collect: 6.861795663833618\n",
      "Took to train: 6.457150459289551\n",
      "\n",
      " Cycle 47 11\n",
      "Took to collect: 8.825143098831177\n",
      "Took to train: 6.43819785118103\n",
      "\n",
      " Cycle 48 11\n",
      "Took to collect: 7.185145854949951\n",
      "Took to train: 6.435116291046143\n",
      "\n",
      " Cycle 49 11\n",
      "Took to collect: 7.939025163650513\n",
      "Took to train: 6.444908142089844\n",
      "\n",
      " Cycle 50 11\n",
      "Took to collect: 7.82607889175415\n",
      "Took to train: 6.471550464630127\n",
      "\n",
      " Cycle 51 11\n",
      "Took to collect: 8.214564800262451\n",
      "Took to train: 6.462692975997925\n",
      "\n",
      " Cycle 52 11\n",
      "Took to collect: 8.149892330169678\n",
      "Took to train: 6.46632719039917\n",
      "\n",
      " Cycle 53 11\n",
      "Took to collect: 7.840009689331055\n",
      "Took to train: 6.465442657470703\n",
      "\n",
      " Cycle 54 11\n",
      "Took to collect: 9.1675386428833\n",
      "Took to train: 6.430088043212891\n",
      "\n",
      " Cycle 55 11\n",
      "Took to collect: 8.583956718444824\n",
      "Took to train: 6.414535284042358\n",
      "\n",
      " Cycle 56 11\n",
      "Took to collect: 7.714339733123779\n",
      "Took to train: 6.4515321254730225\n",
      "\n",
      " Cycle 57 11\n",
      "Took to collect: 7.887286424636841\n",
      "Took to train: 6.466682195663452\n",
      "\n",
      " Cycle 58 11\n",
      "Took to collect: 7.862690687179565\n",
      "Took to train: 6.386192798614502\n",
      "\n",
      " Cycle 59 11\n",
      "Took to collect: 8.079014301300049\n",
      "Took to train: 6.282808780670166\n",
      "\n",
      " Cycle 60 11\n",
      "Took to collect: 8.860522747039795\n",
      "Took to train: 6.35342001914978\n",
      "\n",
      " Cycle 61 11\n",
      "Took to collect: 7.987581968307495\n",
      "Took to train: 6.397214889526367\n",
      "\n",
      " Cycle 62 11\n",
      "Took to collect: 7.396362543106079\n",
      "Took to train: 6.401221752166748\n",
      "\n",
      " Cycle 63 11\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 8.33657193183899\n",
      "Took to train: 6.4204185009002686\n",
      "\n",
      " Cycle 64 11\n",
      "Took to collect: 8.744316816329956\n",
      "Took to train: 6.450434684753418\n",
      "\n",
      " Cycle 65 11\n",
      "Took to collect: 8.289577007293701\n",
      "Took to train: 6.321859836578369\n",
      "\n",
      " Cycle 66 11\n",
      "Took to collect: 7.333741188049316\n",
      "Took to train: 6.2649617195129395\n",
      "\n",
      " Cycle 67 11\n",
      "Took to collect: 7.725177049636841\n",
      "Took to train: 6.453019142150879\n",
      "\n",
      " Cycle 68 11\n",
      "Took to collect: 8.836285591125488\n",
      "Took to train: 6.266851902008057\n",
      "\n",
      " Cycle 69 11\n",
      "Took to collect: 8.170777797698975\n",
      "Took to train: 6.255139589309692\n",
      "\n",
      " Cycle 70 11\n",
      "Took to collect: 6.511826038360596\n",
      "Took to train: 6.426756858825684\n",
      "\n",
      " Cycle 71 11\n",
      "Took to collect: 8.238686800003052\n",
      "Took to train: 6.394256830215454\n",
      "\n",
      " Cycle 72 11\n",
      "Took to collect: 8.286089181900024\n",
      "Took to train: 6.47066330909729\n",
      "\n",
      " Cycle 73 11\n",
      "Took to collect: 9.539567232131958\n",
      "Took to train: 6.531899929046631\n",
      "\n",
      " Cycle 74 11\n",
      "Took to collect: 7.923651933670044\n",
      "Took to train: 6.496876001358032\n",
      "\n",
      " Cycle 75 11\n",
      "Took to collect: 6.673309564590454\n",
      "Took to train: 6.495124578475952\n",
      "\n",
      " Cycle 76 11\n",
      "Took to collect: 6.230748414993286\n",
      "Took to train: 6.484329462051392\n",
      "\n",
      " Cycle 77 11\n",
      "Took to collect: 8.12288784980774\n",
      "Took to train: 6.425550699234009\n",
      "\n",
      " Cycle 78 11\n",
      "Took to collect: 8.427700281143188\n",
      "Took to train: 6.403459787368774\n",
      "\n",
      " Cycle 79 11\n",
      "Took to collect: 7.652986288070679\n",
      "Took to train: 6.389505624771118\n",
      "\n",
      " Cycle 80 11\n",
      "Took to collect: 8.474154949188232\n",
      "Took to train: 6.482592344284058\n",
      "\n",
      " Cycle 81 11\n",
      "Took to collect: 7.437079429626465\n",
      "Took to train: 6.47969126701355\n",
      "\n",
      " Cycle 82 11\n",
      "Took to collect: 7.999358177185059\n",
      "Took to train: 6.402611970901489\n",
      "\n",
      " Cycle 83 11\n",
      "Took to collect: 6.818148612976074\n",
      "Took to train: 6.411659240722656\n",
      "\n",
      " Cycle 84 11\n",
      "Took to collect: 8.618398189544678\n",
      "Took to train: 6.398664236068726\n",
      "\n",
      " Cycle 85 11\n",
      "Took to collect: 7.9799604415893555\n",
      "Took to train: 6.287101745605469\n",
      "\n",
      " Cycle 86 11\n",
      "Took to collect: 7.7189836502075195\n",
      "Took to train: 6.258669137954712\n",
      "\n",
      " Cycle 87 11\n",
      "Took to collect: 8.509511947631836\n",
      "Took to train: 6.289291858673096\n",
      "\n",
      " Cycle 88 11\n",
      "Took to collect: 8.270236730575562\n",
      "Took to train: 6.2615814208984375\n",
      "\n",
      " Cycle 89 11\n",
      "Took to collect: 7.265992879867554\n",
      "Took to train: 6.385005474090576\n",
      "\n",
      " Cycle 90 11\n",
      "Took to collect: 8.830235958099365\n",
      "Took to train: 6.484617710113525\n",
      "\n",
      " Cycle 91 11\n",
      "Took to collect: 7.6329450607299805\n",
      "Took to train: 6.4992759227752686\n",
      "\n",
      " Cycle 92 11\n",
      "Took to collect: 8.46915078163147\n",
      "Took to train: 6.437371492385864\n",
      "\n",
      " Cycle 93 11\n",
      "Took to collect: 7.329739809036255\n",
      "Took to train: 6.383824586868286\n",
      "\n",
      " Cycle 94 11\n",
      "Took to collect: 7.114698886871338\n",
      "Took to train: 6.52582573890686\n",
      "\n",
      " Cycle 95 11\n",
      "Took to collect: 8.436022520065308\n",
      "Took to train: 6.441370248794556\n",
      "\n",
      " Cycle 96 11\n",
      "Took to collect: 7.31264066696167\n",
      "Took to train: 6.442317485809326\n",
      "\n",
      " Cycle 97 11\n",
      "Took to collect: 7.434466361999512\n",
      "Took to train: 6.499433279037476\n",
      "\n",
      " Cycle 98 11\n",
      "Took to collect: 8.834219455718994\n",
      "Took to train: 6.614313125610352\n",
      "\n",
      " Cycle 99 11\n",
      "Took to collect: 7.569281101226807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.610127687454224\n",
      "Time collect avg cycle: 7.964261221885681\n",
      "Time train avg cycle: 6.4172470664978025\n",
      "Total avg cycle: 14.391761147975922\n",
      "Ending epoch\n",
      "2020-10-26 02:10:28.763913 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 11 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.429271\n",
      "trainer/QF2 Loss                                    0.400911\n",
      "trainer/Policy Loss                                51.9253\n",
      "trainer/Q1 Predictions Mean                       -51.9938\n",
      "trainer/Q1 Predictions Std                         30.3255\n",
      "trainer/Q1 Predictions Max                          7.76007\n",
      "trainer/Q1 Predictions Min                       -101.895\n",
      "trainer/Q2 Predictions Mean                       -51.955\n",
      "trainer/Q2 Predictions Std                         30.3181\n",
      "trainer/Q2 Predictions Max                          7.49942\n",
      "trainer/Q2 Predictions Min                       -102.126\n",
      "trainer/Q Targets Mean                            -51.9099\n",
      "trainer/Q Targets Std                              30.3374\n",
      "trainer/Q Targets Max                               7.62267\n",
      "trainer/Q Targets Min                            -101.852\n",
      "trainer/Log Pis Mean                                3.14423\n",
      "trainer/Log Pis Std                                 2.13338\n",
      "trainer/Log Pis Max                                 9.60829\n",
      "trainer/Log Pis Min                                -4.67474\n",
      "trainer/policy/mean Mean                           -0.314568\n",
      "trainer/policy/mean Std                             0.597196\n",
      "trainer/policy/mean Max                             0.989593\n",
      "trainer/policy/mean Min                            -0.994928\n",
      "trainer/policy/normal/std Mean                      0.324192\n",
      "trainer/policy/normal/std Std                       0.196483\n",
      "trainer/policy/normal/std Max                       1.02645\n",
      "trainer/policy/normal/std Min                       0.052748\n",
      "trainer/policy/normal/log_std Mean                 -1.36955\n",
      "trainer/policy/normal/log_std Std                   0.753615\n",
      "trainer/policy/normal/log_std Max                   0.0261048\n",
      "trainer/policy/normal/log_std Min                  -2.94223\n",
      "trainer/Alpha                                       0.0149515\n",
      "trainer/Alpha Loss                                  0.606173\n",
      "exploration/num steps total                    121000\n",
      "exploration/num paths total                      2421\n",
      "exploration/path length Mean                       49.7512\n",
      "exploration/path length Std                         2.63875\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        16\n",
      "exploration/Rewards Mean                           -0.995\n",
      "exploration/Rewards Std                             0.0705337\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.5025\n",
      "exploration/Returns Std                             3.68421\n",
      "exploration/Returns Max                           -13\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.236271\n",
      "exploration/Actions Std                             0.535386\n",
      "exploration/Actions Max                             0.998797\n",
      "exploration/Actions Min                            -0.998989\n",
      "exploration/Num Paths                             201\n",
      "exploration/Average Returns                       -49.5025\n",
      "exploration/env_infos/final/is_success Mean         0.00497512\n",
      "exploration/env_infos/final/is_success Std          0.0703589\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0001\n",
      "exploration/env_infos/is_success Std                0.0099995\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                       6000\n",
      "evaluation/num paths total                        120\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.296275\n",
      "evaluation/Actions Std                              0.509382\n",
      "evaluation/Actions Max                              0.948869\n",
      "evaluation/Actions Min                             -0.987474\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.999127\n",
      "time/evaluation sampling (s)                       39.7233\n",
      "time/exploration sampling (s)                     796.446\n",
      "time/logging (s)                                    0.0271735\n",
      "time/sac training (s)                             200.104\n",
      "time/saving (s)                                     0.0146632\n",
      "time/training (s)                                   0.00722926\n",
      "time/epoch (s)                                   1037.32\n",
      "time/total (s)                                  16303.5\n",
      "Epoch                                              11\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 12\n",
      "\n",
      " Cycle 0 12\n",
      "Took to collect: 7.628800630569458\n",
      "Took to train: 6.479515790939331\n",
      "\n",
      " Cycle 1 12\n",
      "Took to collect: 8.347548007965088\n",
      "Took to train: 6.435959100723267\n",
      "\n",
      " Cycle 2 12\n",
      "Took to collect: 9.50026798248291\n",
      "Took to train: 6.4980788230896\n",
      "\n",
      " Cycle 3 12\n",
      "Took to collect: 8.144457817077637\n",
      "Took to train: 6.540552616119385\n",
      "\n",
      " Cycle 4 12\n",
      "Took to collect: 8.222286462783813\n",
      "Took to train: 6.494180202484131\n",
      "\n",
      " Cycle 5 12\n",
      "Took to collect: 7.559881210327148\n",
      "Took to train: 6.535620927810669\n",
      "\n",
      " Cycle 6 12\n",
      "Took to collect: 7.921149730682373\n",
      "Took to train: 6.445738792419434\n",
      "\n",
      " Cycle 7 12\n",
      "Took to collect: 8.640329360961914\n",
      "Took to train: 6.4424309730529785\n",
      "\n",
      " Cycle 8 12\n",
      "Took to collect: 7.978156566619873\n",
      "Took to train: 6.446026563644409\n",
      "\n",
      " Cycle 9 12\n",
      "Took to collect: 8.400733232498169\n",
      "Took to train: 6.43561315536499\n",
      "\n",
      " Cycle 10 12\n",
      "Took to collect: 7.004606246948242\n",
      "Took to train: 6.43200421333313\n",
      "\n",
      " Cycle 11 12\n",
      "Took to collect: 9.215128183364868\n",
      "Took to train: 6.492390394210815\n",
      "\n",
      " Cycle 12 12\n",
      "Took to collect: 6.599043369293213\n",
      "Took to train: 6.495601177215576\n",
      "\n",
      " Cycle 13 12\n",
      "Took to collect: 8.252104043960571\n",
      "Took to train: 6.465188980102539\n",
      "\n",
      " Cycle 14 12\n",
      "Took to collect: 8.1721351146698\n",
      "Took to train: 6.518802881240845\n",
      "\n",
      " Cycle 15 12\n",
      "Took to collect: 7.641621351242065\n",
      "Took to train: 6.4801952838897705\n",
      "\n",
      " Cycle 16 12\n",
      "Took to collect: 6.6491639614105225\n",
      "Took to train: 6.460330009460449\n",
      "\n",
      " Cycle 17 12\n",
      "Took to collect: 8.381612777709961\n",
      "Took to train: 6.482677459716797\n",
      "\n",
      " Cycle 18 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 8.170064449310303\n",
      "Took to train: 6.484358787536621\n",
      "\n",
      " Cycle 19 12\n",
      "Took to collect: 7.1605610847473145\n",
      "Took to train: 6.469273805618286\n",
      "\n",
      " Cycle 20 12\n",
      "Took to collect: 7.680448055267334\n",
      "Took to train: 6.478957414627075\n",
      "\n",
      " Cycle 21 12\n",
      "Took to collect: 7.278374671936035\n",
      "Took to train: 6.499076843261719\n",
      "\n",
      " Cycle 22 12\n",
      "Took to collect: 7.869381904602051\n",
      "Took to train: 6.3296592235565186\n",
      "\n",
      " Cycle 23 12\n",
      "Took to collect: 8.04303503036499\n",
      "Took to train: 6.411823749542236\n",
      "\n",
      " Cycle 24 12\n",
      "Took to collect: 8.395182132720947\n",
      "Took to train: 6.475703239440918\n",
      "\n",
      " Cycle 25 12\n",
      "Took to collect: 7.228020191192627\n",
      "Took to train: 6.470162391662598\n",
      "\n",
      " Cycle 26 12\n",
      "Took to collect: 6.316341400146484\n",
      "Took to train: 6.474181413650513\n",
      "\n",
      " Cycle 27 12\n",
      "Took to collect: 6.466301679611206\n",
      "Took to train: 6.412808656692505\n",
      "\n",
      " Cycle 28 12\n",
      "Took to collect: 9.171809434890747\n",
      "Took to train: 6.507103443145752\n",
      "\n",
      " Cycle 29 12\n",
      "Took to collect: 7.61755633354187\n",
      "Took to train: 6.476137399673462\n",
      "\n",
      " Cycle 30 12\n",
      "Took to collect: 9.418551683425903\n",
      "Took to train: 6.487314939498901\n",
      "\n",
      " Cycle 31 12\n",
      "Took to collect: 8.927884578704834\n",
      "Took to train: 6.455049276351929\n",
      "\n",
      " Cycle 32 12\n",
      "Took to collect: 9.887332916259766\n",
      "Took to train: 6.419532537460327\n",
      "\n",
      " Cycle 33 12\n",
      "Took to collect: 6.51311182975769\n",
      "Took to train: 6.345284700393677\n",
      "\n",
      " Cycle 34 12\n",
      "Took to collect: 7.776077508926392\n",
      "Took to train: 6.38217568397522\n",
      "\n",
      " Cycle 35 12\n",
      "Took to collect: 8.878964185714722\n",
      "Took to train: 6.285999059677124\n",
      "\n",
      " Cycle 36 12\n",
      "Took to collect: 5.945089340209961\n",
      "Took to train: 6.3740458488464355\n",
      "\n",
      " Cycle 37 12\n",
      "Took to collect: 8.411046981811523\n",
      "Took to train: 6.367838382720947\n",
      "\n",
      " Cycle 38 12\n",
      "Took to collect: 8.838764905929565\n",
      "Took to train: 6.352283954620361\n",
      "\n",
      " Cycle 39 12\n",
      "Took to collect: 7.2687766551971436\n",
      "Took to train: 6.397462368011475\n",
      "\n",
      " Cycle 40 12\n",
      "Took to collect: 6.991992473602295\n",
      "Took to train: 6.382808208465576\n",
      "\n",
      " Cycle 41 12\n",
      "Took to collect: 6.995802402496338\n",
      "Took to train: 6.385919809341431\n",
      "\n",
      " Cycle 42 12\n",
      "Took to collect: 7.390096664428711\n",
      "Took to train: 6.392863750457764\n",
      "\n",
      " Cycle 43 12\n",
      "Took to collect: 8.151315450668335\n",
      "Took to train: 6.395024299621582\n",
      "\n",
      " Cycle 44 12\n",
      "Took to collect: 8.613042831420898\n",
      "Took to train: 6.469172716140747\n",
      "\n",
      " Cycle 45 12\n",
      "Took to collect: 9.676311254501343\n",
      "Took to train: 6.466330289840698\n",
      "\n",
      " Cycle 46 12\n",
      "Took to collect: 10.142343997955322\n",
      "Took to train: 6.42429518699646\n",
      "\n",
      " Cycle 47 12\n",
      "Took to collect: 9.358855724334717\n",
      "Took to train: 6.2826550006866455\n",
      "\n",
      " Cycle 48 12\n",
      "Took to collect: 6.645725250244141\n",
      "Took to train: 6.271286964416504\n",
      "\n",
      " Cycle 49 12\n",
      "Took to collect: 6.397868871688843\n",
      "Took to train: 6.286935567855835\n",
      "\n",
      " Cycle 50 12\n",
      "Took to collect: 7.704373598098755\n",
      "Took to train: 6.419501781463623\n",
      "\n",
      " Cycle 51 12\n",
      "Took to collect: 7.373609781265259\n",
      "Took to train: 6.449506521224976\n",
      "\n",
      " Cycle 52 12\n",
      "Took to collect: 8.023160934448242\n",
      "Took to train: 6.38994026184082\n",
      "\n",
      " Cycle 53 12\n",
      "Took to collect: 7.404474973678589\n",
      "Took to train: 6.402402877807617\n",
      "\n",
      " Cycle 54 12\n",
      "Took to collect: 7.142845392227173\n",
      "Took to train: 6.470658540725708\n",
      "\n",
      " Cycle 55 12\n",
      "Took to collect: 8.128016471862793\n",
      "Took to train: 6.4626593589782715\n",
      "\n",
      " Cycle 56 12\n",
      "Took to collect: 9.013145685195923\n",
      "Took to train: 6.482103586196899\n",
      "\n",
      " Cycle 57 12\n",
      "Took to collect: 8.298829555511475\n",
      "Took to train: 6.467663526535034\n",
      "\n",
      " Cycle 58 12\n",
      "Took to collect: 6.667720794677734\n",
      "Took to train: 6.448699235916138\n",
      "\n",
      " Cycle 59 12\n",
      "Took to collect: 2.8043832778930664\n",
      "Took to train: 6.490018129348755\n",
      "\n",
      " Cycle 60 12\n",
      "Took to collect: 7.799682378768921\n",
      "Took to train: 6.509063243865967\n",
      "\n",
      " Cycle 61 12\n",
      "Took to collect: 4.076684474945068\n",
      "Took to train: 6.5088791847229\n",
      "\n",
      " Cycle 62 12\n",
      "Took to collect: 6.959167718887329\n",
      "Took to train: 6.465847969055176\n",
      "\n",
      " Cycle 63 12\n",
      "Took to collect: 8.827407121658325\n",
      "Took to train: 6.480983018875122\n",
      "\n",
      " Cycle 64 12\n",
      "Took to collect: 4.796114444732666\n",
      "Took to train: 6.423109292984009\n",
      "\n",
      " Cycle 65 12\n",
      "Took to collect: 7.525686502456665\n",
      "Took to train: 6.370335817337036\n",
      "\n",
      " Cycle 66 12\n",
      "Took to collect: 7.373000621795654\n",
      "Took to train: 6.406143665313721\n",
      "\n",
      " Cycle 67 12\n",
      "Took to collect: 4.76310133934021\n",
      "Took to train: 6.478853464126587\n",
      "\n",
      " Cycle 68 12\n",
      "Took to collect: 8.857499599456787\n",
      "Took to train: 6.493373394012451\n",
      "\n",
      " Cycle 69 12\n",
      "Took to collect: 7.017632246017456\n",
      "Took to train: 6.497181415557861\n",
      "\n",
      " Cycle 70 12\n",
      "Took to collect: 8.714255094528198\n",
      "Took to train: 6.4706130027771\n",
      "\n",
      " Cycle 71 12\n",
      "Took to collect: 7.535456418991089\n",
      "Took to train: 6.470826148986816\n",
      "\n",
      " Cycle 72 12\n",
      "Took to collect: 7.858869314193726\n",
      "Took to train: 6.443260908126831\n",
      "\n",
      " Cycle 73 12\n",
      "Took to collect: 8.299944877624512\n",
      "Took to train: 6.464663028717041\n",
      "\n",
      " Cycle 74 12\n",
      "Took to collect: 7.653656959533691\n",
      "Took to train: 6.3859617710113525\n",
      "\n",
      " Cycle 75 12\n",
      "Took to collect: 7.235090017318726\n",
      "Took to train: 6.380779504776001\n",
      "\n",
      " Cycle 76 12\n",
      "Took to collect: 6.7944440841674805\n",
      "Took to train: 6.350108861923218\n",
      "\n",
      " Cycle 77 12\n",
      "Took to collect: 7.3413474559783936\n",
      "Took to train: 6.470199823379517\n",
      "\n",
      " Cycle 78 12\n",
      "Took to collect: 6.97282338142395\n",
      "Took to train: 6.457313060760498\n",
      "\n",
      " Cycle 79 12\n",
      "Took to collect: 7.250475645065308\n",
      "Took to train: 6.438100337982178\n",
      "\n",
      " Cycle 80 12\n",
      "Took to collect: 7.071278095245361\n",
      "Took to train: 6.45493745803833\n",
      "\n",
      " Cycle 81 12\n",
      "Took to collect: 8.015844345092773\n",
      "Took to train: 6.44013237953186\n",
      "\n",
      " Cycle 82 12\n",
      "Took to collect: 6.71343994140625\n",
      "Took to train: 6.339183330535889\n",
      "\n",
      " Cycle 83 12\n",
      "Took to collect: 7.065694332122803\n",
      "Took to train: 6.332902669906616\n",
      "\n",
      " Cycle 84 12\n",
      "Took to collect: 6.393245697021484\n",
      "Took to train: 6.44092321395874\n",
      "\n",
      " Cycle 85 12\n",
      "Took to collect: 8.338701725006104\n",
      "Took to train: 6.4383909702301025\n",
      "\n",
      " Cycle 86 12\n",
      "Took to collect: 7.655414581298828\n",
      "Took to train: 6.418917894363403\n",
      "\n",
      " Cycle 87 12\n",
      "Took to collect: 6.8293116092681885\n",
      "Took to train: 6.402631759643555\n",
      "\n",
      " Cycle 88 12\n",
      "Took to collect: 8.815013408660889\n",
      "Took to train: 6.331124782562256\n",
      "\n",
      " Cycle 89 12\n",
      "Took to collect: 7.356313705444336\n",
      "Took to train: 6.325837850570679\n",
      "\n",
      " Cycle 90 12\n",
      "Took to collect: 6.73877739906311\n",
      "Took to train: 6.429756164550781\n",
      "\n",
      " Cycle 91 12\n",
      "Took to collect: 7.5234668254852295\n",
      "Took to train: 6.4703710079193115\n",
      "\n",
      " Cycle 92 12\n",
      "Took to collect: 7.921595335006714\n",
      "Took to train: 6.416034698486328\n",
      "\n",
      " Cycle 93 12\n",
      "Took to collect: 7.890893459320068\n",
      "Took to train: 6.295424222946167\n",
      "\n",
      " Cycle 94 12\n",
      "Took to collect: 7.6462342739105225\n",
      "Took to train: 6.483301877975464\n",
      "\n",
      " Cycle 95 12\n",
      "Took to collect: 6.2326531410217285\n",
      "Took to train: 6.37717866897583\n",
      "\n",
      " Cycle 96 12\n",
      "Took to collect: 6.518750905990601\n",
      "Took to train: 6.353726863861084\n",
      "\n",
      " Cycle 97 12\n",
      "Took to collect: 8.014594793319702\n",
      "Took to train: 6.4379026889801025\n",
      "\n",
      " Cycle 98 12\n",
      "Took to collect: 8.951414585113525\n",
      "Took to train: 6.485624313354492\n",
      "\n",
      " Cycle 99 12\n",
      "Took to collect: 7.489888906478882\n",
      "Took to train: 6.579959154129028\n",
      "Time collect avg cycle: 7.632804851531983\n",
      "Time train avg cycle: 6.433974449634552\n",
      "Total avg cycle: 14.07740096092224\n",
      "Ending epoch\n",
      "2020-10-26 02:34:33.945186 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 12 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.433435\n",
      "trainer/QF2 Loss                                    0.413867\n",
      "trainer/Policy Loss                                53.6723\n",
      "trainer/Q1 Predictions Mean                       -53.7346\n",
      "trainer/Q1 Predictions Std                         29.6888\n",
      "trainer/Q1 Predictions Max                          5.36695\n",
      "trainer/Q1 Predictions Min                       -102.263\n",
      "trainer/Q2 Predictions Mean                       -53.6787\n",
      "trainer/Q2 Predictions Std                         29.6929\n",
      "trainer/Q2 Predictions Max                          5.401\n",
      "trainer/Q2 Predictions Min                       -102.132\n",
      "trainer/Q Targets Mean                            -53.6255\n",
      "trainer/Q Targets Std                              29.7409\n",
      "trainer/Q Targets Max                               5.52205\n",
      "trainer/Q Targets Min                            -102.824\n",
      "trainer/Log Pis Mean                                3.36534\n",
      "trainer/Log Pis Std                                 2.31488\n",
      "trainer/Log Pis Max                                10.3053\n",
      "trainer/Log Pis Min                                -4.97744\n",
      "trainer/policy/mean Mean                           -0.254125\n",
      "trainer/policy/mean Std                             0.638884\n",
      "trainer/policy/mean Max                             0.993958\n",
      "trainer/policy/mean Min                            -0.995742\n",
      "trainer/policy/normal/std Mean                      0.33194\n",
      "trainer/policy/normal/std Std                       0.20037\n",
      "trainer/policy/normal/std Max                       1.01299\n",
      "trainer/policy/normal/std Min                       0.0502575\n",
      "trainer/policy/normal/log_std Mean                 -1.35677\n",
      "trainer/policy/normal/log_std Std                   0.78226\n",
      "trainer/policy/normal/log_std Max                   0.0129073\n",
      "trainer/policy/normal/log_std Min                  -2.9906\n",
      "trainer/Alpha                                       0.0156513\n",
      "trainer/Alpha Loss                                  1.51878\n",
      "exploration/num steps total                    131000\n",
      "exploration/num paths total                      2621\n",
      "exploration/path length Mean                       50\n",
      "exploration/path length Std                         0\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        50\n",
      "exploration/Rewards Mean                           -0.9969\n",
      "exploration/Rewards Std                             0.0555913\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.845\n",
      "exploration/Returns Std                             1.30421\n",
      "exploration/Returns Max                           -35\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.230626\n",
      "exploration/Actions Std                             0.572409\n",
      "exploration/Actions Max                             0.998898\n",
      "exploration/Actions Min                            -0.999253\n",
      "exploration/Num Paths                             200\n",
      "exploration/Average Returns                       -49.845\n",
      "exploration/env_infos/final/is_success Mean         0\n",
      "exploration/env_infos/final/is_success Std          0\n",
      "exploration/env_infos/final/is_success Max          0\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0\n",
      "exploration/env_infos/is_success Std                0\n",
      "exploration/env_infos/is_success Max                0\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                       6500\n",
      "evaluation/num paths total                        130\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.304813\n",
      "evaluation/Actions Std                              0.489286\n",
      "evaluation/Actions Max                              0.967588\n",
      "evaluation/Actions Min                             -0.983397\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               1.03635\n",
      "time/evaluation sampling (s)                       37.3784\n",
      "time/exploration sampling (s)                     763.3\n",
      "time/logging (s)                                    0.0312137\n",
      "time/sac training (s)                             200.672\n",
      "time/saving (s)                                     0.0138962\n",
      "time/training (s)                                   0.00713037\n",
      "time/epoch (s)                                   1002.44\n",
      "time/total (s)                                  17748.5\n",
      "Epoch                                              12\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 13\n",
      "\n",
      " Cycle 0 13\n",
      "Took to collect: 8.277600049972534\n",
      "Took to train: 6.470418691635132\n",
      "\n",
      " Cycle 1 13\n",
      "Took to collect: 7.79324197769165\n",
      "Took to train: 6.376192331314087\n",
      "\n",
      " Cycle 2 13\n",
      "Took to collect: 5.876034498214722\n",
      "Took to train: 6.386435508728027\n",
      "\n",
      " Cycle 3 13\n",
      "Took to collect: 9.175522089004517\n",
      "Took to train: 6.390628099441528\n",
      "\n",
      " Cycle 4 13\n",
      "Took to collect: 7.5016632080078125\n",
      "Took to train: 6.375540494918823\n",
      "\n",
      " Cycle 5 13\n",
      "Took to collect: 9.77353286743164\n",
      "Took to train: 6.374823570251465\n",
      "\n",
      " Cycle 6 13\n",
      "Took to collect: 8.559049844741821\n",
      "Took to train: 6.394575595855713\n",
      "\n",
      " Cycle 7 13\n",
      "Took to collect: 7.45958685874939\n",
      "Took to train: 6.384232759475708\n",
      "\n",
      " Cycle 8 13\n",
      "Took to collect: 8.83525276184082\n",
      "Took to train: 6.3894219398498535\n",
      "\n",
      " Cycle 9 13\n",
      "Took to collect: 7.672406435012817\n",
      "Took to train: 6.4483489990234375\n",
      "\n",
      " Cycle 10 13\n",
      "Took to collect: 7.144129991531372\n",
      "Took to train: 6.47113823890686\n",
      "\n",
      " Cycle 11 13\n",
      "Took to collect: 7.486395597457886\n",
      "Took to train: 6.407650709152222\n",
      "\n",
      " Cycle 12 13\n",
      "Took to collect: 8.981727123260498\n",
      "Took to train: 6.3145835399627686\n",
      "\n",
      " Cycle 13 13\n",
      "Took to collect: 6.880308628082275\n",
      "Took to train: 6.438938856124878\n",
      "\n",
      " Cycle 14 13\n",
      "Took to collect: 7.421555519104004\n",
      "Took to train: 6.48974871635437\n",
      "\n",
      " Cycle 15 13\n",
      "Took to collect: 8.166667222976685\n",
      "Took to train: 6.358374118804932\n",
      "\n",
      " Cycle 16 13\n",
      "Took to collect: 9.880444049835205\n",
      "Took to train: 6.424581527709961\n",
      "\n",
      " Cycle 17 13\n",
      "Took to collect: 7.1503586769104\n",
      "Took to train: 6.497133493423462\n",
      "\n",
      " Cycle 18 13\n",
      "Took to collect: 7.6013453006744385\n",
      "Took to train: 6.462291240692139\n",
      "\n",
      " Cycle 19 13\n",
      "Took to collect: 6.9457104206085205\n",
      "Took to train: 6.4982664585113525\n",
      "\n",
      " Cycle 20 13\n",
      "Took to collect: 8.770817756652832\n",
      "Took to train: 6.422057628631592\n",
      "\n",
      " Cycle 21 13\n",
      "Took to collect: 7.724460124969482\n",
      "Took to train: 6.389028787612915\n",
      "\n",
      " Cycle 22 13\n",
      "Took to collect: 9.551359415054321\n",
      "Took to train: 6.373399972915649\n",
      "\n",
      " Cycle 23 13\n",
      "Took to collect: 6.8677167892456055\n",
      "Took to train: 6.394762277603149\n",
      "\n",
      " Cycle 24 13\n",
      "Took to collect: 8.546568393707275\n",
      "Took to train: 6.383908987045288\n",
      "\n",
      " Cycle 25 13\n",
      "Took to collect: 7.18507981300354\n",
      "Took to train: 6.383794069290161\n",
      "\n",
      " Cycle 26 13\n",
      "Took to collect: 6.164601802825928\n",
      "Took to train: 6.394941806793213\n",
      "\n",
      " Cycle 27 13\n",
      "Took to collect: 8.987772941589355\n",
      "Took to train: 6.386063098907471\n",
      "\n",
      " Cycle 28 13\n",
      "Took to collect: 7.870222568511963\n",
      "Took to train: 6.38675332069397\n",
      "\n",
      " Cycle 29 13\n",
      "Took to collect: 6.26121973991394\n",
      "Took to train: 6.386641025543213\n",
      "\n",
      " Cycle 30 13\n",
      "Took to collect: 8.0832839012146\n",
      "Took to train: 6.380484104156494\n",
      "\n",
      " Cycle 31 13\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 8.013086795806885\n",
      "Took to train: 6.382959604263306\n",
      "\n",
      " Cycle 32 13\n",
      "Took to collect: 8.883528709411621\n",
      "Took to train: 6.379405498504639\n",
      "\n",
      " Cycle 33 13\n",
      "Took to collect: 6.449084043502808\n",
      "Took to train: 6.385667324066162\n",
      "\n",
      " Cycle 34 13\n",
      "Took to collect: 9.426352262496948\n",
      "Took to train: 6.384366512298584\n",
      "\n",
      " Cycle 35 13\n",
      "Took to collect: 9.348387718200684\n",
      "Took to train: 6.376404762268066\n",
      "\n",
      " Cycle 36 13\n",
      "Took to collect: 7.458492994308472\n",
      "Took to train: 6.386916399002075\n",
      "\n",
      " Cycle 37 13\n",
      "Took to collect: 7.726836681365967\n",
      "Took to train: 6.320194244384766\n",
      "\n",
      " Cycle 38 13\n",
      "Took to collect: 8.796518087387085\n",
      "Took to train: 6.321837663650513\n",
      "\n",
      " Cycle 39 13\n",
      "Took to collect: 7.371352910995483\n",
      "Took to train: 6.317877292633057\n",
      "\n",
      " Cycle 40 13\n",
      "Took to collect: 6.387377023696899\n",
      "Took to train: 6.32907509803772\n",
      "\n",
      " Cycle 41 13\n",
      "Took to collect: 8.79894733428955\n",
      "Took to train: 6.381133556365967\n",
      "\n",
      " Cycle 42 13\n",
      "Took to collect: 8.314412832260132\n",
      "Took to train: 6.408713102340698\n",
      "\n",
      " Cycle 43 13\n",
      "Took to collect: 7.674934387207031\n",
      "Took to train: 6.413970947265625\n",
      "\n",
      " Cycle 44 13\n",
      "Took to collect: 8.925888776779175\n",
      "Took to train: 6.384037017822266\n",
      "\n",
      " Cycle 45 13\n",
      "Took to collect: 7.725512266159058\n",
      "Took to train: 6.387566089630127\n",
      "\n",
      " Cycle 46 13\n",
      "Took to collect: 7.338050603866577\n",
      "Took to train: 6.390410661697388\n",
      "\n",
      " Cycle 47 13\n",
      "Took to collect: 7.914066553115845\n",
      "Took to train: 6.385560989379883\n",
      "\n",
      " Cycle 48 13\n",
      "Took to collect: 6.775568008422852\n",
      "Took to train: 6.390480041503906\n",
      "\n",
      " Cycle 49 13\n",
      "Took to collect: 6.671553134918213\n",
      "Took to train: 6.432111740112305\n",
      "\n",
      " Cycle 50 13\n",
      "Took to collect: 7.421727418899536\n",
      "Took to train: 6.378124713897705\n",
      "\n",
      " Cycle 51 13\n",
      "Took to collect: 8.687922239303589\n",
      "Took to train: 6.37088680267334\n",
      "\n",
      " Cycle 52 13\n",
      "Took to collect: 7.3713059425354\n",
      "Took to train: 6.398233413696289\n",
      "\n",
      " Cycle 53 13\n",
      "Took to collect: 8.740087270736694\n",
      "Took to train: 6.361453056335449\n",
      "\n",
      " Cycle 54 13\n",
      "Took to collect: 7.635505676269531\n",
      "Took to train: 6.378126382827759\n",
      "\n",
      " Cycle 55 13\n",
      "Took to collect: 8.176912546157837\n",
      "Took to train: 6.505179166793823\n",
      "\n",
      " Cycle 56 13\n",
      "Took to collect: 8.027175664901733\n",
      "Took to train: 6.405578136444092\n",
      "\n",
      " Cycle 57 13\n",
      "Took to collect: 7.7510085105896\n",
      "Took to train: 6.382197618484497\n",
      "\n",
      " Cycle 58 13\n",
      "Took to collect: 8.780814170837402\n",
      "Took to train: 6.408891916275024\n",
      "\n",
      " Cycle 59 13\n",
      "Took to collect: 8.589755535125732\n",
      "Took to train: 6.391481399536133\n",
      "\n",
      " Cycle 60 13\n",
      "Took to collect: 8.319329023361206\n",
      "Took to train: 6.401948690414429\n",
      "\n",
      " Cycle 61 13\n",
      "Took to collect: 8.080212831497192\n",
      "Took to train: 6.3921897411346436\n",
      "\n",
      " Cycle 62 13\n",
      "Took to collect: 6.557180881500244\n",
      "Took to train: 6.382113933563232\n",
      "\n",
      " Cycle 63 13\n",
      "Took to collect: 8.999454259872437\n",
      "Took to train: 6.398401260375977\n",
      "\n",
      " Cycle 64 13\n",
      "Took to collect: 8.267046451568604\n",
      "Took to train: 6.387021064758301\n",
      "\n",
      " Cycle 65 13\n",
      "Took to collect: 6.51234769821167\n",
      "Took to train: 6.4836719036102295\n",
      "\n",
      " Cycle 66 13\n",
      "Took to collect: 8.447463274002075\n",
      "Took to train: 6.37758731842041\n",
      "\n",
      " Cycle 67 13\n",
      "Took to collect: 7.392967462539673\n",
      "Took to train: 6.388249635696411\n",
      "\n",
      " Cycle 68 13\n",
      "Took to collect: 8.429925918579102\n",
      "Took to train: 6.387551546096802\n",
      "\n",
      " Cycle 69 13\n",
      "Took to collect: 7.952950954437256\n",
      "Took to train: 6.379534721374512\n",
      "\n",
      " Cycle 70 13\n",
      "Took to collect: 6.883614778518677\n",
      "Took to train: 6.383366107940674\n",
      "\n",
      " Cycle 71 13\n",
      "Took to collect: 7.574888467788696\n",
      "Took to train: 6.362985134124756\n",
      "\n",
      " Cycle 72 13\n",
      "Took to collect: 8.950413465499878\n",
      "Took to train: 6.384131193161011\n",
      "\n",
      " Cycle 73 13\n",
      "Took to collect: 8.02748417854309\n",
      "Took to train: 6.385256290435791\n",
      "\n",
      " Cycle 74 13\n",
      "Took to collect: 8.132781982421875\n",
      "Took to train: 6.461389780044556\n",
      "\n",
      " Cycle 75 13\n",
      "Took to collect: 7.580099105834961\n",
      "Took to train: 6.455575466156006\n",
      "\n",
      " Cycle 76 13\n",
      "Took to collect: 8.684331178665161\n",
      "Took to train: 6.404969215393066\n",
      "\n",
      " Cycle 77 13\n",
      "Took to collect: 8.25274920463562\n",
      "Took to train: 6.386831998825073\n",
      "\n",
      " Cycle 78 13\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 8.750709533691406\n",
      "Took to train: 6.404001235961914\n",
      "\n",
      " Cycle 79 13\n",
      "Took to collect: 7.950852870941162\n",
      "Took to train: 6.388861656188965\n",
      "\n",
      " Cycle 80 13\n",
      "Took to collect: 8.004375219345093\n",
      "Took to train: 6.401622533798218\n",
      "\n",
      " Cycle 81 13\n",
      "Took to collect: 7.326294660568237\n",
      "Took to train: 6.429206371307373\n",
      "\n",
      " Cycle 82 13\n",
      "Took to collect: 6.163011312484741\n",
      "Took to train: 6.352190971374512\n",
      "\n",
      " Cycle 83 13\n",
      "Took to collect: 9.554713726043701\n",
      "Took to train: 6.386440753936768\n",
      "\n",
      " Cycle 84 13\n",
      "Took to collect: 7.444683074951172\n",
      "Took to train: 6.447285413742065\n",
      "\n",
      " Cycle 85 13\n",
      "Took to collect: 7.94662070274353\n",
      "Took to train: 6.532577753067017\n",
      "\n",
      " Cycle 86 13\n",
      "Took to collect: 8.18743634223938\n",
      "Took to train: 6.51814079284668\n",
      "\n",
      " Cycle 87 13\n",
      "Took to collect: 8.3010892868042\n",
      "Took to train: 6.534692049026489\n",
      "\n",
      " Cycle 88 13\n",
      "Took to collect: 8.013020992279053\n",
      "Took to train: 6.509232044219971\n",
      "\n",
      " Cycle 89 13\n",
      "Took to collect: 8.036846399307251\n",
      "Took to train: 6.497263669967651\n",
      "\n",
      " Cycle 90 13\n",
      "Took to collect: 7.004757404327393\n",
      "Took to train: 6.375813961029053\n",
      "\n",
      " Cycle 91 13\n",
      "Took to collect: 8.030759572982788\n",
      "Took to train: 6.368981122970581\n",
      "\n",
      " Cycle 92 13\n",
      "Took to collect: 7.891902446746826\n",
      "Took to train: 6.448148488998413\n",
      "\n",
      " Cycle 93 13\n",
      "Took to collect: 7.519777536392212\n",
      "Took to train: 6.473224639892578\n",
      "\n",
      " Cycle 94 13\n",
      "Took to collect: 7.810313940048218\n",
      "Took to train: 6.486407041549683\n",
      "\n",
      " Cycle 95 13\n",
      "Took to collect: 8.599027156829834\n",
      "Took to train: 6.4311137199401855\n",
      "\n",
      " Cycle 96 13\n",
      "Took to collect: 7.785084009170532\n",
      "Took to train: 6.303714752197266\n",
      "\n",
      " Cycle 97 13\n",
      "Took to collect: 6.709290981292725\n",
      "Took to train: 6.3292341232299805\n",
      "\n",
      " Cycle 98 13\n",
      "Took to collect: 8.332535028457642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.422053813934326\n",
      "\n",
      " Cycle 99 13\n",
      "Took to collect: 7.844780683517456\n",
      "Took to train: 6.496229648590088\n",
      "Time collect avg cycle: 7.920309264659881\n",
      "Time train avg cycle: 6.405132126808167\n",
      "Total avg cycle: 14.33559710741043\n",
      "Ending epoch\n",
      "2020-10-26 02:59:06.992524 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 13 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.527651\n",
      "trainer/QF2 Loss                                    0.603332\n",
      "trainer/Policy Loss                                55.6385\n",
      "trainer/Q1 Predictions Mean                       -55.5705\n",
      "trainer/Q1 Predictions Std                         29.8027\n",
      "trainer/Q1 Predictions Max                          3.87952\n",
      "trainer/Q1 Predictions Min                       -104.044\n",
      "trainer/Q2 Predictions Mean                       -55.7305\n",
      "trainer/Q2 Predictions Std                         29.7794\n",
      "trainer/Q2 Predictions Max                          3.14939\n",
      "trainer/Q2 Predictions Min                       -104.336\n",
      "trainer/Q Targets Mean                            -55.3561\n",
      "trainer/Q Targets Std                              29.8348\n",
      "trainer/Q Targets Max                               3.90524\n",
      "trainer/Q Targets Min                            -103.717\n",
      "trainer/Log Pis Mean                                2.85582\n",
      "trainer/Log Pis Std                                 2.02318\n",
      "trainer/Log Pis Max                                10.1977\n",
      "trainer/Log Pis Min                                -3.81683\n",
      "trainer/policy/mean Mean                           -0.203227\n",
      "trainer/policy/mean Std                             0.644062\n",
      "trainer/policy/mean Max                             0.989891\n",
      "trainer/policy/mean Min                            -0.989376\n",
      "trainer/policy/normal/std Mean                      0.34278\n",
      "trainer/policy/normal/std Std                       0.217599\n",
      "trainer/policy/normal/std Max                       1.21649\n",
      "trainer/policy/normal/std Min                       0.0476512\n",
      "trainer/policy/normal/log_std Mean                 -1.33249\n",
      "trainer/policy/normal/log_std Std                   0.785769\n",
      "trainer/policy/normal/log_std Max                   0.195969\n",
      "trainer/policy/normal/log_std Min                  -3.04385\n",
      "trainer/Alpha                                       0.015699\n",
      "trainer/Alpha Loss                                 -0.598944\n",
      "exploration/num steps total                    141000\n",
      "exploration/num paths total                      2823\n",
      "exploration/path length Mean                       49.505\n",
      "exploration/path length Std                         4.04216\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         9\n",
      "exploration/Rewards Mean                           -0.9966\n",
      "exploration/Rewards Std                             0.0582103\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.3366\n",
      "exploration/Returns Std                             4.27351\n",
      "exploration/Returns Max                            -8\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.259006\n",
      "exploration/Actions Std                             0.585553\n",
      "exploration/Actions Max                             0.999856\n",
      "exploration/Actions Min                            -0.999871\n",
      "exploration/Num Paths                             202\n",
      "exploration/Average Returns                       -49.3366\n",
      "exploration/env_infos/final/is_success Mean         0.00990099\n",
      "exploration/env_infos/final/is_success Std          0.0990099\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0002\n",
      "exploration/env_infos/is_success Std                0.0141407\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                       6962\n",
      "evaluation/num paths total                        140\n",
      "evaluation/path length Mean                        46.2\n",
      "evaluation/path length Std                         11.4\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         12\n",
      "evaluation/Rewards Mean                            -0.995671\n",
      "evaluation/Rewards Std                              0.0656526\n",
      "evaluation/Rewards Max                             -0\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -46\n",
      "evaluation/Returns Std                             12\n",
      "evaluation/Returns Max                            -10\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.250017\n",
      "evaluation/Actions Std                              0.467451\n",
      "evaluation/Actions Max                              0.969444\n",
      "evaluation/Actions Min                             -0.977244\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -46\n",
      "evaluation/env_infos/final/is_success Mean          0.1\n",
      "evaluation/env_infos/final/is_success Std           0.3\n",
      "evaluation/env_infos/final/is_success Max           1\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0.0021645\n",
      "evaluation/env_infos/is_success Std                 0.0464738\n",
      "evaluation/env_infos/is_success Max                 1\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.990413\n",
      "time/evaluation sampling (s)                       39.4217\n",
      "time/exploration sampling (s)                     792.05\n",
      "time/logging (s)                                    0.0278373\n",
      "time/sac training (s)                             201.411\n",
      "time/saving (s)                                     0.0139088\n",
      "time/training (s)                                   0.0070322\n",
      "time/epoch (s)                                   1033.92\n",
      "time/total (s)                                  19221.3\n",
      "Epoch                                              13\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 14\n",
      "\n",
      " Cycle 0 14\n",
      "Took to collect: 7.9100775718688965\n",
      "Took to train: 6.493772029876709\n",
      "\n",
      " Cycle 1 14\n",
      "Took to collect: 8.262694597244263\n",
      "Took to train: 6.468811988830566\n",
      "\n",
      " Cycle 2 14\n",
      "Took to collect: 7.117553234100342\n",
      "Took to train: 6.450620889663696\n",
      "\n",
      " Cycle 3 14\n",
      "Took to collect: 7.970227479934692\n",
      "Took to train: 6.445830583572388\n",
      "\n",
      " Cycle 4 14\n",
      "Took to collect: 6.681453466415405\n",
      "Took to train: 6.444589138031006\n",
      "\n",
      " Cycle 5 14\n",
      "Took to collect: 8.381930589675903\n",
      "Took to train: 6.285994291305542\n",
      "\n",
      " Cycle 6 14\n",
      "Took to collect: 7.621636867523193\n",
      "Took to train: 6.293275356292725\n",
      "\n",
      " Cycle 7 14\n",
      "Took to collect: 8.301422119140625\n",
      "Took to train: 6.310791254043579\n",
      "\n",
      " Cycle 8 14\n",
      "Took to collect: 8.01772689819336\n",
      "Took to train: 6.283082962036133\n",
      "\n",
      " Cycle 9 14\n",
      "Took to collect: 9.576666355133057\n",
      "Took to train: 6.369719505310059\n",
      "\n",
      " Cycle 10 14\n",
      "Took to collect: 7.068178176879883\n",
      "Took to train: 6.401750802993774\n",
      "\n",
      " Cycle 11 14\n",
      "Took to collect: 6.87251353263855\n",
      "Took to train: 6.444014310836792\n",
      "\n",
      " Cycle 12 14\n",
      "Took to collect: 7.502067804336548\n",
      "Took to train: 6.425645351409912\n",
      "\n",
      " Cycle 13 14\n",
      "Took to collect: 7.406964063644409\n",
      "Took to train: 6.246636390686035\n",
      "\n",
      " Cycle 14 14\n",
      "Took to collect: 9.60327696800232\n",
      "Took to train: 6.24969744682312\n",
      "\n",
      " Cycle 15 14\n",
      "Took to collect: 6.431126117706299\n",
      "Took to train: 6.244030475616455\n",
      "\n",
      " Cycle 16 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 7.816412925720215\n",
      "Took to train: 6.260714530944824\n",
      "\n",
      " Cycle 17 14\n",
      "Took to collect: 7.9375224113464355\n",
      "Took to train: 6.253999471664429\n",
      "\n",
      " Cycle 18 14\n",
      "Took to collect: 6.869809627532959\n",
      "Took to train: 6.414054870605469\n",
      "\n",
      " Cycle 19 14\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 9.322201251983643\n",
      "Took to train: 6.423557281494141\n",
      "\n",
      " Cycle 20 14\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 5.404151439666748\n",
      "Took to train: 6.448236465454102\n",
      "\n",
      " Cycle 21 14\n",
      "Took to collect: 8.380592584609985\n",
      "Took to train: 6.448199510574341\n",
      "\n",
      " Cycle 22 14\n",
      "Took to collect: 5.725768804550171\n",
      "Took to train: 6.462751388549805\n",
      "\n",
      " Cycle 23 14\n",
      "Took to collect: 7.971250772476196\n",
      "Took to train: 6.446825981140137\n",
      "\n",
      " Cycle 24 14\n",
      "Took to collect: 8.507035493850708\n",
      "Took to train: 6.434597492218018\n",
      "\n",
      " Cycle 25 14\n",
      "Took to collect: 7.543151617050171\n",
      "Took to train: 6.436373233795166\n",
      "\n",
      " Cycle 26 14\n",
      "Took to collect: 9.19756007194519\n",
      "Took to train: 6.458908557891846\n",
      "\n",
      " Cycle 27 14\n",
      "Took to collect: 6.989084720611572\n",
      "Took to train: 6.429775238037109\n",
      "\n",
      " Cycle 28 14\n",
      "Took to collect: 7.425990581512451\n",
      "Took to train: 6.400003671646118\n",
      "\n",
      " Cycle 29 14\n",
      "Took to collect: 8.026597261428833\n",
      "Took to train: 6.365516901016235\n",
      "\n",
      " Cycle 30 14\n",
      "Took to collect: 8.249372482299805\n",
      "Took to train: 6.372110843658447\n",
      "\n",
      " Cycle 31 14\n",
      "Took to collect: 6.678449630737305\n",
      "Took to train: 6.380567312240601\n",
      "\n",
      " Cycle 32 14\n",
      "Took to collect: 8.441219806671143\n",
      "Took to train: 6.444432973861694\n",
      "\n",
      " Cycle 33 14\n",
      "Took to collect: 8.503020286560059\n",
      "Took to train: 6.414965391159058\n",
      "\n",
      " Cycle 34 14\n",
      "Took to collect: 7.919372081756592\n",
      "Took to train: 6.425568342208862\n",
      "\n",
      " Cycle 35 14\n",
      "Took to collect: 7.296435832977295\n",
      "Took to train: 6.43532657623291\n",
      "\n",
      " Cycle 36 14\n",
      "Took to collect: 7.845916509628296\n",
      "Took to train: 6.380375146865845\n",
      "\n",
      " Cycle 37 14\n",
      "Took to collect: 6.099570274353027\n",
      "Took to train: 6.376516103744507\n",
      "\n",
      " Cycle 38 14\n",
      "Took to collect: 7.832399606704712\n",
      "Took to train: 6.396910190582275\n",
      "\n",
      " Cycle 39 14\n",
      "Took to collect: 6.780821084976196\n",
      "Took to train: 6.392461776733398\n",
      "\n",
      " Cycle 40 14\n",
      "Took to collect: 6.689622402191162\n",
      "Took to train: 6.363003730773926\n",
      "\n",
      " Cycle 41 14\n",
      "Took to collect: 7.630290269851685\n",
      "Took to train: 6.376413583755493\n",
      "\n",
      " Cycle 42 14\n",
      "Took to collect: 6.916325807571411\n",
      "Took to train: 6.474563360214233\n",
      "\n",
      " Cycle 43 14\n",
      "Took to collect: 8.026761531829834\n",
      "Took to train: 6.49482536315918\n",
      "\n",
      " Cycle 44 14\n",
      "Took to collect: 7.2589781284332275\n",
      "Took to train: 6.497112512588501\n",
      "\n",
      " Cycle 45 14\n",
      "Took to collect: 7.366157054901123\n",
      "Took to train: 6.486739873886108\n",
      "\n",
      " Cycle 46 14\n",
      "Took to collect: 8.212099075317383\n",
      "Took to train: 6.420278549194336\n",
      "\n",
      " Cycle 47 14\n",
      "Took to collect: 9.357813119888306\n",
      "Took to train: 6.440649509429932\n",
      "\n",
      " Cycle 48 14\n",
      "Took to collect: 7.6316657066345215\n",
      "Took to train: 6.436657190322876\n",
      "\n",
      " Cycle 49 14\n",
      "Took to collect: 7.910445213317871\n",
      "Took to train: 6.431239128112793\n",
      "\n",
      " Cycle 50 14\n",
      "Took to collect: 8.006983757019043\n",
      "Took to train: 6.427400588989258\n",
      "\n",
      " Cycle 51 14\n",
      "Took to collect: 7.609792947769165\n",
      "Took to train: 6.4178385734558105\n",
      "\n",
      " Cycle 52 14\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 8.342206716537476\n",
      "Took to train: 6.370474338531494\n",
      "\n",
      " Cycle 53 14\n",
      "Took to collect: 8.641988754272461\n",
      "Took to train: 6.424511194229126\n",
      "\n",
      " Cycle 54 14\n",
      "Took to collect: 7.515925168991089\n",
      "Took to train: 6.4634785652160645\n",
      "\n",
      " Cycle 55 14\n",
      "Took to collect: 8.47558856010437\n",
      "Took to train: 6.458833456039429\n",
      "\n",
      " Cycle 56 14\n",
      "Took to collect: 7.71288537979126\n",
      "Took to train: 6.450266122817993\n",
      "\n",
      " Cycle 57 14\n",
      "Took to collect: 6.836368560791016\n",
      "Took to train: 6.5010364055633545\n",
      "\n",
      " Cycle 58 14\n",
      "Took to collect: 6.3068461418151855\n",
      "Took to train: 6.485624313354492\n",
      "\n",
      " Cycle 59 14\n",
      "Took to collect: 7.8568315505981445\n",
      "Took to train: 6.493236541748047\n",
      "\n",
      " Cycle 60 14\n",
      "Took to collect: 8.172096967697144\n",
      "Took to train: 6.469330787658691\n",
      "\n",
      " Cycle 61 14\n",
      "Took to collect: 8.252208948135376\n",
      "Took to train: 6.429171085357666\n",
      "\n",
      " Cycle 62 14\n",
      "Took to collect: 7.723980903625488\n",
      "Took to train: 6.418792724609375\n",
      "\n",
      " Cycle 63 14\n",
      "Took to collect: 7.792377948760986\n",
      "Took to train: 6.317209720611572\n",
      "\n",
      " Cycle 64 14\n",
      "Took to collect: 8.84643006324768\n",
      "Took to train: 6.447981357574463\n",
      "\n",
      " Cycle 65 14\n",
      "Took to collect: 7.350598335266113\n",
      "Took to train: 6.505681991577148\n",
      "\n",
      " Cycle 66 14\n",
      "Took to collect: 7.8164637088775635\n",
      "Took to train: 6.330044507980347\n",
      "\n",
      " Cycle 67 14\n",
      "Took to collect: 8.173094034194946\n",
      "Took to train: 6.468518495559692\n",
      "\n",
      " Cycle 68 14\n",
      "Took to collect: 6.958261728286743\n",
      "Took to train: 6.5196685791015625\n",
      "\n",
      " Cycle 69 14\n",
      "Took to collect: 8.068490028381348\n",
      "Took to train: 6.415326833724976\n",
      "\n",
      " Cycle 70 14\n",
      "Took to collect: 9.165584802627563\n",
      "Took to train: 6.457433223724365\n",
      "\n",
      " Cycle 71 14\n",
      "Took to collect: 7.294759511947632\n",
      "Took to train: 6.343736410140991\n",
      "\n",
      " Cycle 72 14\n",
      "Took to collect: 7.205630540847778\n",
      "Took to train: 6.375301122665405\n",
      "\n",
      " Cycle 73 14\n",
      "Took to collect: 7.055461645126343\n",
      "Took to train: 6.3594348430633545\n",
      "\n",
      " Cycle 74 14\n",
      "Took to collect: 7.104131460189819\n",
      "Took to train: 6.395798683166504\n",
      "\n",
      " Cycle 75 14\n",
      "Took to collect: 7.512245178222656\n",
      "Took to train: 6.320730209350586\n",
      "\n",
      " Cycle 76 14\n",
      "Took to collect: 6.373795032501221\n",
      "Took to train: 6.252410888671875\n",
      "\n",
      " Cycle 77 14\n",
      "Took to collect: 6.575380563735962\n",
      "Took to train: 6.249906301498413\n",
      "\n",
      " Cycle 78 14\n",
      "Took to collect: 6.623986005783081\n",
      "Took to train: 6.247565984725952\n",
      "\n",
      " Cycle 79 14\n",
      "Took to collect: 8.248971939086914\n",
      "Took to train: 6.408193111419678\n",
      "\n",
      " Cycle 80 14\n",
      "Took to collect: 8.05772590637207\n",
      "Took to train: 6.4470415115356445\n",
      "\n",
      " Cycle 81 14\n",
      "Took to collect: 7.312135934829712\n",
      "Took to train: 6.473812580108643\n",
      "\n",
      " Cycle 82 14\n",
      "Took to collect: 8.128865718841553\n",
      "Took to train: 6.45186972618103\n",
      "\n",
      " Cycle 83 14\n",
      "Took to collect: 6.841212749481201\n",
      "Took to train: 6.406633377075195\n",
      "\n",
      " Cycle 84 14\n",
      "Took to collect: 7.832621097564697\n",
      "Took to train: 6.378161907196045\n",
      "\n",
      " Cycle 85 14\n",
      "Took to collect: 8.726710557937622\n",
      "Took to train: 6.370621919631958\n",
      "\n",
      " Cycle 86 14\n",
      "Took to collect: 6.978011131286621\n",
      "Took to train: 6.340773105621338\n",
      "\n",
      " Cycle 87 14\n",
      "Took to collect: 9.275072813034058\n",
      "Took to train: 6.405340194702148\n",
      "\n",
      " Cycle 88 14\n",
      "Took to collect: 7.772950887680054\n",
      "Took to train: 6.428637981414795\n",
      "\n",
      " Cycle 89 14\n",
      "Took to collect: 7.363879442214966\n",
      "Took to train: 6.414518356323242\n",
      "\n",
      " Cycle 90 14\n",
      "Took to collect: 7.180743932723999\n",
      "Took to train: 6.405076742172241\n",
      "\n",
      " Cycle 91 14\n",
      "Took to collect: 7.185181617736816\n",
      "Took to train: 6.217692136764526\n",
      "\n",
      " Cycle 92 14\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.817533254623413\n",
      "Took to train: 6.429731845855713\n",
      "\n",
      " Cycle 93 14\n",
      "Took to collect: 7.232012987136841\n",
      "Took to train: 6.425657749176025\n",
      "\n",
      " Cycle 94 14\n",
      "Took to collect: 8.806773662567139\n",
      "Took to train: 6.469985008239746\n",
      "\n",
      " Cycle 95 14\n",
      "Took to collect: 8.937566757202148\n",
      "Took to train: 6.388731002807617\n",
      "\n",
      " Cycle 96 14\n",
      "Took to collect: 6.385470628738403\n",
      "Took to train: 6.4201295375823975\n",
      "\n",
      " Cycle 97 14\n",
      "Took to collect: 8.031593084335327\n",
      "Took to train: 6.497841835021973\n",
      "\n",
      " Cycle 98 14\n",
      "Took to collect: 6.960991382598877\n",
      "Took to train: 6.548904657363892\n",
      "\n",
      " Cycle 99 14\n",
      "Took to collect: 8.105321645736694\n",
      "Took to train: 6.526249647140503\n",
      "Time collect avg cycle: 7.690411233901978\n",
      "Time train avg cycle: 6.406548426151276\n",
      "Total avg cycle: 14.107137753963471\n",
      "Ending epoch\n",
      "2020-10-26 03:23:20.350438 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 14 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.595522\n",
      "trainer/QF2 Loss                                    0.548147\n",
      "trainer/Policy Loss                                55.4168\n",
      "trainer/Q1 Predictions Mean                       -55.4625\n",
      "trainer/Q1 Predictions Std                         28.4984\n",
      "trainer/Q1 Predictions Max                          6.73162\n",
      "trainer/Q1 Predictions Min                       -104.195\n",
      "trainer/Q2 Predictions Mean                       -55.4101\n",
      "trainer/Q2 Predictions Std                         28.5756\n",
      "trainer/Q2 Predictions Max                          6.60201\n",
      "trainer/Q2 Predictions Min                       -104.397\n",
      "trainer/Q Targets Mean                            -55.4607\n",
      "trainer/Q Targets Std                              28.541\n",
      "trainer/Q Targets Max                               7.04602\n",
      "trainer/Q Targets Min                            -104.58\n",
      "trainer/Log Pis Mean                                3.14869\n",
      "trainer/Log Pis Std                                 2.1046\n",
      "trainer/Log Pis Max                                 7.60572\n",
      "trainer/Log Pis Min                                -4.25607\n",
      "trainer/policy/mean Mean                           -0.334131\n",
      "trainer/policy/mean Std                             0.597799\n",
      "trainer/policy/mean Max                             0.990868\n",
      "trainer/policy/mean Min                            -0.991938\n",
      "trainer/policy/normal/std Mean                      0.337194\n",
      "trainer/policy/normal/std Std                       0.219819\n",
      "trainer/policy/normal/std Max                       1.26514\n",
      "trainer/policy/normal/std Min                       0.0469843\n",
      "trainer/policy/normal/log_std Mean                 -1.36087\n",
      "trainer/policy/normal/log_std Std                   0.805011\n",
      "trainer/policy/normal/log_std Max                   0.235185\n",
      "trainer/policy/normal/log_std Min                  -3.05794\n",
      "trainer/Alpha                                       0.0151794\n",
      "trainer/Alpha Loss                                  0.622679\n",
      "exploration/num steps total                    151000\n",
      "exploration/num paths total                      3029\n",
      "exploration/path length Mean                       48.5437\n",
      "exploration/path length Std                         7.03014\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         8\n",
      "exploration/Rewards Mean                           -0.9913\n",
      "exploration/Rewards Std                             0.0928672\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -48.1214\n",
      "exploration/Returns Std                             7.88386\n",
      "exploration/Returns Max                            -7\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.279381\n",
      "exploration/Actions Std                             0.590852\n",
      "exploration/Actions Max                             0.999706\n",
      "exploration/Actions Min                            -0.999893\n",
      "exploration/Num Paths                             206\n",
      "exploration/Average Returns                       -48.1214\n",
      "exploration/env_infos/final/is_success Mean         0.0291262\n",
      "exploration/env_infos/final/is_success Std          0.16816\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0006\n",
      "exploration/env_infos/is_success Std                0.0244875\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                       7421\n",
      "evaluation/num paths total                        150\n",
      "evaluation/path length Mean                        45.9\n",
      "evaluation/path length Std                         12.3\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                          9\n",
      "evaluation/Rewards Mean                            -0.910675\n",
      "evaluation/Rewards Std                              0.285212\n",
      "evaluation/Rewards Max                             -0\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -41.8\n",
      "evaluation/Returns Std                             16.1914\n",
      "evaluation/Returns Max                             -7\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.259021\n",
      "evaluation/Actions Std                              0.451385\n",
      "evaluation/Actions Max                              0.978793\n",
      "evaluation/Actions Min                             -0.970506\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -41.8\n",
      "evaluation/env_infos/final/is_success Mean          0.1\n",
      "evaluation/env_infos/final/is_success Std           0.3\n",
      "evaluation/env_infos/final/is_success Max           1\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0.00217865\n",
      "evaluation/env_infos/is_success Std                 0.0466251\n",
      "evaluation/env_infos/is_success Max                 1\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.992037\n",
      "time/evaluation sampling (s)                       42.5809\n",
      "time/exploration sampling (s)                     769.061\n",
      "time/logging (s)                                    0.027128\n",
      "time/sac training (s)                             199.81\n",
      "time/saving (s)                                     0.0140232\n",
      "time/training (s)                                   0.00707382\n",
      "time/epoch (s)                                   1012.49\n",
      "time/total (s)                                  20674.5\n",
      "Epoch                                              14\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 15\n",
      "\n",
      " Cycle 0 15\n",
      "Took to collect: 5.836615085601807\n",
      "Took to train: 6.409161329269409\n",
      "\n",
      " Cycle 1 15\n",
      "Took to collect: 6.859422206878662\n",
      "Took to train: 6.347672700881958\n",
      "\n",
      " Cycle 2 15\n",
      "Took to collect: 7.699200391769409\n",
      "Took to train: 6.2765443325042725\n",
      "\n",
      " Cycle 3 15\n",
      "Took to collect: 5.5972206592559814\n",
      "Took to train: 6.282230854034424\n",
      "\n",
      " Cycle 4 15\n",
      "Took to collect: 7.303028106689453\n",
      "Took to train: 6.281261205673218\n",
      "\n",
      " Cycle 5 15\n",
      "Took to collect: 7.923928499221802\n",
      "Took to train: 6.29110050201416\n",
      "\n",
      " Cycle 6 15\n",
      "Took to collect: 7.9800355434417725\n",
      "Took to train: 6.291543245315552\n",
      "\n",
      " Cycle 7 15\n",
      "Took to collect: 8.462289810180664\n",
      "Took to train: 6.284850358963013\n",
      "\n",
      " Cycle 8 15\n",
      "Took to collect: 7.619324684143066\n",
      "Took to train: 6.293433666229248\n",
      "\n",
      " Cycle 9 15\n",
      "Took to collect: 6.291703939437866\n",
      "Took to train: 6.27670693397522\n",
      "\n",
      " Cycle 10 15\n",
      "Took to collect: 7.1155476570129395\n",
      "Took to train: 6.339860916137695\n",
      "\n",
      " Cycle 11 15\n",
      "Took to collect: 7.131891489028931\n",
      "Took to train: 6.385688543319702\n",
      "\n",
      " Cycle 12 15\n",
      "Took to collect: 7.54756498336792\n",
      "Took to train: 6.351786375045776\n",
      "\n",
      " Cycle 13 15\n",
      "Took to collect: 7.6851279735565186\n",
      "Took to train: 6.250873804092407\n",
      "\n",
      " Cycle 14 15\n",
      "Took to collect: 6.324771881103516\n",
      "Took to train: 6.425396680831909\n",
      "\n",
      " Cycle 15 15\n",
      "Took to collect: 6.354140520095825\n",
      "Took to train: 6.4238340854644775\n",
      "\n",
      " Cycle 16 15\n",
      "Took to collect: 7.102271556854248\n",
      "Took to train: 6.444648742675781\n",
      "\n",
      " Cycle 17 15\n",
      "Took to collect: 6.65194034576416\n",
      "Took to train: 6.425787448883057\n",
      "\n",
      " Cycle 18 15\n",
      "Took to collect: 7.86957311630249\n",
      "Took to train: 6.483327865600586\n",
      "\n",
      " Cycle 19 15\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.227954387664795\n",
      "Took to train: 6.490491151809692\n",
      "\n",
      " Cycle 20 15\n",
      "Took to collect: 6.296027660369873\n",
      "Took to train: 6.282243967056274\n",
      "\n",
      " Cycle 21 15\n",
      "Took to collect: 7.579005241394043\n",
      "Took to train: 6.282442092895508\n",
      "\n",
      " Cycle 22 15\n",
      "Took to collect: 8.06837511062622\n",
      "Took to train: 6.385156631469727\n",
      "\n",
      " Cycle 23 15\n",
      "Took to collect: 8.1846284866333\n",
      "Took to train: 6.404460430145264\n",
      "\n",
      " Cycle 24 15\n",
      "Took to collect: 8.722711324691772\n",
      "Took to train: 6.392165660858154\n",
      "\n",
      " Cycle 25 15\n",
      "Took to collect: 8.118325233459473\n",
      "Took to train: 6.311782121658325\n",
      "\n",
      " Cycle 26 15\n",
      "Took to collect: 8.087090969085693\n",
      "Took to train: 6.415997743606567\n",
      "\n",
      " Cycle 27 15\n",
      "Took to collect: 6.840214490890503\n",
      "Took to train: 6.466632604598999\n",
      "\n",
      " Cycle 28 15\n",
      "Took to collect: 7.1957480907440186\n",
      "Took to train: 6.49315619468689\n",
      "\n",
      " Cycle 29 15\n",
      "Took to collect: 7.216162204742432\n",
      "Took to train: 6.43970799446106\n",
      "\n",
      " Cycle 30 15\n",
      "Took to collect: 7.682269096374512\n",
      "Took to train: 6.429842948913574\n",
      "\n",
      " Cycle 31 15\n",
      "Took to collect: 5.0761189460754395\n",
      "Took to train: 6.469902276992798\n",
      "\n",
      " Cycle 32 15\n",
      "Took to collect: 8.523456811904907\n",
      "Took to train: 6.4272918701171875\n",
      "\n",
      " Cycle 33 15\n",
      "Took to collect: 4.406301736831665\n",
      "Took to train: 6.382606506347656\n",
      "\n",
      " Cycle 34 15\n",
      "Took to collect: 7.363360404968262\n",
      "Took to train: 6.40631103515625\n",
      "\n",
      " Cycle 35 15\n",
      "Took to collect: 9.102566480636597\n",
      "Took to train: 6.398278713226318\n",
      "\n",
      " Cycle 36 15\n",
      "Took to collect: 5.304470062255859\n",
      "Took to train: 6.290753602981567\n",
      "\n",
      " Cycle 37 15\n",
      "Took to collect: 6.4130332469940186\n",
      "Took to train: 6.267772674560547\n",
      "\n",
      " Cycle 38 15\n",
      "Took to collect: 7.054476261138916\n",
      "Took to train: 6.277224540710449\n",
      "\n",
      " Cycle 39 15\n",
      "Took to collect: 7.194705486297607\n",
      "Took to train: 6.365895748138428\n",
      "\n",
      " Cycle 40 15\n",
      "Took to collect: 4.999709367752075\n",
      "Took to train: 6.297407150268555\n",
      "\n",
      " Cycle 41 15\n",
      "Took to collect: 4.958816051483154\n",
      "Took to train: 6.3253114223480225\n",
      "\n",
      " Cycle 42 15\n",
      "Took to collect: 6.270753622055054\n",
      "Took to train: 6.394787073135376\n",
      "\n",
      " Cycle 43 15\n",
      "Took to collect: 8.364005327224731\n",
      "Took to train: 6.389143705368042\n",
      "\n",
      " Cycle 44 15\n",
      "Took to collect: 5.219739198684692\n",
      "Took to train: 6.3916075229644775\n",
      "\n",
      " Cycle 45 15\n",
      "Took to collect: 6.464111804962158\n",
      "Took to train: 6.397995948791504\n",
      "\n",
      " Cycle 46 15\n",
      "Took to collect: 6.9129064083099365\n",
      "Took to train: 6.419933557510376\n",
      "\n",
      " Cycle 47 15\n",
      "Took to collect: 7.5794150829315186\n",
      "Took to train: 6.480802297592163\n",
      "\n",
      " Cycle 48 15\n",
      "Took to collect: 7.2567360401153564\n",
      "Took to train: 6.420082092285156\n",
      "\n",
      " Cycle 49 15\n",
      "Took to collect: 5.699163913726807\n",
      "Took to train: 6.4028143882751465\n",
      "\n",
      " Cycle 50 15\n",
      "Took to collect: 6.338818550109863\n",
      "Took to train: 6.42732048034668\n",
      "\n",
      " Cycle 51 15\n",
      "Took to collect: 5.3161375522613525\n",
      "Took to train: 6.439266681671143\n",
      "\n",
      " Cycle 52 15\n",
      "Took to collect: 6.913461446762085\n",
      "Took to train: 6.44464898109436\n",
      "\n",
      " Cycle 53 15\n",
      "Took to collect: 8.342699766159058\n",
      "Took to train: 6.443141937255859\n",
      "\n",
      " Cycle 54 15\n",
      "Took to collect: 7.386894941329956\n",
      "Took to train: 6.440817832946777\n",
      "\n",
      " Cycle 55 15\n",
      "Took to collect: 6.814614772796631\n",
      "Took to train: 6.249049425125122\n",
      "\n",
      " Cycle 56 15\n",
      "Took to collect: 5.644892454147339\n",
      "Took to train: 6.236596584320068\n",
      "\n",
      " Cycle 57 15\n",
      "Took to collect: 3.9975180625915527\n",
      "Took to train: 6.251560688018799\n",
      "\n",
      " Cycle 58 15\n",
      "Took to collect: 5.6461663246154785\n",
      "Took to train: 6.328217267990112\n",
      "\n",
      " Cycle 59 15\n",
      "Took to collect: 7.732896327972412\n",
      "Took to train: 6.387602090835571\n",
      "\n",
      " Cycle 60 15\n",
      "Took to collect: 7.457926034927368\n",
      "Took to train: 6.406926393508911\n",
      "\n",
      " Cycle 61 15\n",
      "Took to collect: 6.751774072647095\n",
      "Took to train: 6.274153232574463\n",
      "\n",
      " Cycle 62 15\n",
      "Took to collect: 7.5775063037872314\n",
      "Took to train: 6.269083738327026\n",
      "\n",
      " Cycle 63 15\n",
      "Took to collect: 6.725790500640869\n",
      "Took to train: 6.248331546783447\n",
      "\n",
      " Cycle 64 15\n",
      "Took to collect: 7.179409980773926\n",
      "Took to train: 6.270111322402954\n",
      "\n",
      " Cycle 65 15\n",
      "Took to collect: 6.8113603591918945\n",
      "Took to train: 6.269269704818726\n",
      "\n",
      " Cycle 66 15\n",
      "Took to collect: 7.751095294952393\n",
      "Took to train: 6.250569105148315\n",
      "\n",
      " Cycle 67 15\n",
      "Took to collect: 7.373668193817139\n",
      "Took to train: 6.2717444896698\n",
      "\n",
      " Cycle 68 15\n",
      "Took to collect: 6.792996168136597\n",
      "Took to train: 6.259085655212402\n",
      "\n",
      " Cycle 69 15\n",
      "Took to collect: 6.254997253417969\n",
      "Took to train: 6.26168966293335\n",
      "\n",
      " Cycle 70 15\n",
      "Took to collect: 7.50089955329895\n",
      "Took to train: 6.237886667251587\n",
      "\n",
      " Cycle 71 15\n",
      "Took to collect: 7.3963141441345215\n",
      "Took to train: 6.377317905426025\n",
      "\n",
      " Cycle 72 15\n",
      "Took to collect: 4.232391834259033\n",
      "Took to train: 6.345358610153198\n",
      "\n",
      " Cycle 73 15\n",
      "Took to collect: 6.2216477394104\n",
      "Took to train: 6.2870378494262695\n",
      "\n",
      " Cycle 74 15\n",
      "Took to collect: 6.305014371871948\n",
      "Took to train: 6.282153844833374\n",
      "\n",
      " Cycle 75 15\n",
      "Took to collect: 6.572486639022827\n",
      "Took to train: 6.41795015335083\n",
      "\n",
      " Cycle 76 15\n",
      "Took to collect: 2.9913768768310547\n",
      "Took to train: 6.362020492553711\n",
      "\n",
      " Cycle 77 15\n",
      "Took to collect: 4.323314905166626\n",
      "Took to train: 6.290512323379517\n",
      "\n",
      " Cycle 78 15\n",
      "Took to collect: 6.067991733551025\n",
      "Took to train: 6.316133499145508\n",
      "\n",
      " Cycle 79 15\n",
      "Took to collect: 8.709084749221802\n",
      "Took to train: 6.2760093212127686\n",
      "\n",
      " Cycle 80 15\n",
      "Took to collect: 7.861248970031738\n",
      "Took to train: 6.28365421295166\n",
      "\n",
      " Cycle 81 15\n",
      "Took to collect: 6.948728561401367\n",
      "Took to train: 6.3764002323150635\n",
      "\n",
      " Cycle 82 15\n",
      "Took to collect: 4.641665458679199\n",
      "Took to train: 6.387451171875\n",
      "\n",
      " Cycle 83 15\n",
      "Took to collect: 6.150944709777832\n",
      "Took to train: 6.429342269897461\n",
      "\n",
      " Cycle 84 15\n",
      "Took to collect: 7.053410291671753\n",
      "Took to train: 6.318021297454834\n",
      "\n",
      " Cycle 85 15\n",
      "Took to collect: 6.777909278869629\n",
      "Took to train: 6.496241807937622\n",
      "\n",
      " Cycle 86 15\n",
      "Took to collect: 7.599947929382324\n",
      "Took to train: 6.387326717376709\n",
      "\n",
      " Cycle 87 15\n",
      "Took to collect: 7.501558542251587\n",
      "Took to train: 6.300159692764282\n",
      "\n",
      " Cycle 88 15\n",
      "Took to collect: 7.282015800476074\n",
      "Took to train: 6.457993030548096\n",
      "\n",
      " Cycle 89 15\n",
      "Took to collect: 9.851515531539917\n",
      "Took to train: 6.453646898269653\n",
      "\n",
      " Cycle 90 15\n",
      "Took to collect: 8.375163078308105\n",
      "Took to train: 6.420174598693848\n",
      "\n",
      " Cycle 91 15\n",
      "Took to collect: 7.897929906845093\n",
      "Took to train: 6.256772518157959\n",
      "\n",
      " Cycle 92 15\n",
      "Took to collect: 7.28315806388855\n",
      "Took to train: 6.2732274532318115\n",
      "\n",
      " Cycle 93 15\n",
      "Took to collect: 8.1074538230896\n",
      "Took to train: 6.39055323600769\n",
      "\n",
      " Cycle 94 15\n",
      "Took to collect: 7.542919635772705\n",
      "Took to train: 6.42501163482666\n",
      "\n",
      " Cycle 95 15\n",
      "Took to collect: 7.457705974578857\n",
      "Took to train: 6.33789324760437\n",
      "\n",
      " Cycle 96 15\n",
      "Took to collect: 7.0707573890686035\n",
      "Took to train: 6.2382166385650635\n",
      "\n",
      " Cycle 97 15\n",
      "Took to collect: 9.389436960220337\n",
      "Took to train: 6.308764219284058\n",
      "\n",
      " Cycle 98 15\n",
      "Took to collect: 7.612198829650879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.502853870391846\n",
      "\n",
      " Cycle 99 15\n",
      "Took to collect: 8.927977561950684\n",
      "Took to train: 6.3626227378845215\n",
      "Time collect avg cycle: 6.9720275020599365\n",
      "Time train avg cycle: 6.355936062335968\n",
      "Total avg cycle: 13.337945337295531\n",
      "Ending epoch\n",
      "2020-10-26 03:46:17.452546 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 15 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.672887\n",
      "trainer/QF2 Loss                                    0.617924\n",
      "trainer/Policy Loss                                53.8411\n",
      "trainer/Q1 Predictions Mean                       -53.8471\n",
      "trainer/Q1 Predictions Std                         29.8851\n",
      "trainer/Q1 Predictions Max                          3.63616\n",
      "trainer/Q1 Predictions Min                       -106.535\n",
      "trainer/Q2 Predictions Mean                       -53.8095\n",
      "trainer/Q2 Predictions Std                         29.8746\n",
      "trainer/Q2 Predictions Max                          3.65153\n",
      "trainer/Q2 Predictions Min                       -105.713\n",
      "trainer/Q Targets Mean                            -53.655\n",
      "trainer/Q Targets Std                              29.8445\n",
      "trainer/Q Targets Max                               3.7392\n",
      "trainer/Q Targets Min                            -105.883\n",
      "trainer/Log Pis Mean                                2.95177\n",
      "trainer/Log Pis Std                                 2.27236\n",
      "trainer/Log Pis Max                                10.0889\n",
      "trainer/Log Pis Min                                -4.65932\n",
      "trainer/policy/mean Mean                           -0.232088\n",
      "trainer/policy/mean Std                             0.632472\n",
      "trainer/policy/mean Max                             0.993982\n",
      "trainer/policy/mean Min                            -0.989046\n",
      "trainer/policy/normal/std Mean                      0.341339\n",
      "trainer/policy/normal/std Std                       0.22685\n",
      "trainer/policy/normal/std Max                       1.29981\n",
      "trainer/policy/normal/std Min                       0.0481922\n",
      "trainer/policy/normal/log_std Mean                 -1.38361\n",
      "trainer/policy/normal/log_std Std                   0.865631\n",
      "trainer/policy/normal/log_std Max                   0.262216\n",
      "trainer/policy/normal/log_std Min                  -3.03256\n",
      "trainer/Alpha                                       0.0160269\n",
      "trainer/Alpha Loss                                 -0.199359\n",
      "exploration/num steps total                    161000\n",
      "exploration/num paths total                      3230\n",
      "exploration/path length Mean                       49.7512\n",
      "exploration/path length Std                         2.84733\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        11\n",
      "exploration/Rewards Mean                           -0.9972\n",
      "exploration/Rewards Std                             0.0528409\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.6119\n",
      "exploration/Returns Std                             3.20737\n",
      "exploration/Returns Max                           -10\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.257442\n",
      "exploration/Actions Std                             0.647899\n",
      "exploration/Actions Max                             0.999952\n",
      "exploration/Actions Min                            -0.999877\n",
      "exploration/Num Paths                             201\n",
      "exploration/Average Returns                       -49.6119\n",
      "exploration/env_infos/final/is_success Mean         0.00497512\n",
      "exploration/env_infos/final/is_success Std          0.0703589\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0001\n",
      "exploration/env_infos/is_success Std                0.0099995\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                       7890\n",
      "evaluation/num paths total                        161\n",
      "evaluation/path length Mean                        42.6364\n",
      "evaluation/path length Std                         15.6221\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                          9\n",
      "evaluation/Rewards Mean                            -0.987207\n",
      "evaluation/Rewards Std                              0.112381\n",
      "evaluation/Rewards Max                             -0\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -42.0909\n",
      "evaluation/Returns Std                             16.5445\n",
      "evaluation/Returns Max                             -7\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.291051\n",
      "evaluation/Actions Std                              0.492275\n",
      "evaluation/Actions Max                              0.979429\n",
      "evaluation/Actions Min                             -0.972243\n",
      "evaluation/Num Paths                               11\n",
      "evaluation/Average Returns                        -42.0909\n",
      "evaluation/env_infos/final/is_success Mean          0.181818\n",
      "evaluation/env_infos/final/is_success Std           0.385695\n",
      "evaluation/env_infos/final/is_success Max           1\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0.00426439\n",
      "evaluation/env_infos/is_success Std                 0.0651629\n",
      "evaluation/env_infos/is_success Max                 1\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.972531\n",
      "time/evaluation sampling (s)                       43.2447\n",
      "time/exploration sampling (s)                     697.222\n",
      "time/logging (s)                                    0.0285801\n",
      "time/sac training (s)                             198.021\n",
      "time/saving (s)                                     0.0141637\n",
      "time/training (s)                                   0.00686712\n",
      "time/epoch (s)                                    939.51\n",
      "time/total (s)                                  22051.4\n",
      "Epoch                                              15\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 16\n",
      "\n",
      " Cycle 0 16\n",
      "Took to collect: 5.94496488571167\n",
      "Took to train: 6.274813652038574\n",
      "\n",
      " Cycle 1 16\n",
      "Took to collect: 5.392319202423096\n",
      "Took to train: 6.307065963745117\n",
      "\n",
      " Cycle 2 16\n",
      "Took to collect: 4.536359786987305\n",
      "Took to train: 6.458438873291016\n",
      "\n",
      " Cycle 3 16\n",
      "Took to collect: 6.801790714263916\n",
      "Took to train: 6.4282097816467285\n",
      "\n",
      " Cycle 4 16\n",
      "Took to collect: 6.761487722396851\n",
      "Took to train: 6.404979944229126\n",
      "\n",
      " Cycle 5 16\n",
      "Took to collect: 7.217453956604004\n",
      "Took to train: 6.368044853210449\n",
      "\n",
      " Cycle 6 16\n",
      "Took to collect: 8.356269121170044\n",
      "Took to train: 6.37078070640564\n",
      "\n",
      " Cycle 7 16\n",
      "Took to collect: 7.6794092655181885\n",
      "Took to train: 6.418818473815918\n",
      "\n",
      " Cycle 8 16\n",
      "Took to collect: 6.787302017211914\n",
      "Took to train: 6.422841548919678\n",
      "\n",
      " Cycle 9 16\n",
      "Took to collect: 6.939043760299683\n",
      "Took to train: 6.4375715255737305\n",
      "\n",
      " Cycle 10 16\n",
      "Took to collect: 6.912147760391235\n",
      "Took to train: 6.439396619796753\n",
      "\n",
      " Cycle 11 16\n",
      "Took to collect: 6.665012359619141\n",
      "Took to train: 6.410274028778076\n",
      "\n",
      " Cycle 12 16\n",
      "Took to collect: 7.928049325942993\n",
      "Took to train: 6.409799814224243\n",
      "\n",
      " Cycle 13 16\n",
      "Took to collect: 7.810749292373657\n",
      "Took to train: 6.483916282653809\n",
      "\n",
      " Cycle 14 16\n",
      "Took to collect: 6.5535595417022705\n",
      "Took to train: 6.504467725753784\n",
      "\n",
      " Cycle 15 16\n",
      "Took to collect: 7.816612243652344\n",
      "Took to train: 6.515220642089844\n",
      "\n",
      " Cycle 16 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 8.165435314178467\n",
      "Took to train: 6.539046764373779\n",
      "\n",
      " Cycle 17 16\n",
      "Took to collect: 9.516561508178711\n",
      "Took to train: 6.541577577590942\n",
      "\n",
      " Cycle 18 16\n",
      "Took to collect: 7.58193039894104\n",
      "Took to train: 6.511528015136719\n",
      "\n",
      " Cycle 19 16\n",
      "Took to collect: 6.164417743682861\n",
      "Took to train: 6.441210031509399\n",
      "\n",
      " Cycle 20 16\n",
      "Took to collect: 7.543949842453003\n",
      "Took to train: 6.522930145263672\n",
      "\n",
      " Cycle 21 16\n",
      "Took to collect: 6.857581853866577\n",
      "Took to train: 6.511135101318359\n",
      "\n",
      " Cycle 22 16\n",
      "Took to collect: 7.956442832946777\n",
      "Took to train: 6.374457120895386\n",
      "\n",
      " Cycle 23 16\n",
      "Took to collect: 6.607374429702759\n",
      "Took to train: 6.37713098526001\n",
      "\n",
      " Cycle 24 16\n",
      "Took to collect: 5.580601453781128\n",
      "Took to train: 6.4239678382873535\n",
      "\n",
      " Cycle 25 16\n",
      "Took to collect: 7.667681694030762\n",
      "Took to train: 6.380644798278809\n",
      "\n",
      " Cycle 26 16\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 6.75235915184021\n",
      "Took to train: 6.460223436355591\n",
      "\n",
      " Cycle 27 16\n",
      "Took to collect: 6.9466798305511475\n",
      "Took to train: 6.459983587265015\n",
      "\n",
      " Cycle 28 16\n",
      "Took to collect: 7.77592921257019\n",
      "Took to train: 6.513823986053467\n",
      "\n",
      " Cycle 29 16\n",
      "Took to collect: 7.099438190460205\n",
      "Took to train: 6.3800599575042725\n",
      "\n",
      " Cycle 30 16\n",
      "Took to collect: 6.777444839477539\n",
      "Took to train: 6.518744945526123\n",
      "\n",
      " Cycle 31 16\n",
      "Took to collect: 8.104056358337402\n",
      "Took to train: 6.493623733520508\n",
      "\n",
      " Cycle 32 16\n",
      "Took to collect: 7.936815977096558\n",
      "Took to train: 6.499974489212036\n",
      "\n",
      " Cycle 33 16\n",
      "Took to collect: 7.696768760681152\n",
      "Took to train: 6.486880540847778\n",
      "\n",
      " Cycle 34 16\n",
      "Took to collect: 6.367923259735107\n",
      "Took to train: 6.3040852546691895\n",
      "\n",
      " Cycle 35 16\n",
      "Took to collect: 7.883905649185181\n",
      "Took to train: 6.311230421066284\n",
      "\n",
      " Cycle 36 16\n",
      "Took to collect: 6.894433975219727\n",
      "Took to train: 6.349442005157471\n",
      "\n",
      " Cycle 37 16\n",
      "Took to collect: 7.157670736312866\n",
      "Took to train: 6.356817007064819\n",
      "\n",
      " Cycle 38 16\n",
      "Took to collect: 8.421194076538086\n",
      "Took to train: 6.3962743282318115\n",
      "\n",
      " Cycle 39 16\n",
      "Took to collect: 7.335888385772705\n",
      "Took to train: 6.3919689655303955\n",
      "\n",
      " Cycle 40 16\n",
      "Took to collect: 7.76513934135437\n",
      "Took to train: 6.415274143218994\n",
      "\n",
      " Cycle 41 16\n",
      "Took to collect: 7.5230817794799805\n",
      "Took to train: 6.3811609745025635\n",
      "\n",
      " Cycle 42 16\n",
      "Took to collect: 8.080466747283936\n",
      "Took to train: 6.372766733169556\n",
      "\n",
      " Cycle 43 16\n",
      "Took to collect: 6.367780447006226\n",
      "Took to train: 6.355650901794434\n",
      "\n",
      " Cycle 44 16\n",
      "Took to collect: 7.691066026687622\n",
      "Took to train: 6.286230802536011\n",
      "\n",
      " Cycle 45 16\n",
      "Took to collect: 7.304376840591431\n",
      "Took to train: 6.283568620681763\n",
      "\n",
      " Cycle 46 16\n",
      "Took to collect: 6.209339141845703\n",
      "Took to train: 6.285043954849243\n",
      "\n",
      " Cycle 47 16\n",
      "Took to collect: 7.788769006729126\n",
      "Took to train: 6.279377222061157\n",
      "\n",
      " Cycle 48 16\n",
      "Took to collect: 7.3209826946258545\n",
      "Took to train: 6.30833625793457\n",
      "\n",
      " Cycle 49 16\n",
      "Took to collect: 8.293940782546997\n",
      "Took to train: 6.273953676223755\n",
      "\n",
      " Cycle 50 16\n",
      "Took to collect: 7.966545581817627\n",
      "Took to train: 6.375355958938599\n",
      "\n",
      " Cycle 51 16\n",
      "Took to collect: 7.759632587432861\n",
      "Took to train: 6.43502140045166\n",
      "\n",
      " Cycle 52 16\n",
      "Took to collect: 8.084742784500122\n",
      "Took to train: 6.381817817687988\n",
      "\n",
      " Cycle 53 16\n",
      "Took to collect: 6.526962995529175\n",
      "Took to train: 6.4014809131622314\n",
      "\n",
      " Cycle 54 16\n",
      "Took to collect: 7.489493131637573\n",
      "Took to train: 6.401712894439697\n",
      "\n",
      " Cycle 55 16\n",
      "Took to collect: 9.301039695739746\n",
      "Took to train: 6.465528964996338\n",
      "\n",
      " Cycle 56 16\n",
      "Took to collect: 7.154605150222778\n",
      "Took to train: 6.4472150802612305\n",
      "\n",
      " Cycle 57 16\n",
      "Took to collect: 8.297333717346191\n",
      "Took to train: 6.466661691665649\n",
      "\n",
      " Cycle 58 16\n",
      "Took to collect: 6.051630258560181\n",
      "Took to train: 6.492253541946411\n",
      "\n",
      " Cycle 59 16\n",
      "Took to collect: 6.764004707336426\n",
      "Took to train: 6.3836729526519775\n",
      "\n",
      " Cycle 60 16\n",
      "Took to collect: 6.8549768924713135\n",
      "Took to train: 6.432753086090088\n",
      "\n",
      " Cycle 61 16\n",
      "Took to collect: 7.109552621841431\n",
      "Took to train: 6.457329750061035\n",
      "\n",
      " Cycle 62 16\n",
      "Took to collect: 7.077969312667847\n",
      "Took to train: 6.465512752532959\n",
      "\n",
      " Cycle 63 16\n",
      "Took to collect: 7.90700364112854\n",
      "Took to train: 6.450325012207031\n",
      "\n",
      " Cycle 64 16\n",
      "Took to collect: 6.517975091934204\n",
      "Took to train: 6.377825736999512\n",
      "\n",
      " Cycle 65 16\n",
      "Took to collect: 6.657685995101929\n",
      "Took to train: 6.381088972091675\n",
      "\n",
      " Cycle 66 16\n",
      "Took to collect: 8.302522420883179\n",
      "Took to train: 6.282263278961182\n",
      "\n",
      " Cycle 67 16\n",
      "Took to collect: 8.698944807052612\n",
      "Took to train: 6.277591943740845\n",
      "\n",
      " Cycle 68 16\n",
      "Took to collect: 6.891416788101196\n",
      "Took to train: 6.453456401824951\n",
      "\n",
      " Cycle 69 16\n",
      "Took to collect: 7.004905462265015\n",
      "Took to train: 6.438642978668213\n",
      "\n",
      " Cycle 70 16\n",
      "Took to collect: 8.695860862731934\n",
      "Took to train: 6.2763049602508545\n",
      "\n",
      " Cycle 71 16\n",
      "Took to collect: 7.4217376708984375\n",
      "Took to train: 6.272062063217163\n",
      "\n",
      " Cycle 72 16\n",
      "Took to collect: 9.202808856964111\n",
      "Took to train: 6.276330232620239\n",
      "\n",
      " Cycle 73 16\n",
      "Took to collect: 7.397599458694458\n",
      "Took to train: 6.28461766242981\n",
      "\n",
      " Cycle 74 16\n",
      "Took to collect: 7.462611198425293\n",
      "Took to train: 6.282386064529419\n",
      "\n",
      " Cycle 75 16\n",
      "Took to collect: 7.199027061462402\n",
      "Took to train: 6.4606547355651855\n",
      "\n",
      " Cycle 76 16\n",
      "Took to collect: 6.869633436203003\n",
      "Took to train: 6.3818464279174805\n",
      "\n",
      " Cycle 77 16\n",
      "Took to collect: 8.362955570220947\n",
      "Took to train: 6.3754823207855225\n",
      "\n",
      " Cycle 78 16\n",
      "Took to collect: 7.924928903579712\n",
      "Took to train: 6.3321661949157715\n",
      "\n",
      " Cycle 79 16\n",
      "Took to collect: 7.912764072418213\n",
      "Took to train: 6.355602979660034\n",
      "\n",
      " Cycle 80 16\n",
      "Took to collect: 7.116446018218994\n",
      "Took to train: 6.468451261520386\n",
      "\n",
      " Cycle 81 16\n",
      "Took to collect: 7.291117906570435\n",
      "Took to train: 6.438482284545898\n",
      "\n",
      " Cycle 82 16\n",
      "Took to collect: 6.49170446395874\n",
      "Took to train: 6.47237229347229\n",
      "\n",
      " Cycle 83 16\n",
      "Took to collect: 8.389446496963501\n",
      "Took to train: 6.316898345947266\n",
      "\n",
      " Cycle 84 16\n",
      "Took to collect: 8.00476861000061\n",
      "Took to train: 6.348183870315552\n",
      "\n",
      " Cycle 85 16\n",
      "Took to collect: 6.876805067062378\n",
      "Took to train: 6.34775972366333\n",
      "\n",
      " Cycle 86 16\n",
      "Took to collect: 7.462315320968628\n",
      "Took to train: 6.3828465938568115\n",
      "\n",
      " Cycle 87 16\n",
      "Took to collect: 7.669482469558716\n",
      "Took to train: 6.340412616729736\n",
      "\n",
      " Cycle 88 16\n",
      "Took to collect: 7.262147903442383\n",
      "Took to train: 6.363457679748535\n",
      "\n",
      " Cycle 89 16\n",
      "Took to collect: 8.925901412963867\n",
      "Took to train: 6.34955620765686\n",
      "\n",
      " Cycle 90 16\n",
      "Took to collect: 7.28334903717041\n",
      "Took to train: 6.353874683380127\n",
      "\n",
      " Cycle 91 16\n",
      "Took to collect: 8.769008159637451\n",
      "Took to train: 6.307358980178833\n",
      "\n",
      " Cycle 92 16\n",
      "Took to collect: 8.499791145324707\n",
      "Took to train: 6.415950298309326\n",
      "\n",
      " Cycle 93 16\n",
      "Took to collect: 7.97051477432251\n",
      "Took to train: 6.417259454727173\n",
      "\n",
      " Cycle 94 16\n",
      "Took to collect: 7.542234897613525\n",
      "Took to train: 6.318453788757324\n",
      "\n",
      " Cycle 95 16\n",
      "Took to collect: 7.751076936721802\n",
      "Took to train: 6.41615104675293\n",
      "\n",
      " Cycle 96 16\n",
      "Took to collect: 7.329920530319214\n",
      "Took to train: 6.459761142730713\n",
      "\n",
      " Cycle 97 16\n",
      "Took to collect: 7.728744268417358\n",
      "Took to train: 6.463550329208374\n",
      "\n",
      " Cycle 98 16\n",
      "Took to collect: 6.316372394561768\n",
      "Took to train: 6.550008296966553\n",
      "\n",
      " Cycle 99 16\n",
      "Took to collect: 7.4327921867370605\n",
      "Took to train: 6.53691840171814\n",
      "Time collect avg cycle: 7.402227699756622\n",
      "Time train avg cycle: 6.400754368305206\n",
      "Total avg cycle: 13.813195433616638\n",
      "Ending epoch\n",
      "2020-10-26 04:09:58.895063 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 16 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.728919\n",
      "trainer/QF2 Loss                                    1.26924\n",
      "trainer/Policy Loss                                50.655\n",
      "trainer/Q1 Predictions Mean                       -50.1208\n",
      "trainer/Q1 Predictions Std                         30.3854\n",
      "trainer/Q1 Predictions Max                         -0.0508998\n",
      "trainer/Q1 Predictions Min                       -105.542\n",
      "trainer/Q2 Predictions Mean                       -50.8308\n",
      "trainer/Q2 Predictions Std                         30.2067\n",
      "trainer/Q2 Predictions Max                         -1.27383\n",
      "trainer/Q2 Predictions Min                       -105.481\n",
      "trainer/Q Targets Mean                            -50.0834\n",
      "trainer/Q Targets Std                              30.3825\n",
      "trainer/Q Targets Max                              -0.227439\n",
      "trainer/Q Targets Min                            -105.742\n",
      "trainer/Log Pis Mean                                3.18357\n",
      "trainer/Log Pis Std                                 1.83532\n",
      "trainer/Log Pis Max                                 8.86913\n",
      "trainer/Log Pis Min                                -3.3532\n",
      "trainer/policy/mean Mean                           -0.28432\n",
      "trainer/policy/mean Std                             0.62609\n",
      "trainer/policy/mean Max                             0.992874\n",
      "trainer/policy/mean Min                            -0.9841\n",
      "trainer/policy/normal/std Mean                      0.347269\n",
      "trainer/policy/normal/std Std                       0.235356\n",
      "trainer/policy/normal/std Max                       1.7141\n",
      "trainer/policy/normal/std Min                       0.0475893\n",
      "trainer/policy/normal/log_std Mean                 -1.34978\n",
      "trainer/policy/normal/log_std Std                   0.831232\n",
      "trainer/policy/normal/log_std Max                   0.538886\n",
      "trainer/policy/normal/log_std Min                  -3.04515\n",
      "trainer/Alpha                                       0.0151791\n",
      "trainer/Alpha Loss                                  0.768757\n",
      "exploration/num steps total                    171000\n",
      "exploration/num paths total                      3431\n",
      "exploration/path length Mean                       49.7512\n",
      "exploration/path length Std                         2.79975\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        12\n",
      "exploration/Rewards Mean                           -0.9966\n",
      "exploration/Rewards Std                             0.0582103\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.5821\n",
      "exploration/Returns Std                             3.68734\n",
      "exploration/Returns Max                           -10\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.404507\n",
      "exploration/Actions Std                             0.657355\n",
      "exploration/Actions Max                             0.999966\n",
      "exploration/Actions Min                            -0.999981\n",
      "exploration/Num Paths                             201\n",
      "exploration/Average Returns                       -49.5821\n",
      "exploration/env_infos/final/is_success Mean         0.00497512\n",
      "exploration/env_infos/final/is_success Std          0.0703589\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0001\n",
      "exploration/env_infos/is_success Std                0.0099995\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                       8390\n",
      "evaluation/num paths total                        171\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.302299\n",
      "evaluation/Actions Std                              0.644839\n",
      "evaluation/Actions Max                              0.973454\n",
      "evaluation/Actions Min                             -0.985729\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.995937\n",
      "time/evaluation sampling (s)                       40.0597\n",
      "time/exploration sampling (s)                     740.242\n",
      "time/logging (s)                                    0.0277116\n",
      "time/sac training (s)                             199.752\n",
      "time/saving (s)                                     0.0139397\n",
      "time/training (s)                                   0.00698795\n",
      "time/epoch (s)                                    981.098\n",
      "time/total (s)                                  23472.6\n",
      "Epoch                                              16\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 17\n",
      "\n",
      " Cycle 0 17\n",
      "Took to collect: 7.760065317153931\n",
      "Took to train: 6.467406511306763\n",
      "\n",
      " Cycle 1 17\n",
      "Took to collect: 7.759995698928833\n",
      "Took to train: 6.466947317123413\n",
      "\n",
      " Cycle 2 17\n",
      "Took to collect: 9.257097005844116\n",
      "Took to train: 6.270872354507446\n",
      "\n",
      " Cycle 3 17\n",
      "Took to collect: 7.107975244522095\n",
      "Took to train: 6.236702919006348\n",
      "\n",
      " Cycle 4 17\n",
      "Took to collect: 7.652096271514893\n",
      "Took to train: 6.269330739974976\n",
      "\n",
      " Cycle 5 17\n",
      "Took to collect: 7.401785373687744\n",
      "Took to train: 6.2556421756744385\n",
      "\n",
      " Cycle 6 17\n",
      "Took to collect: 8.103379964828491\n",
      "Took to train: 6.278684377670288\n",
      "\n",
      " Cycle 7 17\n",
      "Took to collect: 8.79074740409851\n",
      "Took to train: 6.459673643112183\n",
      "\n",
      " Cycle 8 17\n",
      "Took to collect: 6.8170249462127686\n",
      "Took to train: 6.4583470821380615\n",
      "\n",
      " Cycle 9 17\n",
      "Took to collect: 8.10477876663208\n",
      "Took to train: 6.450273513793945\n",
      "\n",
      " Cycle 10 17\n",
      "Took to collect: 9.300730466842651\n",
      "Took to train: 6.4307098388671875\n",
      "\n",
      " Cycle 11 17\n",
      "Took to collect: 9.767846584320068\n",
      "Took to train: 6.395591974258423\n",
      "\n",
      " Cycle 12 17\n",
      "Took to collect: 6.767383575439453\n",
      "Took to train: 6.441544532775879\n",
      "\n",
      " Cycle 13 17\n",
      "Took to collect: 8.037138938903809\n",
      "Took to train: 6.454271554946899\n",
      "\n",
      " Cycle 14 17\n",
      "Took to collect: 8.467426061630249\n",
      "Took to train: 6.4422712326049805\n",
      "\n",
      " Cycle 15 17\n",
      "Took to collect: 7.5931315422058105\n",
      "Took to train: 6.4382688999176025\n",
      "\n",
      " Cycle 16 17\n",
      "Took to collect: 7.59752082824707\n",
      "Took to train: 6.434544086456299\n",
      "\n",
      " Cycle 17 17\n",
      "Took to collect: 7.66107439994812\n",
      "Took to train: 6.44031286239624\n",
      "\n",
      " Cycle 18 17\n",
      "Took to collect: 9.184587001800537\n",
      "Took to train: 6.467285633087158\n",
      "\n",
      " Cycle 19 17\n",
      "Took to collect: 8.46614670753479\n",
      "Took to train: 6.436660051345825\n",
      "\n",
      " Cycle 20 17\n",
      "Took to collect: 8.029999017715454\n",
      "Took to train: 6.46003270149231\n",
      "\n",
      " Cycle 21 17\n",
      "Took to collect: 6.034151554107666\n",
      "Took to train: 6.384526491165161\n",
      "\n",
      " Cycle 22 17\n",
      "Took to collect: 7.541348934173584\n",
      "Took to train: 6.407484531402588\n",
      "\n",
      " Cycle 23 17\n",
      "Took to collect: 8.1109778881073\n",
      "Took to train: 6.430617332458496\n",
      "\n",
      " Cycle 24 17\n",
      "Took to collect: 7.862710237503052\n",
      "Took to train: 6.425400495529175\n",
      "\n",
      " Cycle 25 17\n",
      "Took to collect: 7.457545280456543\n",
      "Took to train: 6.458248615264893\n",
      "\n",
      " Cycle 26 17\n",
      "Took to collect: 8.12855315208435\n",
      "Took to train: 6.4348859786987305\n",
      "\n",
      " Cycle 27 17\n",
      "Took to collect: 9.6508309841156\n",
      "Took to train: 6.465192079544067\n",
      "\n",
      " Cycle 28 17\n",
      "Took to collect: 7.33247709274292\n",
      "Took to train: 6.485195159912109\n",
      "\n",
      " Cycle 29 17\n",
      "Took to collect: 7.973005056381226\n",
      "Took to train: 6.4427125453948975\n",
      "\n",
      " Cycle 30 17\n",
      "Took to collect: 8.4058678150177\n",
      "Took to train: 6.409895181655884\n",
      "\n",
      " Cycle 31 17\n",
      "Took to collect: 8.441388368606567\n",
      "Took to train: 6.4416162967681885\n",
      "\n",
      " Cycle 32 17\n",
      "Took to collect: 7.837804317474365\n",
      "Took to train: 6.455682277679443\n",
      "\n",
      " Cycle 33 17\n",
      "Took to collect: 8.111544370651245\n",
      "Took to train: 6.4270617961883545\n",
      "\n",
      " Cycle 34 17\n",
      "Took to collect: 9.021663188934326\n",
      "Took to train: 6.476645469665527\n",
      "\n",
      " Cycle 35 17\n",
      "Took to collect: 9.612053394317627\n",
      "Took to train: 6.470301151275635\n",
      "\n",
      " Cycle 36 17\n",
      "Took to collect: 7.561178207397461\n",
      "Took to train: 6.444830894470215\n",
      "\n",
      " Cycle 37 17\n",
      "Took to collect: 7.74579119682312\n",
      "Took to train: 6.454196929931641\n",
      "\n",
      " Cycle 38 17\n",
      "Took to collect: 7.568830966949463\n",
      "Took to train: 6.450716495513916\n",
      "\n",
      " Cycle 39 17\n",
      "Took to collect: 8.380085706710815\n",
      "Took to train: 6.465011119842529\n",
      "\n",
      " Cycle 40 17\n",
      "Took to collect: 6.890542030334473\n",
      "Took to train: 6.449001312255859\n",
      "\n",
      " Cycle 41 17\n",
      "Took to collect: 8.439529418945312\n",
      "Took to train: 6.456110715866089\n",
      "\n",
      " Cycle 42 17\n",
      "Took to collect: 7.593982458114624\n",
      "Took to train: 6.374309778213501\n",
      "\n",
      " Cycle 43 17\n",
      "Took to collect: 7.622916221618652\n",
      "Took to train: 6.457813739776611\n",
      "\n",
      " Cycle 44 17\n",
      "Took to collect: 8.093839883804321\n",
      "Took to train: 6.4372475147247314\n",
      "\n",
      " Cycle 45 17\n",
      "Took to collect: 7.741607189178467\n",
      "Took to train: 6.444275140762329\n",
      "\n",
      " Cycle 46 17\n",
      "Took to collect: 7.572540044784546\n",
      "Took to train: 6.438489675521851\n",
      "\n",
      " Cycle 47 17\n",
      "Took to collect: 7.067251205444336\n",
      "Took to train: 6.455529451370239\n",
      "\n",
      " Cycle 48 17\n",
      "Took to collect: 5.959753036499023\n",
      "Took to train: 6.354531526565552\n",
      "\n",
      " Cycle 49 17\n",
      "Took to collect: 9.260926723480225\n",
      "Took to train: 6.317101001739502\n",
      "\n",
      " Cycle 50 17\n",
      "Took to collect: 6.765714168548584\n",
      "Took to train: 6.3579490184783936\n",
      "\n",
      " Cycle 51 17\n",
      "Took to collect: 8.1182279586792\n",
      "Took to train: 6.383655786514282\n",
      "\n",
      " Cycle 52 17\n",
      "Took to collect: 7.52020525932312\n",
      "Took to train: 6.362903356552124\n",
      "\n",
      " Cycle 53 17\n",
      "Took to collect: 8.521941184997559\n",
      "Took to train: 6.433435916900635\n",
      "\n",
      " Cycle 54 17\n",
      "Took to collect: 7.5883307456970215\n",
      "Took to train: 6.34233546257019\n",
      "\n",
      " Cycle 55 17\n",
      "Took to collect: 8.043772459030151\n",
      "Took to train: 6.427023887634277\n",
      "\n",
      " Cycle 56 17\n",
      "Took to collect: 7.981860160827637\n",
      "Took to train: 6.4089295864105225\n",
      "\n",
      " Cycle 57 17\n",
      "Took to collect: 8.564851999282837\n",
      "Took to train: 6.395632266998291\n",
      "\n",
      " Cycle 58 17\n",
      "Took to collect: 7.813305139541626\n",
      "Took to train: 6.392570734024048\n",
      "\n",
      " Cycle 59 17\n",
      "Took to collect: 8.262679815292358\n",
      "Took to train: 6.4397523403167725\n",
      "\n",
      " Cycle 60 17\n",
      "Took to collect: 8.398523807525635\n",
      "Took to train: 6.448389291763306\n",
      "\n",
      " Cycle 61 17\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 8.286678552627563\n",
      "Took to train: 6.435413599014282\n",
      "\n",
      " Cycle 62 17\n",
      "Took to collect: 7.624987602233887\n",
      "Took to train: 6.376011610031128\n",
      "\n",
      " Cycle 63 17\n",
      "Took to collect: 9.005790948867798\n",
      "Took to train: 6.401673316955566\n",
      "\n",
      " Cycle 64 17\n",
      "Took to collect: 8.140710830688477\n",
      "Took to train: 6.356858968734741\n",
      "\n",
      " Cycle 65 17\n",
      "Took to collect: 8.907734632492065\n",
      "Took to train: 6.41696310043335\n",
      "\n",
      " Cycle 66 17\n",
      "Took to collect: 8.104491949081421\n",
      "Took to train: 6.388838291168213\n",
      "\n",
      " Cycle 67 17\n",
      "Took to collect: 7.856423616409302\n",
      "Took to train: 6.302773475646973\n",
      "\n",
      " Cycle 68 17\n",
      "Took to collect: 7.535435199737549\n",
      "Took to train: 6.413867950439453\n",
      "\n",
      " Cycle 69 17\n",
      "Took to collect: 8.42947244644165\n",
      "Took to train: 6.425004720687866\n",
      "\n",
      " Cycle 70 17\n",
      "Took to collect: 8.206741571426392\n",
      "Took to train: 6.412032842636108\n",
      "\n",
      " Cycle 71 17\n",
      "Took to collect: 7.6323933601379395\n",
      "Took to train: 6.4340660572052\n",
      "\n",
      " Cycle 72 17\n",
      "Took to collect: 8.899835109710693\n",
      "Took to train: 6.4272589683532715\n",
      "\n",
      " Cycle 73 17\n",
      "Took to collect: 9.207439661026001\n",
      "Took to train: 6.436015367507935\n",
      "\n",
      " Cycle 74 17\n",
      "Took to collect: 8.002026081085205\n",
      "Took to train: 6.37809419631958\n",
      "\n",
      " Cycle 75 17\n",
      "Took to collect: 7.744563817977905\n",
      "Took to train: 6.366176605224609\n",
      "\n",
      " Cycle 76 17\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.342745780944824\n",
      "Took to train: 6.2711122035980225\n",
      "\n",
      " Cycle 77 17\n",
      "Took to collect: 7.78486967086792\n",
      "Took to train: 6.369595527648926\n",
      "\n",
      " Cycle 78 17\n",
      "Took to collect: 7.233870983123779\n",
      "Took to train: 6.390684127807617\n",
      "\n",
      " Cycle 79 17\n",
      "Took to collect: 9.007759094238281\n",
      "Took to train: 6.407206058502197\n",
      "\n",
      " Cycle 80 17\n",
      "Took to collect: 7.5366857051849365\n",
      "Took to train: 6.386615514755249\n",
      "\n",
      " Cycle 81 17\n",
      "Took to collect: 7.302209138870239\n",
      "Took to train: 6.344726085662842\n",
      "\n",
      " Cycle 82 17\n",
      "Took to collect: 8.034923553466797\n",
      "Took to train: 6.3529746532440186\n",
      "\n",
      " Cycle 83 17\n",
      "Took to collect: 7.7273640632629395\n",
      "Took to train: 6.419781923294067\n",
      "\n",
      " Cycle 84 17\n",
      "Took to collect: 8.697477340698242\n",
      "Took to train: 6.420602798461914\n",
      "\n",
      " Cycle 85 17\n",
      "Took to collect: 7.819638013839722\n",
      "Took to train: 6.380066633224487\n",
      "\n",
      " Cycle 86 17\n",
      "Took to collect: 7.5926806926727295\n",
      "Took to train: 6.364576816558838\n",
      "\n",
      " Cycle 87 17\n",
      "Took to collect: 7.757369756698608\n",
      "Took to train: 6.350971698760986\n",
      "\n",
      " Cycle 88 17\n",
      "Took to collect: 8.033844470977783\n",
      "Took to train: 6.3802571296691895\n",
      "\n",
      " Cycle 89 17\n",
      "Took to collect: 7.879546403884888\n",
      "Took to train: 6.321739912033081\n",
      "\n",
      " Cycle 90 17\n",
      "Took to collect: 8.308902263641357\n",
      "Took to train: 6.237586498260498\n",
      "\n",
      " Cycle 91 17\n",
      "Took to collect: 7.920384168624878\n",
      "Took to train: 6.239413261413574\n",
      "\n",
      " Cycle 92 17\n",
      "Took to collect: 7.063702821731567\n",
      "Took to train: 6.231311559677124\n",
      "\n",
      " Cycle 93 17\n",
      "Took to collect: 8.330281019210815\n",
      "Took to train: 6.429786205291748\n",
      "\n",
      " Cycle 94 17\n",
      "Took to collect: 8.594988822937012\n",
      "Took to train: 6.36040472984314\n",
      "\n",
      " Cycle 95 17\n",
      "Took to collect: 8.366780042648315\n",
      "Took to train: 6.408392906188965\n",
      "\n",
      " Cycle 96 17\n",
      "Took to collect: 7.781247138977051\n",
      "Took to train: 6.463766574859619\n",
      "\n",
      " Cycle 97 17\n",
      "Took to collect: 7.898157358169556\n",
      "Took to train: 6.527919769287109\n",
      "\n",
      " Cycle 98 17\n",
      "Took to collect: 7.313811779022217\n",
      "Took to train: 6.581336498260498\n",
      "\n",
      " Cycle 99 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 7.433491945266724\n",
      "Took to train: 6.617332696914673\n",
      "Time collect avg cycle: 7.985754971504211\n",
      "Time train avg cycle: 6.406917932033539\n",
      "Total avg cycle: 14.403044519424439\n",
      "Ending epoch\n",
      "2020-10-26 04:34:36.281754 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 17 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.647511\n",
      "trainer/QF2 Loss                                    0.593342\n",
      "trainer/Policy Loss                                49.6388\n",
      "trainer/Q1 Predictions Mean                       -49.5698\n",
      "trainer/Q1 Predictions Std                         30.5687\n",
      "trainer/Q1 Predictions Max                          4.3195\n",
      "trainer/Q1 Predictions Min                       -105.686\n",
      "trainer/Q2 Predictions Mean                       -49.7411\n",
      "trainer/Q2 Predictions Std                         30.5267\n",
      "trainer/Q2 Predictions Max                          3.51234\n",
      "trainer/Q2 Predictions Min                       -105.737\n",
      "trainer/Q Targets Mean                            -49.7535\n",
      "trainer/Q Targets Std                              30.5749\n",
      "trainer/Q Targets Max                               3.96337\n",
      "trainer/Q Targets Min                            -105.441\n",
      "trainer/Log Pis Mean                                3.08855\n",
      "trainer/Log Pis Std                                 1.91378\n",
      "trainer/Log Pis Max                                10.7319\n",
      "trainer/Log Pis Min                                -3.7206\n",
      "trainer/policy/mean Mean                           -0.240862\n",
      "trainer/policy/mean Std                             0.616289\n",
      "trainer/policy/mean Max                             0.994965\n",
      "trainer/policy/mean Min                            -0.994362\n",
      "trainer/policy/normal/std Mean                      0.331857\n",
      "trainer/policy/normal/std Std                       0.224199\n",
      "trainer/policy/normal/std Max                       1.58555\n",
      "trainer/policy/normal/std Min                       0.0539853\n",
      "trainer/policy/normal/log_std Mean                 -1.39961\n",
      "trainer/policy/normal/log_std Std                   0.840665\n",
      "trainer/policy/normal/log_std Max                   0.460929\n",
      "trainer/policy/normal/log_std Min                  -2.91904\n",
      "trainer/Alpha                                       0.0142556\n",
      "trainer/Alpha Loss                                  0.376391\n",
      "exploration/num steps total                    181000\n",
      "exploration/num paths total                      3633\n",
      "exploration/path length Mean                       49.505\n",
      "exploration/path length Std                         4.11018\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         9\n",
      "exploration/Rewards Mean                           -0.998\n",
      "exploration/Rewards Std                             0.0446766\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.4059\n",
      "exploration/Returns Std                             4.38196\n",
      "exploration/Returns Max                            -8\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.450259\n",
      "exploration/Actions Std                             0.644302\n",
      "exploration/Actions Max                             0.999945\n",
      "exploration/Actions Min                            -0.999922\n",
      "exploration/Num Paths                             202\n",
      "exploration/Average Returns                       -49.4059\n",
      "exploration/env_infos/final/is_success Mean         0.00990099\n",
      "exploration/env_infos/final/is_success Std          0.0990099\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0002\n",
      "exploration/env_infos/is_success Std                0.0141407\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                       8890\n",
      "evaluation/num paths total                        181\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.33456\n",
      "evaluation/Actions Std                              0.566738\n",
      "evaluation/Actions Max                              0.976366\n",
      "evaluation/Actions Min                             -0.977102\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               1.01129\n",
      "time/evaluation sampling (s)                       37.0186\n",
      "time/exploration sampling (s)                     798.595\n",
      "time/logging (s)                                    0.0376873\n",
      "time/sac training (s)                             199.769\n",
      "time/saving (s)                                     0.0140645\n",
      "time/training (s)                                   0.00701086\n",
      "time/epoch (s)                                   1036.45\n",
      "time/total (s)                                  24949.8\n",
      "Epoch                                              17\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 18\n",
      "\n",
      " Cycle 0 18\n",
      "Took to collect: 7.059630393981934\n",
      "Took to train: 6.500351190567017\n",
      "\n",
      " Cycle 1 18\n",
      "Took to collect: 7.306079387664795\n",
      "Took to train: 6.489753007888794\n",
      "\n",
      " Cycle 2 18\n",
      "Took to collect: 8.106044292449951\n",
      "Took to train: 6.4283976554870605\n",
      "\n",
      " Cycle 3 18\n",
      "Took to collect: 8.210822105407715\n",
      "Took to train: 6.460675001144409\n",
      "\n",
      " Cycle 4 18\n",
      "Took to collect: 8.113962411880493\n",
      "Took to train: 6.405692100524902\n",
      "\n",
      " Cycle 5 18\n",
      "Took to collect: 7.99291729927063\n",
      "Took to train: 6.371086359024048\n",
      "\n",
      " Cycle 6 18\n",
      "Took to collect: 7.130947589874268\n",
      "Took to train: 6.444833993911743\n",
      "\n",
      " Cycle 7 18\n",
      "Took to collect: 8.274842500686646\n",
      "Took to train: 6.4391701221466064\n",
      "\n",
      " Cycle 8 18\n",
      "Took to collect: 8.409940958023071\n",
      "Took to train: 6.401267766952515\n",
      "\n",
      " Cycle 9 18\n",
      "Took to collect: 7.415194511413574\n",
      "Took to train: 6.366827487945557\n",
      "\n",
      " Cycle 10 18\n",
      "Took to collect: 8.182435035705566\n",
      "Took to train: 6.456828594207764\n",
      "\n",
      " Cycle 11 18\n",
      "Took to collect: 7.289053678512573\n",
      "Took to train: 6.343280553817749\n",
      "\n",
      " Cycle 12 18\n",
      "Took to collect: 7.478701114654541\n",
      "Took to train: 6.423961877822876\n",
      "\n",
      " Cycle 13 18\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.899674892425537\n",
      "Took to train: 6.39104700088501\n",
      "\n",
      " Cycle 14 18\n",
      "Took to collect: 8.435423851013184\n",
      "Took to train: 6.400654554367065\n",
      "\n",
      " Cycle 15 18\n",
      "Took to collect: 7.3509910106658936\n",
      "Took to train: 6.351408004760742\n",
      "\n",
      " Cycle 16 18\n",
      "Took to collect: 7.700346946716309\n",
      "Took to train: 6.287130832672119\n",
      "\n",
      " Cycle 17 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 8.443486213684082\n",
      "Took to train: 6.2891082763671875\n",
      "\n",
      " Cycle 18 18\n",
      "Took to collect: 8.03603196144104\n",
      "Took to train: 6.355788230895996\n",
      "\n",
      " Cycle 19 18\n",
      "Took to collect: 8.20889663696289\n",
      "Took to train: 6.394858360290527\n",
      "\n",
      " Cycle 20 18\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 8.889960527420044\n",
      "Took to train: 6.460435390472412\n",
      "\n",
      " Cycle 21 18\n",
      "Took to collect: 7.598111391067505\n",
      "Took to train: 6.486042499542236\n",
      "\n",
      " Cycle 22 18\n",
      "Took to collect: 7.409732103347778\n",
      "Took to train: 6.472800016403198\n",
      "\n",
      " Cycle 23 18\n",
      "Took to collect: 7.842912197113037\n",
      "Took to train: 6.4100964069366455\n",
      "\n",
      " Cycle 24 18\n",
      "Took to collect: 8.201359033584595\n",
      "Took to train: 6.489761590957642\n",
      "\n",
      " Cycle 25 18\n",
      "Took to collect: 7.2843544483184814\n",
      "Took to train: 6.435877323150635\n",
      "\n",
      " Cycle 26 18\n",
      "Took to collect: 7.839138031005859\n",
      "Took to train: 6.433662414550781\n",
      "\n",
      " Cycle 27 18\n",
      "Took to collect: 7.50135064125061\n",
      "Took to train: 6.4690070152282715\n",
      "\n",
      " Cycle 28 18\n",
      "Took to collect: 8.41842532157898\n",
      "Took to train: 6.450520992279053\n",
      "\n",
      " Cycle 29 18\n",
      "Took to collect: 9.211297035217285\n",
      "Took to train: 6.443681955337524\n",
      "\n",
      " Cycle 30 18\n",
      "Took to collect: 7.226955890655518\n",
      "Took to train: 6.445346117019653\n",
      "\n",
      " Cycle 31 18\n",
      "Took to collect: 8.138732671737671\n",
      "Took to train: 6.457234621047974\n",
      "\n",
      " Cycle 32 18\n",
      "Took to collect: 8.279582500457764\n",
      "Took to train: 6.437098979949951\n",
      "\n",
      " Cycle 33 18\n",
      "Took to collect: 7.744450569152832\n",
      "Took to train: 6.428946018218994\n",
      "\n",
      " Cycle 34 18\n",
      "Took to collect: 8.229182720184326\n",
      "Took to train: 6.457594633102417\n",
      "\n",
      " Cycle 35 18\n",
      "Took to collect: 7.029723405838013\n",
      "Took to train: 6.447749137878418\n",
      "\n",
      " Cycle 36 18\n",
      "Took to collect: 8.051450729370117\n",
      "Took to train: 6.326762437820435\n",
      "\n",
      " Cycle 37 18\n",
      "Took to collect: 8.946177005767822\n",
      "Took to train: 6.334697484970093\n",
      "\n",
      " Cycle 38 18\n",
      "Took to collect: 8.948200225830078\n",
      "Took to train: 6.3582305908203125\n",
      "\n",
      " Cycle 39 18\n",
      "Took to collect: 6.8633623123168945\n",
      "Took to train: 6.254636764526367\n",
      "\n",
      " Cycle 40 18\n",
      "Took to collect: 7.581765651702881\n",
      "Took to train: 6.308938026428223\n",
      "\n",
      " Cycle 41 18\n",
      "Took to collect: 8.497232675552368\n",
      "Took to train: 6.389336585998535\n",
      "\n",
      " Cycle 42 18\n",
      "Took to collect: 8.806975364685059\n",
      "Took to train: 6.282700538635254\n",
      "\n",
      " Cycle 43 18\n",
      "Took to collect: 8.540992736816406\n",
      "Took to train: 6.355717897415161\n",
      "\n",
      " Cycle 44 18\n",
      "Took to collect: 9.225854873657227\n",
      "Took to train: 6.250583648681641\n",
      "\n",
      " Cycle 45 18\n",
      "Took to collect: 7.904834985733032\n",
      "Took to train: 6.244073867797852\n",
      "\n",
      " Cycle 46 18\n",
      "Took to collect: 7.3809332847595215\n",
      "Took to train: 6.394909620285034\n",
      "\n",
      " Cycle 47 18\n",
      "Took to collect: 8.30173134803772\n",
      "Took to train: 6.521661281585693\n",
      "\n",
      " Cycle 48 18\n",
      "Took to collect: 7.853103160858154\n",
      "Took to train: 6.468676567077637\n",
      "\n",
      " Cycle 49 18\n",
      "Took to collect: 8.068649053573608\n",
      "Took to train: 6.516864061355591\n",
      "\n",
      " Cycle 50 18\n",
      "Took to collect: 9.38801383972168\n",
      "Took to train: 6.502119302749634\n",
      "\n",
      " Cycle 51 18\n",
      "Took to collect: 7.963151454925537\n",
      "Took to train: 6.527593612670898\n",
      "\n",
      " Cycle 52 18\n",
      "Took to collect: 8.929548740386963\n",
      "Took to train: 6.4631507396698\n",
      "\n",
      " Cycle 53 18\n",
      "Took to collect: 7.616369962692261\n",
      "Took to train: 6.495089292526245\n",
      "\n",
      " Cycle 54 18\n",
      "Took to collect: 8.432373762130737\n",
      "Took to train: 6.495344638824463\n",
      "\n",
      " Cycle 55 18\n",
      "Took to collect: 7.788574457168579\n",
      "Took to train: 6.4933037757873535\n",
      "\n",
      " Cycle 56 18\n",
      "Took to collect: 7.493785381317139\n",
      "Took to train: 6.496612310409546\n",
      "\n",
      " Cycle 57 18\n",
      "Took to collect: 6.574794054031372\n",
      "Took to train: 6.492438077926636\n",
      "\n",
      " Cycle 58 18\n",
      "Took to collect: 8.62318468093872\n",
      "Took to train: 6.394988298416138\n",
      "\n",
      " Cycle 59 18\n",
      "Took to collect: 6.8376195430755615\n",
      "Took to train: 6.398199796676636\n",
      "\n",
      " Cycle 60 18\n",
      "Took to collect: 6.8217809200286865\n",
      "Took to train: 6.3646299839019775\n",
      "\n",
      " Cycle 61 18\n",
      "Took to collect: 8.438293933868408\n",
      "Took to train: 6.373882055282593\n",
      "\n",
      " Cycle 62 18\n",
      "Took to collect: 8.059715509414673\n",
      "Took to train: 6.438496112823486\n",
      "\n",
      " Cycle 63 18\n",
      "Took to collect: 7.908897161483765\n",
      "Took to train: 6.4590418338775635\n",
      "\n",
      " Cycle 64 18\n",
      "Took to collect: 8.818692684173584\n",
      "Took to train: 6.3961241245269775\n",
      "\n",
      " Cycle 65 18\n",
      "Took to collect: 7.110713720321655\n",
      "Took to train: 6.332338333129883\n",
      "\n",
      " Cycle 66 18\n",
      "Took to collect: 7.68047022819519\n",
      "Took to train: 6.2619874477386475\n",
      "\n",
      " Cycle 67 18\n",
      "Took to collect: 7.736676931381226\n",
      "Took to train: 6.274080753326416\n",
      "\n",
      " Cycle 68 18\n",
      "Took to collect: 7.569708347320557\n",
      "Took to train: 6.2756736278533936\n",
      "\n",
      " Cycle 69 18\n",
      "Took to collect: 6.554285764694214\n",
      "Took to train: 6.278298616409302\n",
      "\n",
      " Cycle 70 18\n",
      "Took to collect: 7.85740065574646\n",
      "Took to train: 6.265655755996704\n",
      "\n",
      " Cycle 71 18\n",
      "Took to collect: 6.474559307098389\n",
      "Took to train: 6.2667396068573\n",
      "\n",
      " Cycle 72 18\n",
      "Took to collect: 7.575253009796143\n",
      "Took to train: 6.27307915687561\n",
      "\n",
      " Cycle 73 18\n",
      "Took to collect: 7.972408056259155\n",
      "Took to train: 6.278686761856079\n",
      "\n",
      " Cycle 74 18\n",
      "Took to collect: 8.714847803115845\n",
      "Took to train: 6.269745588302612\n",
      "\n",
      " Cycle 75 18\n",
      "Took to collect: 7.298699140548706\n",
      "Took to train: 6.2810516357421875\n",
      "\n",
      " Cycle 76 18\n",
      "Took to collect: 8.385207176208496\n",
      "Took to train: 6.287327289581299\n",
      "\n",
      " Cycle 77 18\n",
      "Took to collect: 7.970717430114746\n",
      "Took to train: 6.293247222900391\n",
      "\n",
      " Cycle 78 18\n",
      "Took to collect: 8.30158281326294\n",
      "Took to train: 6.363841533660889\n",
      "\n",
      " Cycle 79 18\n",
      "Took to collect: 7.7916259765625\n",
      "Took to train: 6.274895906448364\n",
      "\n",
      " Cycle 80 18\n",
      "Took to collect: 7.385826587677002\n",
      "Took to train: 6.290756464004517\n",
      "\n",
      " Cycle 81 18\n",
      "Took to collect: 7.544277191162109\n",
      "Took to train: 6.274282693862915\n",
      "\n",
      " Cycle 82 18\n",
      "Took to collect: 8.194250583648682\n",
      "Took to train: 6.31679105758667\n",
      "\n",
      " Cycle 83 18\n",
      "Took to collect: 7.955177307128906\n",
      "Took to train: 6.297115087509155\n",
      "\n",
      " Cycle 84 18\n",
      "Took to collect: 8.800513744354248\n",
      "Took to train: 6.236860275268555\n",
      "\n",
      " Cycle 85 18\n",
      "Took to collect: 7.342418670654297\n",
      "Took to train: 6.362900018692017\n",
      "\n",
      " Cycle 86 18\n",
      "Took to collect: 7.205697059631348\n",
      "Took to train: 6.380875587463379\n",
      "\n",
      " Cycle 87 18\n",
      "Took to collect: 8.356242418289185\n",
      "Took to train: 6.370573043823242\n",
      "\n",
      " Cycle 88 18\n",
      "Took to collect: 8.43168330192566\n",
      "Took to train: 6.39989709854126\n",
      "\n",
      " Cycle 89 18\n",
      "Took to collect: 6.91461443901062\n",
      "Took to train: 6.426297426223755\n",
      "\n",
      " Cycle 90 18\n",
      "Took to collect: 7.596799373626709\n",
      "Took to train: 6.400678873062134\n",
      "\n",
      " Cycle 91 18\n",
      "Took to collect: 7.0995988845825195\n",
      "Took to train: 6.404388427734375\n",
      "\n",
      " Cycle 92 18\n",
      "Took to collect: 7.105666637420654\n",
      "Took to train: 6.3375403881073\n",
      "\n",
      " Cycle 93 18\n",
      "Took to collect: 7.228394508361816\n",
      "Took to train: 6.219955682754517\n",
      "\n",
      " Cycle 94 18\n",
      "Took to collect: 9.038789749145508\n",
      "Took to train: 6.436930179595947\n",
      "\n",
      " Cycle 95 18\n",
      "Took to collect: 7.601104497909546\n",
      "Took to train: 6.266077041625977\n",
      "\n",
      " Cycle 96 18\n",
      "Took to collect: 7.4872307777404785\n",
      "Took to train: 6.265304327011108\n",
      "\n",
      " Cycle 97 18\n",
      "Took to collect: 6.958355665206909\n",
      "Took to train: 6.3923985958099365\n",
      "\n",
      " Cycle 98 18\n",
      "Took to collect: 7.406161308288574\n",
      "Took to train: 6.556495666503906\n",
      "\n",
      " Cycle 99 18\n",
      "Took to collect: 8.641324520111084\n",
      "Took to train: 6.5119123458862305\n",
      "Time collect avg cycle: 7.878450343608856\n",
      "Time train avg cycle: 6.384514589309692\n",
      "Total avg cycle: 14.273034479618072\n",
      "Ending epoch\n",
      "2020-10-26 04:59:11.174919 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 18 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.743692\n",
      "trainer/QF2 Loss                                    0.763316\n",
      "trainer/Policy Loss                                47.4549\n",
      "trainer/Q1 Predictions Mean                       -47.4336\n",
      "trainer/Q1 Predictions Std                         32.4288\n",
      "trainer/Q1 Predictions Max                          4.27059\n",
      "trainer/Q1 Predictions Min                       -105.174\n",
      "trainer/Q2 Predictions Mean                       -47.5062\n",
      "trainer/Q2 Predictions Std                         32.3768\n",
      "trainer/Q2 Predictions Max                          3.79096\n",
      "trainer/Q2 Predictions Min                       -105.337\n",
      "trainer/Q Targets Mean                            -47.4965\n",
      "trainer/Q Targets Std                              32.4716\n",
      "trainer/Q Targets Max                               3.8965\n",
      "trainer/Q Targets Min                            -105.276\n",
      "trainer/Log Pis Mean                                3.19141\n",
      "trainer/Log Pis Std                                 1.91406\n",
      "trainer/Log Pis Max                                 9.70651\n",
      "trainer/Log Pis Min                                -1.80168\n",
      "trainer/policy/mean Mean                           -0.292587\n",
      "trainer/policy/mean Std                             0.616848\n",
      "trainer/policy/mean Max                             0.990373\n",
      "trainer/policy/mean Min                            -0.998369\n",
      "trainer/policy/normal/std Mean                      0.334507\n",
      "trainer/policy/normal/std Std                       0.251088\n",
      "trainer/policy/normal/std Max                       1.6284\n",
      "trainer/policy/normal/std Min                       0.0449975\n",
      "trainer/policy/normal/log_std Mean                 -1.40494\n",
      "trainer/policy/normal/log_std Std                   0.839499\n",
      "trainer/policy/normal/log_std Max                   0.487596\n",
      "trainer/policy/normal/log_std Min                  -3.10115\n",
      "trainer/Alpha                                       0.0135679\n",
      "trainer/Alpha Loss                                  0.823071\n",
      "exploration/num steps total                    191000\n",
      "exploration/num paths total                      3835\n",
      "exploration/path length Mean                       49.505\n",
      "exploration/path length Std                         4.01143\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         9\n",
      "exploration/Rewards Mean                           -0.9993\n",
      "exploration/Rewards Std                             0.0264483\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.4703\n",
      "exploration/Returns Std                             4.34087\n",
      "exploration/Returns Max                            -7\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.409966\n",
      "exploration/Actions Std                             0.641735\n",
      "exploration/Actions Max                             0.999958\n",
      "exploration/Actions Min                            -0.99978\n",
      "exploration/Num Paths                             202\n",
      "exploration/Average Returns                       -49.4703\n",
      "exploration/env_infos/final/is_success Mean         0.00990099\n",
      "exploration/env_infos/final/is_success Std          0.0990099\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0002\n",
      "exploration/env_infos/is_success Std                0.0141407\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                       9390\n",
      "evaluation/num paths total                        191\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.507157\n",
      "evaluation/Actions Std                              0.632011\n",
      "evaluation/Actions Max                              0.957938\n",
      "evaluation/Actions Min                             -0.978343\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.980785\n",
      "time/evaluation sampling (s)                       47.5161\n",
      "time/exploration sampling (s)                     787.865\n",
      "time/logging (s)                                    0.0284119\n",
      "time/sac training (s)                             199.005\n",
      "time/saving (s)                                     0.0140438\n",
      "time/training (s)                                   0.00699306\n",
      "time/epoch (s)                                   1035.42\n",
      "time/total (s)                                  26424.5\n",
      "Epoch                                              18\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 19\n",
      "\n",
      " Cycle 0 19\n",
      "Took to collect: 8.785841464996338\n",
      "Took to train: 6.469110488891602\n",
      "\n",
      " Cycle 1 19\n",
      "Took to collect: 8.079222679138184\n",
      "Took to train: 6.446617126464844\n",
      "\n",
      " Cycle 2 19\n",
      "Took to collect: 7.1459434032440186\n",
      "Took to train: 6.406543016433716\n",
      "\n",
      " Cycle 3 19\n",
      "Took to collect: 9.0238516330719\n",
      "Took to train: 6.425217628479004\n",
      "\n",
      " Cycle 4 19\n",
      "Took to collect: 6.7244133949279785\n",
      "Took to train: 6.397737741470337\n",
      "\n",
      " Cycle 5 19\n",
      "Took to collect: 6.316718339920044\n",
      "Took to train: 6.414041042327881\n",
      "\n",
      " Cycle 6 19\n",
      "Took to collect: 8.880372762680054\n",
      "Took to train: 6.394946336746216\n",
      "\n",
      " Cycle 7 19\n",
      "Took to collect: 6.67524266242981\n",
      "Took to train: 6.319819450378418\n",
      "\n",
      " Cycle 8 19\n",
      "Took to collect: 7.391807794570923\n",
      "Took to train: 6.3501527309417725\n",
      "\n",
      " Cycle 9 19\n",
      "Took to collect: 7.891709089279175\n",
      "Took to train: 6.359618663787842\n",
      "\n",
      " Cycle 10 19\n",
      "Took to collect: 7.895395517349243\n",
      "Took to train: 6.294907569885254\n",
      "\n",
      " Cycle 11 19\n",
      "Took to collect: 6.760108470916748\n",
      "Took to train: 6.283288955688477\n",
      "\n",
      " Cycle 12 19\n",
      "Took to collect: 4.694603681564331\n",
      "Took to train: 6.295303106307983\n",
      "\n",
      " Cycle 13 19\n",
      "Took to collect: 4.976484298706055\n",
      "Took to train: 6.338573694229126\n",
      "\n",
      " Cycle 14 19\n",
      "Took to collect: 4.638891696929932\n",
      "Took to train: 6.415493011474609\n",
      "\n",
      " Cycle 15 19\n",
      "Took to collect: 6.074481248855591\n",
      "Took to train: 6.402981758117676\n",
      "\n",
      " Cycle 16 19\n",
      "Took to collect: 7.050860166549683\n",
      "Took to train: 6.4008026123046875\n",
      "\n",
      " Cycle 17 19\n",
      "Took to collect: 4.362379312515259\n",
      "Took to train: 6.308178186416626\n",
      "\n",
      " Cycle 18 19\n",
      "Took to collect: 4.905515432357788\n",
      "Took to train: 6.307125806808472\n",
      "\n",
      " Cycle 19 19\n",
      "Took to collect: 4.492556571960449\n",
      "Took to train: 6.366851806640625\n",
      "\n",
      " Cycle 20 19\n",
      "Took to collect: 4.732293605804443\n",
      "Took to train: 6.40662693977356\n",
      "\n",
      " Cycle 21 19\n",
      "Took to collect: 4.850602388381958\n",
      "Took to train: 6.40718412399292\n",
      "\n",
      " Cycle 22 19\n",
      "Took to collect: 5.300312042236328\n",
      "Took to train: 6.2983551025390625\n",
      "\n",
      " Cycle 23 19\n",
      "Took to collect: 4.253336429595947\n",
      "Took to train: 6.347074747085571\n",
      "\n",
      " Cycle 24 19\n",
      "Took to collect: 5.087018966674805\n",
      "Took to train: 6.280799388885498\n",
      "\n",
      " Cycle 25 19\n",
      "Took to collect: 5.798245668411255\n",
      "Took to train: 6.29065728187561\n",
      "\n",
      " Cycle 26 19\n",
      "Took to collect: 4.62741756439209\n",
      "Took to train: 6.307190656661987\n",
      "\n",
      " Cycle 27 19\n",
      "Took to collect: 4.343998193740845\n",
      "Took to train: 6.318647146224976\n",
      "\n",
      " Cycle 28 19\n",
      "Took to collect: 4.0253825187683105\n",
      "Took to train: 6.491549968719482\n",
      "\n",
      " Cycle 29 19\n",
      "Took to collect: 4.605105638504028\n",
      "Took to train: 6.400937080383301\n",
      "\n",
      " Cycle 30 19\n",
      "Took to collect: 4.539886951446533\n",
      "Took to train: 6.378241777420044\n",
      "\n",
      " Cycle 31 19\n",
      "Took to collect: 4.441218137741089\n",
      "Took to train: 6.36634087562561\n",
      "\n",
      " Cycle 32 19\n",
      "Took to collect: 4.267930507659912\n",
      "Took to train: 6.366354703903198\n",
      "\n",
      " Cycle 33 19\n",
      "Took to collect: 4.654919862747192\n",
      "Took to train: 6.4918200969696045\n",
      "\n",
      " Cycle 34 19\n",
      "Took to collect: 4.150573968887329\n",
      "Took to train: 6.470999717712402\n",
      "\n",
      " Cycle 35 19\n",
      "Took to collect: 4.839890003204346\n",
      "Took to train: 6.485956430435181\n",
      "\n",
      " Cycle 36 19\n",
      "Took to collect: 4.506960868835449\n",
      "Took to train: 6.445688009262085\n",
      "\n",
      " Cycle 37 19\n",
      "Took to collect: 4.42515754699707\n",
      "Took to train: 6.448076486587524\n",
      "\n",
      " Cycle 38 19\n",
      "Took to collect: 4.346631050109863\n",
      "Took to train: 6.4359047412872314\n",
      "\n",
      " Cycle 39 19\n",
      "Took to collect: 4.845988988876343\n",
      "Took to train: 6.471473455429077\n",
      "\n",
      " Cycle 40 19\n",
      "Took to collect: 4.449724435806274\n",
      "Took to train: 6.262660980224609\n",
      "\n",
      " Cycle 41 19\n",
      "Took to collect: 4.695971727371216\n",
      "Took to train: 6.244552373886108\n",
      "\n",
      " Cycle 42 19\n",
      "Took to collect: 4.7934722900390625\n",
      "Took to train: 6.340696573257446\n",
      "\n",
      " Cycle 43 19\n",
      "Took to collect: 4.101679563522339\n",
      "Took to train: 6.465283155441284\n",
      "\n",
      " Cycle 44 19\n",
      "Took to collect: 6.809908390045166\n",
      "Took to train: 6.445655107498169\n",
      "\n",
      " Cycle 45 19\n",
      "Took to collect: 4.260847806930542\n",
      "Took to train: 6.447928428649902\n",
      "\n",
      " Cycle 46 19\n",
      "Took to collect: 8.509239196777344\n",
      "Took to train: 6.4077534675598145\n",
      "\n",
      " Cycle 47 19\n",
      "Took to collect: 4.364710569381714\n",
      "Took to train: 6.384258508682251\n",
      "\n",
      " Cycle 48 19\n",
      "Took to collect: 4.214827537536621\n",
      "Took to train: 6.394855737686157\n",
      "\n",
      " Cycle 49 19\n",
      "Took to collect: 4.224930047988892\n",
      "Took to train: 6.366584777832031\n",
      "\n",
      " Cycle 50 19\n",
      "Took to collect: 4.057051181793213\n",
      "Took to train: 6.442663669586182\n",
      "\n",
      " Cycle 51 19\n",
      "Took to collect: 4.128055572509766\n",
      "Took to train: 6.423283100128174\n",
      "\n",
      " Cycle 52 19\n",
      "Took to collect: 4.012995719909668\n",
      "Took to train: 6.460656642913818\n",
      "\n",
      " Cycle 53 19\n",
      "Took to collect: 4.4247987270355225\n",
      "Took to train: 6.4476637840271\n",
      "\n",
      " Cycle 54 19\n",
      "Took to collect: 4.217846155166626\n",
      "Took to train: 6.502814292907715\n",
      "\n",
      " Cycle 55 19\n",
      "Took to collect: 4.38046407699585\n",
      "Took to train: 6.506428003311157\n",
      "\n",
      " Cycle 56 19\n",
      "Took to collect: 4.389291286468506\n",
      "Took to train: 6.493601083755493\n",
      "\n",
      " Cycle 57 19\n",
      "Took to collect: 4.0027687549591064\n",
      "Took to train: 6.462248086929321\n",
      "\n",
      " Cycle 58 19\n",
      "Took to collect: 4.238865852355957\n",
      "Took to train: 6.431081056594849\n",
      "\n",
      " Cycle 59 19\n",
      "Took to collect: 4.524038553237915\n",
      "Took to train: 6.31491494178772\n",
      "\n",
      " Cycle 60 19\n",
      "Took to collect: 4.29461407661438\n",
      "Took to train: 6.394702672958374\n",
      "\n",
      " Cycle 61 19\n",
      "Took to collect: 4.544783115386963\n",
      "Took to train: 6.408325672149658\n",
      "\n",
      " Cycle 62 19\n",
      "Took to collect: 4.214372158050537\n",
      "Took to train: 6.423240900039673\n",
      "\n",
      " Cycle 63 19\n",
      "Took to collect: 4.18790078163147\n",
      "Took to train: 6.395348310470581\n",
      "\n",
      " Cycle 64 19\n",
      "Took to collect: 4.596582889556885\n",
      "Took to train: 6.4486000537872314\n",
      "\n",
      " Cycle 65 19\n",
      "Took to collect: 4.813839435577393\n",
      "Took to train: 6.480844736099243\n",
      "\n",
      " Cycle 66 19\n",
      "Took to collect: 4.202169179916382\n",
      "Took to train: 6.375742673873901\n",
      "\n",
      " Cycle 67 19\n",
      "Took to collect: 4.384397745132446\n",
      "Took to train: 6.378474235534668\n",
      "\n",
      " Cycle 68 19\n",
      "Took to collect: 3.8691952228546143\n",
      "Took to train: 6.4186530113220215\n",
      "\n",
      " Cycle 69 19\n",
      "Took to collect: 4.275787830352783\n",
      "Took to train: 6.387263298034668\n",
      "\n",
      " Cycle 70 19\n",
      "Took to collect: 4.454865455627441\n",
      "Took to train: 6.40467643737793\n",
      "\n",
      " Cycle 71 19\n",
      "Took to collect: 4.146824598312378\n",
      "Took to train: 6.331094264984131\n",
      "\n",
      " Cycle 72 19\n",
      "Took to collect: 4.128024101257324\n",
      "Took to train: 6.301633358001709\n",
      "\n",
      " Cycle 73 19\n",
      "Took to collect: 4.232672214508057\n",
      "Took to train: 6.4744553565979\n",
      "\n",
      " Cycle 74 19\n",
      "Took to collect: 4.341471433639526\n",
      "Took to train: 6.380931854248047\n",
      "\n",
      " Cycle 75 19\n",
      "Took to collect: 4.150015354156494\n",
      "Took to train: 6.38373589515686\n",
      "\n",
      " Cycle 76 19\n",
      "Took to collect: 4.875568866729736\n",
      "Took to train: 6.3980607986450195\n",
      "\n",
      " Cycle 77 19\n",
      "Took to collect: 4.265774965286255\n",
      "Took to train: 6.4404137134552\n",
      "\n",
      " Cycle 78 19\n",
      "Took to collect: 4.33949613571167\n",
      "Took to train: 6.416021108627319\n",
      "\n",
      " Cycle 79 19\n",
      "Took to collect: 3.996882915496826\n",
      "Took to train: 6.465500354766846\n",
      "\n",
      " Cycle 80 19\n",
      "Took to collect: 4.907662391662598\n",
      "Took to train: 6.5160510540008545\n",
      "\n",
      " Cycle 81 19\n",
      "Took to collect: 4.042180061340332\n",
      "Took to train: 6.4776599407196045\n",
      "\n",
      " Cycle 82 19\n",
      "Took to collect: 4.509284257888794\n",
      "Took to train: 6.505028963088989\n",
      "\n",
      " Cycle 83 19\n",
      "Took to collect: 4.205111980438232\n",
      "Took to train: 6.5196404457092285\n",
      "\n",
      " Cycle 84 19\n",
      "Took to collect: 4.065608978271484\n",
      "Took to train: 6.479264974594116\n",
      "\n",
      " Cycle 85 19\n",
      "Took to collect: 4.5875184535980225\n",
      "Took to train: 6.481079816818237\n",
      "\n",
      " Cycle 86 19\n",
      "Took to collect: 4.226637601852417\n",
      "Took to train: 6.4875993728637695\n",
      "\n",
      " Cycle 87 19\n",
      "Took to collect: 4.327662944793701\n",
      "Took to train: 6.437964200973511\n",
      "\n",
      " Cycle 88 19\n",
      "Took to collect: 4.862254858016968\n",
      "Took to train: 6.481964111328125\n",
      "\n",
      " Cycle 89 19\n",
      "Took to collect: 4.115161895751953\n",
      "Took to train: 6.462958335876465\n",
      "\n",
      " Cycle 90 19\n",
      "Took to collect: 4.7602808475494385\n",
      "Took to train: 6.4663097858428955\n",
      "\n",
      " Cycle 91 19\n",
      "Took to collect: 9.758036136627197\n",
      "Took to train: 6.397875070571899\n",
      "\n",
      " Cycle 92 19\n",
      "Took to collect: 8.582486867904663\n",
      "Took to train: 6.399194240570068\n",
      "\n",
      " Cycle 93 19\n",
      "Took to collect: 5.397089242935181\n",
      "Took to train: 6.409000873565674\n",
      "\n",
      " Cycle 94 19\n",
      "Took to collect: 5.936466693878174\n",
      "Took to train: 6.503503322601318\n",
      "\n",
      " Cycle 95 19\n",
      "Took to collect: 4.137641906738281\n",
      "Took to train: 6.445279836654663\n",
      "\n",
      " Cycle 96 19\n",
      "Took to collect: 4.336947679519653\n",
      "Took to train: 6.3337013721466064\n",
      "\n",
      " Cycle 97 19\n",
      "Took to collect: 4.47293496131897\n",
      "Took to train: 6.413750171661377\n",
      "\n",
      " Cycle 98 19\n",
      "Took to collect: 4.100014925003052\n",
      "Took to train: 6.410861492156982\n",
      "\n",
      " Cycle 99 19\n",
      "Took to collect: 4.094788312911987\n",
      "Took to train: 6.50279688835144\n",
      "Time collect avg cycle: 5.039517674446106\n",
      "Time train avg cycle: 6.407919762134552\n",
      "Total avg cycle: 11.457663571834564\n",
      "Ending epoch\n",
      "2020-10-26 05:18:59.275720 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 19 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.865307\n",
      "trainer/QF2 Loss                                    2.17173\n",
      "trainer/Policy Loss                                45.6736\n",
      "trainer/Q1 Predictions Mean                       -45.8826\n",
      "trainer/Q1 Predictions Std                         33.4046\n",
      "trainer/Q1 Predictions Max                          7.51794\n",
      "trainer/Q1 Predictions Min                       -104.932\n",
      "trainer/Q2 Predictions Mean                       -44.9072\n",
      "trainer/Q2 Predictions Std                         33.6629\n",
      "trainer/Q2 Predictions Max                          8.45378\n",
      "trainer/Q2 Predictions Min                       -104.725\n",
      "trainer/Q Targets Mean                            -45.989\n",
      "trainer/Q Targets Std                              33.4621\n",
      "trainer/Q Targets Max                              10.0333\n",
      "trainer/Q Targets Min                            -105.384\n",
      "trainer/Log Pis Mean                                2.90084\n",
      "trainer/Log Pis Std                                 2.17597\n",
      "trainer/Log Pis Max                                11.6704\n",
      "trainer/Log Pis Min                                -3.84904\n",
      "trainer/policy/mean Mean                           -0.272657\n",
      "trainer/policy/mean Std                             0.596096\n",
      "trainer/policy/mean Max                             0.995779\n",
      "trainer/policy/mean Min                            -0.992284\n",
      "trainer/policy/normal/std Mean                      0.31501\n",
      "trainer/policy/normal/std Std                       0.215657\n",
      "trainer/policy/normal/std Max                       1.57437\n",
      "trainer/policy/normal/std Min                       0.0405404\n",
      "trainer/policy/normal/log_std Mean                 -1.42669\n",
      "trainer/policy/normal/log_std Std                   0.790561\n",
      "trainer/policy/normal/log_std Max                   0.453857\n",
      "trainer/policy/normal/log_std Min                  -3.20546\n",
      "trainer/Alpha                                       0.0124566\n",
      "trainer/Alpha Loss                                 -0.434865\n",
      "exploration/num steps total                    201000\n",
      "exploration/num paths total                      4035\n",
      "exploration/path length Mean                       50\n",
      "exploration/path length Std                         0\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        50\n",
      "exploration/Rewards Mean                           -1\n",
      "exploration/Rewards Std                             0\n",
      "exploration/Rewards Max                            -1\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -50\n",
      "exploration/Returns Std                             0\n",
      "exploration/Returns Max                           -50\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.718892\n",
      "exploration/Actions Std                             0.409954\n",
      "exploration/Actions Max                             0.999742\n",
      "exploration/Actions Min                            -0.999992\n",
      "exploration/Num Paths                             200\n",
      "exploration/Average Returns                       -50\n",
      "exploration/env_infos/final/is_success Mean         0\n",
      "exploration/env_infos/final/is_success Std          0\n",
      "exploration/env_infos/final/is_success Max          0\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0\n",
      "exploration/env_infos/is_success Std                0\n",
      "exploration/env_infos/is_success Max                0\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                       9890\n",
      "evaluation/num paths total                        201\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.290245\n",
      "evaluation/Actions Std                              0.584362\n",
      "evaluation/Actions Max                              0.974938\n",
      "evaluation/Actions Min                             -0.979201\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.997002\n",
      "time/evaluation sampling (s)                       42.2708\n",
      "time/exploration sampling (s)                     503.971\n",
      "time/logging (s)                                    0.0275988\n",
      "time/sac training (s)                             199.916\n",
      "time/saving (s)                                     0.0140266\n",
      "time/training (s)                                   0.00703077\n",
      "time/epoch (s)                                    747.204\n",
      "time/total (s)                                  27612.4\n",
      "Epoch                                              19\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 20\n",
      "\n",
      " Cycle 0 20\n",
      "Took to collect: 4.642949104309082\n",
      "Took to train: 6.529360771179199\n",
      "\n",
      " Cycle 1 20\n",
      "Took to collect: 3.6224091053009033\n",
      "Took to train: 6.527817964553833\n",
      "\n",
      " Cycle 2 20\n",
      "Took to collect: 4.237337112426758\n",
      "Took to train: 6.513015031814575\n",
      "\n",
      " Cycle 3 20\n",
      "Took to collect: 4.064136981964111\n",
      "Took to train: 6.516622304916382\n",
      "\n",
      " Cycle 4 20\n",
      "Took to collect: 4.053408622741699\n",
      "Took to train: 6.51728892326355\n",
      "\n",
      " Cycle 5 20\n",
      "Took to collect: 4.203296184539795\n",
      "Took to train: 6.510364770889282\n",
      "\n",
      " Cycle 6 20\n",
      "Took to collect: 4.486010789871216\n",
      "Took to train: 6.509642601013184\n",
      "\n",
      " Cycle 7 20\n",
      "Took to collect: 4.46052622795105\n",
      "Took to train: 6.531695127487183\n",
      "\n",
      " Cycle 8 20\n",
      "Took to collect: 4.482527494430542\n",
      "Took to train: 6.498072862625122\n",
      "\n",
      " Cycle 9 20\n",
      "Took to collect: 3.9527132511138916\n",
      "Took to train: 6.494223356246948\n",
      "\n",
      " Cycle 10 20\n",
      "Took to collect: 4.351536989212036\n",
      "Took to train: 6.510620355606079\n",
      "\n",
      " Cycle 11 20\n",
      "Took to collect: 4.403322458267212\n",
      "Took to train: 6.4905009269714355\n",
      "\n",
      " Cycle 12 20\n",
      "Took to collect: 4.284991264343262\n",
      "Took to train: 6.396785020828247\n",
      "\n",
      " Cycle 13 20\n",
      "Took to collect: 7.993733167648315\n",
      "Took to train: 6.299120903015137\n",
      "\n",
      " Cycle 14 20\n",
      "Took to collect: 7.968896389007568\n",
      "Took to train: 6.3069140911102295\n",
      "\n",
      " Cycle 15 20\n",
      "Took to collect: 4.108821630477905\n",
      "Took to train: 6.302296876907349\n",
      "\n",
      " Cycle 16 20\n",
      "Took to collect: 6.190750360488892\n",
      "Took to train: 6.315134763717651\n",
      "\n",
      " Cycle 17 20\n",
      "Took to collect: 4.30444598197937\n",
      "Took to train: 6.352182388305664\n",
      "\n",
      " Cycle 18 20\n",
      "Took to collect: 4.107541799545288\n",
      "Took to train: 6.409647464752197\n",
      "\n",
      " Cycle 19 20\n",
      "Took to collect: 4.229067325592041\n",
      "Took to train: 6.462460279464722\n",
      "\n",
      " Cycle 20 20\n",
      "Took to collect: 4.262462854385376\n",
      "Took to train: 6.503817319869995\n",
      "\n",
      " Cycle 21 20\n",
      "Took to collect: 4.427062749862671\n",
      "Took to train: 6.46865439414978\n",
      "\n",
      " Cycle 22 20\n",
      "Took to collect: 4.735827684402466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.495682239532471\n",
      "\n",
      " Cycle 23 20\n",
      "Took to collect: 5.216132164001465\n",
      "Took to train: 6.4170544147491455\n",
      "\n",
      " Cycle 24 20\n",
      "Took to collect: 4.403979063034058\n",
      "Took to train: 6.437610387802124\n",
      "\n",
      " Cycle 25 20\n",
      "Took to collect: 4.0117762088775635\n",
      "Took to train: 6.4211719036102295\n",
      "\n",
      " Cycle 26 20\n",
      "Took to collect: 4.083559036254883\n",
      "Took to train: 6.392267465591431\n",
      "\n",
      " Cycle 27 20\n",
      "Took to collect: 3.938805341720581\n",
      "Took to train: 6.466371536254883\n",
      "\n",
      " Cycle 28 20\n",
      "Took to collect: 3.865602493286133\n",
      "Took to train: 6.5275962352752686\n",
      "\n",
      " Cycle 29 20\n",
      "Took to collect: 7.881077766418457\n",
      "Took to train: 6.49642014503479\n",
      "\n",
      " Cycle 30 20\n",
      "Took to collect: 7.205126047134399\n",
      "Took to train: 6.438812017440796\n",
      "\n",
      " Cycle 31 20\n",
      "Took to collect: 8.73220682144165\n",
      "Took to train: 6.466390371322632\n",
      "\n",
      " Cycle 32 20\n",
      "Took to collect: 9.058919668197632\n",
      "Took to train: 6.452103853225708\n",
      "\n",
      " Cycle 33 20\n",
      "Took to collect: 7.437810897827148\n",
      "Took to train: 6.467243432998657\n",
      "\n",
      " Cycle 34 20\n",
      "Took to collect: 6.497240781784058\n",
      "Took to train: 6.449478626251221\n",
      "\n",
      " Cycle 35 20\n",
      "Took to collect: 9.414219379425049\n",
      "Took to train: 6.430892705917358\n",
      "\n",
      " Cycle 36 20\n",
      "Took to collect: 8.322379112243652\n",
      "Took to train: 6.51829195022583\n",
      "\n",
      " Cycle 37 20\n",
      "Took to collect: 8.27767014503479\n",
      "Took to train: 6.530808687210083\n",
      "\n",
      " Cycle 38 20\n",
      "Took to collect: 8.923524141311646\n",
      "Took to train: 6.396746635437012\n",
      "\n",
      " Cycle 39 20\n",
      "Took to collect: 8.324145317077637\n",
      "Took to train: 6.390082359313965\n",
      "\n",
      " Cycle 40 20\n",
      "Took to collect: 9.209084033966064\n",
      "Took to train: 6.395407438278198\n",
      "\n",
      " Cycle 41 20\n",
      "Took to collect: 7.8968822956085205\n",
      "Took to train: 6.389381170272827\n",
      "\n",
      " Cycle 42 20\n",
      "Took to collect: 8.55669355392456\n",
      "Took to train: 6.397036075592041\n",
      "\n",
      " Cycle 43 20\n",
      "Took to collect: 9.226808071136475\n",
      "Took to train: 6.3953282833099365\n",
      "\n",
      " Cycle 44 20\n",
      "Took to collect: 9.28959321975708\n",
      "Took to train: 6.405241012573242\n",
      "\n",
      " Cycle 45 20\n",
      "Took to collect: 9.999637365341187\n",
      "Took to train: 6.393199682235718\n",
      "\n",
      " Cycle 46 20\n",
      "Took to collect: 8.258494853973389\n",
      "Took to train: 6.4015960693359375\n",
      "\n",
      " Cycle 47 20\n",
      "Took to collect: 9.882646322250366\n",
      "Took to train: 6.391493797302246\n",
      "\n",
      " Cycle 48 20\n",
      "Took to collect: 8.072673559188843\n",
      "Took to train: 6.518371105194092\n",
      "\n",
      " Cycle 49 20\n",
      "Took to collect: 7.079439163208008\n",
      "Took to train: 6.400033235549927\n",
      "\n",
      " Cycle 50 20\n",
      "Took to collect: 8.256781101226807\n",
      "Took to train: 6.386178255081177\n",
      "\n",
      " Cycle 51 20\n",
      "Took to collect: 7.756643056869507\n",
      "Took to train: 6.455390691757202\n",
      "\n",
      " Cycle 52 20\n",
      "Took to collect: 8.064136028289795\n",
      "Took to train: 6.4507715702056885\n",
      "\n",
      " Cycle 53 20\n",
      "Took to collect: 8.149926662445068\n",
      "Took to train: 6.463149309158325\n",
      "\n",
      " Cycle 54 20\n",
      "Took to collect: 8.892661809921265\n",
      "Took to train: 6.473371982574463\n",
      "\n",
      " Cycle 55 20\n",
      "Took to collect: 8.394604921340942\n",
      "Took to train: 6.333599328994751\n",
      "\n",
      " Cycle 56 20\n",
      "Took to collect: 7.859977960586548\n",
      "Took to train: 6.288035154342651\n",
      "\n",
      " Cycle 57 20\n",
      "Took to collect: 9.06064772605896\n",
      "Took to train: 6.294861555099487\n",
      "\n",
      " Cycle 58 20\n",
      "Took to collect: 8.465841054916382\n",
      "Took to train: 6.306750774383545\n",
      "\n",
      " Cycle 59 20\n",
      "Took to collect: 8.722666263580322\n",
      "Took to train: 6.391145467758179\n",
      "\n",
      " Cycle 60 20\n",
      "Took to collect: 7.70023512840271\n",
      "Took to train: 6.312090635299683\n",
      "\n",
      " Cycle 61 20\n",
      "Took to collect: 6.847434759140015\n",
      "Took to train: 6.437734127044678\n",
      "\n",
      " Cycle 62 20\n",
      "Took to collect: 8.59867548942566\n",
      "Took to train: 6.472843170166016\n",
      "\n",
      " Cycle 63 20\n",
      "Took to collect: 9.027778387069702\n",
      "Took to train: 6.460489749908447\n",
      "\n",
      " Cycle 64 20\n",
      "Took to collect: 8.141423225402832\n",
      "Took to train: 6.449558973312378\n",
      "\n",
      " Cycle 65 20\n",
      "Took to collect: 8.57736325263977\n",
      "Took to train: 6.465125799179077\n",
      "\n",
      " Cycle 66 20\n",
      "Took to collect: 9.397872924804688\n",
      "Took to train: 6.4489758014678955\n",
      "\n",
      " Cycle 67 20\n",
      "Took to collect: 7.788863897323608\n",
      "Took to train: 6.477466821670532\n",
      "\n",
      " Cycle 68 20\n",
      "Took to collect: 7.9623942375183105\n",
      "Took to train: 6.437985897064209\n",
      "\n",
      " Cycle 69 20\n",
      "Took to collect: 9.893932819366455\n",
      "Took to train: 6.4595630168914795\n",
      "\n",
      " Cycle 70 20\n",
      "Took to collect: 8.287262439727783\n",
      "Took to train: 6.41135311126709\n",
      "\n",
      " Cycle 71 20\n",
      "Took to collect: 8.488550424575806\n",
      "Took to train: 6.290292501449585\n",
      "\n",
      " Cycle 72 20\n",
      "Took to collect: 8.15633487701416\n",
      "Took to train: 6.370387315750122\n",
      "\n",
      " Cycle 73 20\n",
      "Took to collect: 8.945090293884277\n",
      "Took to train: 6.4013378620147705\n",
      "\n",
      " Cycle 74 20\n",
      "Took to collect: 7.47396445274353\n",
      "Took to train: 6.427866458892822\n",
      "\n",
      " Cycle 75 20\n",
      "Took to collect: 8.083022832870483\n",
      "Took to train: 6.473581552505493\n",
      "\n",
      " Cycle 76 20\n",
      "Took to collect: 9.772957563400269\n",
      "Took to train: 6.443285942077637\n",
      "\n",
      " Cycle 77 20\n",
      "Took to collect: 10.072806119918823\n",
      "Took to train: 6.456476211547852\n",
      "\n",
      " Cycle 78 20\n",
      "Took to collect: 7.084900617599487\n",
      "Took to train: 6.416467189788818\n",
      "\n",
      " Cycle 79 20\n",
      "Took to collect: 8.425269603729248\n",
      "Took to train: 6.421205997467041\n",
      "\n",
      " Cycle 80 20\n",
      "Took to collect: 8.319241762161255\n",
      "Took to train: 6.313586711883545\n",
      "\n",
      " Cycle 81 20\n",
      "Took to collect: 7.737652063369751\n",
      "Took to train: 6.26011323928833\n",
      "\n",
      " Cycle 82 20\n",
      "Took to collect: 7.883167743682861\n",
      "Took to train: 6.284860849380493\n",
      "\n",
      " Cycle 83 20\n",
      "Took to collect: 9.132957220077515\n",
      "Took to train: 6.346598863601685\n",
      "\n",
      " Cycle 84 20\n",
      "Took to collect: 8.655722856521606\n",
      "Took to train: 6.237131834030151\n",
      "\n",
      " Cycle 85 20\n",
      "Took to collect: 8.038778305053711\n",
      "Took to train: 6.234557390213013\n",
      "\n",
      " Cycle 86 20\n",
      "Took to collect: 7.137294769287109\n",
      "Took to train: 6.278292417526245\n",
      "\n",
      " Cycle 87 20\n",
      "Took to collect: 7.978417873382568\n",
      "Took to train: 6.265859127044678\n",
      "\n",
      " Cycle 88 20\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.847054481506348\n",
      "Took to train: 6.246496200561523\n",
      "\n",
      " Cycle 89 20\n",
      "Took to collect: 9.342011451721191\n",
      "Took to train: 6.2579505443573\n",
      "\n",
      " Cycle 90 20\n",
      "Took to collect: 9.691075325012207\n",
      "Took to train: 6.260627269744873\n",
      "\n",
      " Cycle 91 20\n",
      "Took to collect: 10.277260303497314\n",
      "Took to train: 6.416945934295654\n",
      "\n",
      " Cycle 92 20\n",
      "Took to collect: 8.311469793319702\n",
      "Took to train: 6.408989906311035\n",
      "\n",
      " Cycle 93 20\n",
      "Took to collect: 7.864995718002319\n",
      "Took to train: 6.385659456253052\n",
      "\n",
      " Cycle 94 20\n",
      "Took to collect: 6.812504053115845\n",
      "Took to train: 6.405970335006714\n",
      "\n",
      " Cycle 95 20\n",
      "Took to collect: 8.13611626625061\n",
      "Took to train: 6.275267839431763\n",
      "\n",
      " Cycle 96 20\n",
      "Took to collect: 10.068172931671143\n",
      "Took to train: 6.2835235595703125\n",
      "\n",
      " Cycle 97 20\n",
      "Took to collect: 9.14925217628479\n",
      "Took to train: 6.404050350189209\n",
      "\n",
      " Cycle 98 20\n",
      "Took to collect: 8.569645643234253\n",
      "Took to train: 6.396258592605591\n",
      "\n",
      " Cycle 99 20\n",
      "Took to collect: 8.406052589416504\n",
      "Took to train: 6.38596773147583\n",
      "Time collect avg cycle: 7.323487656116486\n",
      "Time train avg cycle: 6.409744017124176\n",
      "Total avg cycle: 13.743336730003357\n",
      "Ending epoch\n",
      "2020-10-26 05:42:17.572735 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 20 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.717906\n",
      "trainer/QF2 Loss                                    0.581181\n",
      "trainer/Policy Loss                                45.373\n",
      "trainer/Q1 Predictions Mean                       -45.516\n",
      "trainer/Q1 Predictions Std                         35.3959\n",
      "trainer/Q1 Predictions Max                         14.474\n",
      "trainer/Q1 Predictions Min                       -106.163\n",
      "trainer/Q2 Predictions Mean                       -45.3947\n",
      "trainer/Q2 Predictions Std                         35.4694\n",
      "trainer/Q2 Predictions Max                         14.649\n",
      "trainer/Q2 Predictions Min                       -105.689\n",
      "trainer/Q Targets Mean                            -45.1298\n",
      "trainer/Q Targets Std                              35.6727\n",
      "trainer/Q Targets Max                              15.2573\n",
      "trainer/Q Targets Min                            -105.592\n",
      "trainer/Log Pis Mean                                2.77325\n",
      "trainer/Log Pis Std                                 2.00944\n",
      "trainer/Log Pis Max                                 9.34156\n",
      "trainer/Log Pis Min                                -3.98918\n",
      "trainer/policy/mean Mean                           -0.231332\n",
      "trainer/policy/mean Std                             0.640487\n",
      "trainer/policy/mean Max                             0.996245\n",
      "trainer/policy/mean Min                            -0.995445\n",
      "trainer/policy/normal/std Mean                      0.368069\n",
      "trainer/policy/normal/std Std                       0.248341\n",
      "trainer/policy/normal/std Max                       1.49636\n",
      "trainer/policy/normal/std Min                       0.0428494\n",
      "trainer/policy/normal/log_std Mean                 -1.26012\n",
      "trainer/policy/normal/log_std Std                   0.771641\n",
      "trainer/policy/normal/log_std Max                   0.403035\n",
      "trainer/policy/normal/log_std Min                  -3.15006\n",
      "trainer/Alpha                                       0.0129811\n",
      "trainer/Alpha Loss                                 -0.98507\n",
      "exploration/num steps total                    211000\n",
      "exploration/num paths total                      4236\n",
      "exploration/path length Mean                       49.7512\n",
      "exploration/path length Std                         2.67433\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        15\n",
      "exploration/Rewards Mean                           -0.9999\n",
      "exploration/Rewards Std                             0.0099995\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.7463\n",
      "exploration/Returns Std                             2.73912\n",
      "exploration/Returns Max                           -14\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.434439\n",
      "exploration/Actions Std                             0.640983\n",
      "exploration/Actions Max                             0.999984\n",
      "exploration/Actions Min                            -0.999945\n",
      "exploration/Num Paths                             201\n",
      "exploration/Average Returns                       -49.7463\n",
      "exploration/env_infos/final/is_success Mean         0.00497512\n",
      "exploration/env_infos/final/is_success Std          0.0703589\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0001\n",
      "exploration/env_infos/is_success Std                0.0099995\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      10390\n",
      "evaluation/num paths total                        211\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.910827\n",
      "evaluation/Actions Std                              0.0232124\n",
      "evaluation/Actions Max                             -0.785144\n",
      "evaluation/Actions Min                             -0.987907\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.98462\n",
      "time/evaluation sampling (s)                       23.8996\n",
      "time/exploration sampling (s)                     732.369\n",
      "time/logging (s)                                    0.028074\n",
      "time/sac training (s)                             199.417\n",
      "time/saving (s)                                     0.0143001\n",
      "time/training (s)                                   0.00700363\n",
      "time/epoch (s)                                    956.719\n",
      "time/total (s)                                  29010.5\n",
      "Epoch                                              20\n",
      "---------------------------------------------  ---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 21\n",
      "\n",
      " Cycle 0 21\n",
      "Took to collect: 7.666482210159302\n",
      "Took to train: 6.430756568908691\n",
      "\n",
      " Cycle 1 21\n",
      "Took to collect: 7.426166534423828\n",
      "Took to train: 6.485415697097778\n",
      "\n",
      " Cycle 2 21\n",
      "Took to collect: 7.602356672286987\n",
      "Took to train: 6.479855537414551\n",
      "\n",
      " Cycle 3 21\n",
      "Took to collect: 6.864947080612183\n",
      "Took to train: 6.384860992431641\n",
      "\n",
      " Cycle 4 21\n",
      "Took to collect: 9.286245107650757\n",
      "Took to train: 6.442263841629028\n",
      "\n",
      " Cycle 5 21\n",
      "Took to collect: 7.367854595184326\n",
      "Took to train: 6.4034998416900635\n",
      "\n",
      " Cycle 6 21\n",
      "Took to collect: 8.085662841796875\n",
      "Took to train: 6.397933721542358\n",
      "\n",
      " Cycle 7 21\n",
      "Took to collect: 8.331686019897461\n",
      "Took to train: 6.455006122589111\n",
      "\n",
      " Cycle 8 21\n",
      "Took to collect: 7.852252721786499\n",
      "Took to train: 6.31045126914978\n",
      "\n",
      " Cycle 9 21\n",
      "Took to collect: 8.46362566947937\n",
      "Took to train: 6.2703776359558105\n",
      "\n",
      " Cycle 10 21\n",
      "Took to collect: 7.545087575912476\n",
      "Took to train: 6.269252300262451\n",
      "\n",
      " Cycle 11 21\n",
      "Took to collect: 7.393659591674805\n",
      "Took to train: 6.280557632446289\n",
      "\n",
      " Cycle 12 21\n",
      "Took to collect: 7.840651035308838\n",
      "Took to train: 6.293156385421753\n",
      "\n",
      " Cycle 13 21\n",
      "Took to collect: 7.467883586883545\n",
      "Took to train: 6.492484092712402\n",
      "\n",
      " Cycle 14 21\n",
      "Took to collect: 7.838918685913086\n",
      "Took to train: 6.466453552246094\n",
      "\n",
      " Cycle 15 21\n",
      "Took to collect: 7.963357210159302\n",
      "Took to train: 6.513297080993652\n",
      "\n",
      " Cycle 16 21\n",
      "Took to collect: 7.59475564956665\n",
      "Took to train: 6.530749082565308\n",
      "\n",
      " Cycle 17 21\n",
      "Took to collect: 8.418270587921143\n",
      "Took to train: 6.526439666748047\n",
      "\n",
      " Cycle 18 21\n",
      "Took to collect: 8.576702356338501\n",
      "Took to train: 6.520251035690308\n",
      "\n",
      " Cycle 19 21\n",
      "Took to collect: 7.867642164230347\n",
      "Took to train: 6.523556709289551\n",
      "\n",
      " Cycle 20 21\n",
      "Took to collect: 7.197787523269653\n",
      "Took to train: 6.441095352172852\n",
      "\n",
      " Cycle 21 21\n",
      "Took to collect: 9.498153448104858\n",
      "Took to train: 6.365648984909058\n",
      "\n",
      " Cycle 22 21\n",
      "Took to collect: 8.354371786117554\n",
      "Took to train: 6.487939357757568\n",
      "\n",
      " Cycle 23 21\n",
      "Took to collect: 9.278291463851929\n",
      "Took to train: 6.4591147899627686\n",
      "\n",
      " Cycle 24 21\n",
      "Took to collect: 7.5778563022613525\n",
      "Took to train: 6.468344449996948\n",
      "\n",
      " Cycle 25 21\n",
      "Took to collect: 8.344511032104492\n",
      "Took to train: 6.450193643569946\n",
      "\n",
      " Cycle 26 21\n",
      "Took to collect: 7.671548366546631\n",
      "Took to train: 6.463152647018433\n",
      "\n",
      " Cycle 27 21\n",
      "Took to collect: 7.744590997695923\n",
      "Took to train: 6.481110334396362\n",
      "\n",
      " Cycle 28 21\n",
      "Took to collect: 9.917639255523682\n",
      "Took to train: 6.497786283493042\n",
      "\n",
      " Cycle 29 21\n",
      "Took to collect: 7.488586664199829\n",
      "Took to train: 6.477020740509033\n",
      "\n",
      " Cycle 30 21\n",
      "Took to collect: 7.94719123840332\n",
      "Took to train: 6.270097494125366\n",
      "\n",
      " Cycle 31 21\n",
      "Took to collect: 9.060038805007935\n",
      "Took to train: 6.270987272262573\n",
      "\n",
      " Cycle 32 21\n",
      "Took to collect: 8.591419696807861\n",
      "Took to train: 6.392877578735352\n",
      "\n",
      " Cycle 33 21\n",
      "Took to collect: 7.227938175201416\n",
      "Took to train: 6.379504203796387\n",
      "\n",
      " Cycle 34 21\n",
      "Took to collect: 7.23301887512207\n",
      "Took to train: 6.410520315170288\n",
      "\n",
      " Cycle 35 21\n",
      "Took to collect: 8.607910394668579\n",
      "Took to train: 6.389637231826782\n",
      "\n",
      " Cycle 36 21\n",
      "Took to collect: 7.2350029945373535\n",
      "Took to train: 6.338565111160278\n",
      "\n",
      " Cycle 37 21\n",
      "Took to collect: 8.5601167678833\n",
      "Took to train: 6.354526042938232\n",
      "\n",
      " Cycle 38 21\n",
      "Took to collect: 8.911322832107544\n",
      "Took to train: 6.369297742843628\n",
      "\n",
      " Cycle 39 21\n",
      "Took to collect: 7.5278754234313965\n",
      "Took to train: 6.396275520324707\n",
      "\n",
      " Cycle 40 21\n",
      "Took to collect: 8.411808729171753\n",
      "Took to train: 6.387937068939209\n",
      "\n",
      " Cycle 41 21\n",
      "Took to collect: 9.533247232437134\n",
      "Took to train: 6.401634454727173\n",
      "\n",
      " Cycle 42 21\n",
      "Took to collect: 9.431474685668945\n",
      "Took to train: 6.277496814727783\n",
      "\n",
      " Cycle 43 21\n",
      "Took to collect: 8.578935384750366\n",
      "Took to train: 6.273700714111328\n",
      "\n",
      " Cycle 44 21\n",
      "Took to collect: 7.219318628311157\n",
      "Took to train: 6.328101396560669\n",
      "\n",
      " Cycle 45 21\n",
      "Took to collect: 7.864272832870483\n",
      "Took to train: 6.451467990875244\n",
      "\n",
      " Cycle 46 21\n",
      "Took to collect: 8.718043088912964\n",
      "Took to train: 6.479822158813477\n",
      "\n",
      " Cycle 47 21\n",
      "Took to collect: 8.329956531524658\n",
      "Took to train: 6.47013783454895\n",
      "\n",
      " Cycle 48 21\n",
      "Took to collect: 7.5834314823150635\n",
      "Took to train: 6.474493980407715\n",
      "\n",
      " Cycle 49 21\n",
      "Took to collect: 8.515139818191528\n",
      "Took to train: 6.481525421142578\n",
      "\n",
      " Cycle 50 21\n",
      "Took to collect: 10.137960433959961\n",
      "Took to train: 6.533003091812134\n",
      "\n",
      " Cycle 51 21\n",
      "Took to collect: 8.130939245223999\n",
      "Took to train: 6.448963403701782\n",
      "\n",
      " Cycle 52 21\n",
      "Took to collect: 10.857126951217651\n",
      "Took to train: 6.46039605140686\n",
      "\n",
      " Cycle 53 21\n",
      "Took to collect: 7.066670656204224\n",
      "Took to train: 6.466820001602173\n",
      "\n",
      " Cycle 54 21\n",
      "Took to collect: 7.915165901184082\n",
      "Took to train: 6.466546058654785\n",
      "\n",
      " Cycle 55 21\n",
      "Took to collect: 9.53455138206482\n",
      "Took to train: 6.532086133956909\n",
      "\n",
      " Cycle 56 21\n",
      "Took to collect: 8.457316875457764\n",
      "Took to train: 6.457085609436035\n",
      "\n",
      " Cycle 57 21\n",
      "Took to collect: 8.643202066421509\n",
      "Took to train: 6.4466681480407715\n",
      "\n",
      " Cycle 58 21\n",
      "Took to collect: 9.131272792816162\n",
      "Took to train: 6.526666879653931\n",
      "\n",
      " Cycle 59 21\n",
      "Took to collect: 9.54893445968628\n",
      "Took to train: 6.399563312530518\n",
      "\n",
      " Cycle 60 21\n",
      "Took to collect: 7.935098171234131\n",
      "Took to train: 6.432915210723877\n",
      "\n",
      " Cycle 61 21\n",
      "Took to collect: 9.179830551147461\n",
      "Took to train: 6.472924709320068\n",
      "\n",
      " Cycle 62 21\n",
      "Took to collect: 8.88789677619934\n",
      "Took to train: 6.4952614307403564\n",
      "\n",
      " Cycle 63 21\n",
      "Took to collect: 8.386247396469116\n",
      "Took to train: 6.490869045257568\n",
      "\n",
      " Cycle 64 21\n",
      "Took to collect: 9.374606132507324\n",
      "Took to train: 6.508160829544067\n",
      "\n",
      " Cycle 65 21\n",
      "Took to collect: 9.493826866149902\n",
      "Took to train: 6.471922874450684\n",
      "\n",
      " Cycle 66 21\n",
      "Took to collect: 10.283745765686035\n",
      "Took to train: 6.490764856338501\n",
      "\n",
      " Cycle 67 21\n",
      "Took to collect: 9.313668489456177\n",
      "Took to train: 6.427664279937744\n",
      "\n",
      " Cycle 68 21\n",
      "Took to collect: 8.008106231689453\n",
      "Took to train: 6.435126066207886\n",
      "\n",
      " Cycle 69 21\n",
      "Took to collect: 7.257570505142212\n",
      "Took to train: 6.4096434116363525\n",
      "\n",
      " Cycle 70 21\n",
      "Took to collect: 8.490962743759155\n",
      "Took to train: 6.424870491027832\n",
      "\n",
      " Cycle 71 21\n",
      "Took to collect: 7.147288084030151\n",
      "Took to train: 6.391153812408447\n",
      "\n",
      " Cycle 72 21\n",
      "Took to collect: 7.550724029541016\n",
      "Took to train: 6.420860528945923\n",
      "\n",
      " Cycle 73 21\n",
      "Took to collect: 8.052178621292114\n",
      "Took to train: 6.383228063583374\n",
      "\n",
      " Cycle 74 21\n",
      "Took to collect: 8.72222113609314\n",
      "Took to train: 6.3197009563446045\n",
      "\n",
      " Cycle 75 21\n",
      "Took to collect: 7.3531715869903564\n",
      "Took to train: 6.470242023468018\n",
      "\n",
      " Cycle 76 21\n",
      "Took to collect: 10.983588457107544\n",
      "Took to train: 6.375906467437744\n",
      "\n",
      " Cycle 77 21\n",
      "Took to collect: 9.00553011894226\n",
      "Took to train: 6.357214689254761\n",
      "\n",
      " Cycle 78 21\n",
      "Took to collect: 9.003653526306152\n",
      "Took to train: 6.500761270523071\n",
      "\n",
      " Cycle 79 21\n",
      "Took to collect: 9.083542823791504\n",
      "Took to train: 6.456569194793701\n",
      "\n",
      " Cycle 80 21\n",
      "Took to collect: 8.815257549285889\n",
      "Took to train: 6.425614595413208\n",
      "\n",
      " Cycle 81 21\n",
      "Took to collect: 7.378512620925903\n",
      "Took to train: 6.410075902938843\n",
      "\n",
      " Cycle 82 21\n",
      "Took to collect: 7.549598693847656\n",
      "Took to train: 6.35352087020874\n",
      "\n",
      " Cycle 83 21\n",
      "Took to collect: 8.185119390487671\n",
      "Took to train: 6.3669867515563965\n",
      "\n",
      " Cycle 84 21\n",
      "Took to collect: 8.80066204071045\n",
      "Took to train: 6.305240869522095\n",
      "\n",
      " Cycle 85 21\n",
      "Took to collect: 7.947943925857544\n",
      "Took to train: 6.381872892379761\n",
      "\n",
      " Cycle 86 21\n",
      "Took to collect: 8.012741804122925\n",
      "Took to train: 6.315799713134766\n",
      "\n",
      " Cycle 87 21\n",
      "Took to collect: 9.187630891799927\n",
      "Took to train: 6.346210718154907\n",
      "\n",
      " Cycle 88 21\n",
      "Took to collect: 8.833948850631714\n",
      "Took to train: 6.3788902759552\n",
      "\n",
      " Cycle 89 21\n",
      "Took to collect: 8.54338788986206\n",
      "Took to train: 6.373633861541748\n",
      "\n",
      " Cycle 90 21\n",
      "Took to collect: 9.517673969268799\n",
      "Took to train: 6.346461772918701\n",
      "\n",
      " Cycle 91 21\n",
      "Took to collect: 6.755149841308594\n",
      "Took to train: 6.402378559112549\n",
      "\n",
      " Cycle 92 21\n",
      "Took to collect: 8.822898864746094\n",
      "Took to train: 6.313500165939331\n",
      "\n",
      " Cycle 93 21\n",
      "Took to collect: 8.91977834701538\n",
      "Took to train: 6.4243879318237305\n",
      "\n",
      " Cycle 94 21\n",
      "Took to collect: 7.942990064620972\n",
      "Took to train: 6.398537874221802\n",
      "\n",
      " Cycle 95 21\n",
      "Took to collect: 7.563582897186279\n",
      "Took to train: 6.309995889663696\n",
      "\n",
      " Cycle 96 21\n",
      "Took to collect: 7.693316221237183\n",
      "Took to train: 6.373376131057739\n",
      "\n",
      " Cycle 97 21\n",
      "Took to collect: 9.494573593139648\n",
      "Took to train: 6.55094313621521\n",
      "\n",
      " Cycle 98 21\n",
      "Took to collect: 8.747976303100586\n",
      "Took to train: 6.45878791809082\n",
      "\n",
      " Cycle 99 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 7.610329866409302\n",
      "Took to train: 6.590121269226074\n",
      "Time collect avg cycle: 8.348746807575226\n",
      "Time train avg cycle: 6.419665277004242\n",
      "Total avg cycle: 14.778446836471558\n",
      "Ending epoch\n",
      "2020-10-26 06:07:34.918143 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 21 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.581878\n",
      "trainer/QF2 Loss                                    0.533852\n",
      "trainer/Policy Loss                                43.6422\n",
      "trainer/Q1 Predictions Mean                       -43.7301\n",
      "trainer/Q1 Predictions Std                         37.3623\n",
      "trainer/Q1 Predictions Max                         10.9107\n",
      "trainer/Q1 Predictions Min                       -106.121\n",
      "trainer/Q2 Predictions Mean                       -43.562\n",
      "trainer/Q2 Predictions Std                         37.398\n",
      "trainer/Q2 Predictions Max                         11.2367\n",
      "trainer/Q2 Predictions Min                       -105.78\n",
      "trainer/Q Targets Mean                            -43.7647\n",
      "trainer/Q Targets Std                              37.3607\n",
      "trainer/Q Targets Max                              10.8064\n",
      "trainer/Q Targets Min                            -105.929\n",
      "trainer/Log Pis Mean                                3.14526\n",
      "trainer/Log Pis Std                                 2.3199\n",
      "trainer/Log Pis Max                                10.0299\n",
      "trainer/Log Pis Min                                -4.39498\n",
      "trainer/policy/mean Mean                           -0.32535\n",
      "trainer/policy/mean Std                             0.637821\n",
      "trainer/policy/mean Max                             0.992487\n",
      "trainer/policy/mean Min                            -0.996369\n",
      "trainer/policy/normal/std Mean                      0.371262\n",
      "trainer/policy/normal/std Std                       0.236936\n",
      "trainer/policy/normal/std Max                       1.5738\n",
      "trainer/policy/normal/std Min                       0.0419513\n",
      "trainer/policy/normal/log_std Mean                 -1.247\n",
      "trainer/policy/normal/log_std Std                   0.780057\n",
      "trainer/policy/normal/log_std Max                   0.453496\n",
      "trainer/policy/normal/log_std Min                  -3.17125\n",
      "trainer/Alpha                                       0.0118973\n",
      "trainer/Alpha Loss                                  0.643716\n",
      "exploration/num steps total                    221000\n",
      "exploration/num paths total                      4436\n",
      "exploration/path length Mean                       50\n",
      "exploration/path length Std                         0\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        50\n",
      "exploration/Rewards Mean                           -1\n",
      "exploration/Rewards Std                             0\n",
      "exploration/Rewards Max                            -1\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -50\n",
      "exploration/Returns Std                             0\n",
      "exploration/Returns Max                           -50\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.301662\n",
      "exploration/Actions Std                             0.67994\n",
      "exploration/Actions Max                             0.999997\n",
      "exploration/Actions Min                            -0.999922\n",
      "exploration/Num Paths                             200\n",
      "exploration/Average Returns                       -50\n",
      "exploration/env_infos/final/is_success Mean         0\n",
      "exploration/env_infos/final/is_success Std          0\n",
      "exploration/env_infos/final/is_success Max          0\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0\n",
      "exploration/env_infos/is_success Std                0\n",
      "exploration/env_infos/is_success Max                0\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      10890\n",
      "evaluation/num paths total                        221\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.372367\n",
      "evaluation/Actions Std                              0.564307\n",
      "evaluation/Actions Max                              0.980681\n",
      "evaluation/Actions Min                             -0.984647\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.977681\n",
      "time/evaluation sampling (s)                       39.4364\n",
      "time/exploration sampling (s)                     834.894\n",
      "time/logging (s)                                    0.0273819\n",
      "time/sac training (s)                             199.844\n",
      "time/saving (s)                                     0.0153241\n",
      "time/training (s)                                   0.00711224\n",
      "time/epoch (s)                                   1075.2\n",
      "time/total (s)                                  30527.6\n",
      "Epoch                                              21\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 22\n",
      "\n",
      " Cycle 0 22\n",
      "Took to collect: 7.4532129764556885\n",
      "Took to train: 6.476136684417725\n",
      "\n",
      " Cycle 1 22\n",
      "Took to collect: 8.986608982086182\n",
      "Took to train: 6.400609016418457\n",
      "\n",
      " Cycle 2 22\n",
      "Took to collect: 8.598938703536987\n",
      "Took to train: 6.396713733673096\n",
      "\n",
      " Cycle 3 22\n",
      "Took to collect: 9.137828588485718\n",
      "Took to train: 6.463092088699341\n",
      "\n",
      " Cycle 4 22\n",
      "Took to collect: 8.435728073120117\n",
      "Took to train: 6.4113287925720215\n",
      "\n",
      " Cycle 5 22\n",
      "Took to collect: 7.538560390472412\n",
      "Took to train: 6.415788173675537\n",
      "\n",
      " Cycle 6 22\n",
      "Took to collect: 8.71255350112915\n",
      "Took to train: 6.451447248458862\n",
      "\n",
      " Cycle 7 22\n",
      "Took to collect: 8.967007875442505\n",
      "Took to train: 6.438854932785034\n",
      "\n",
      " Cycle 8 22\n",
      "Took to collect: 9.476990461349487\n",
      "Took to train: 6.464439630508423\n",
      "\n",
      " Cycle 9 22\n",
      "Took to collect: 8.987927675247192\n",
      "Took to train: 6.4559173583984375\n",
      "\n",
      " Cycle 10 22\n",
      "Took to collect: 7.631192922592163\n",
      "Took to train: 6.449335098266602\n",
      "\n",
      " Cycle 11 22\n",
      "Took to collect: 8.974800825119019\n",
      "Took to train: 6.453714847564697\n",
      "\n",
      " Cycle 12 22\n",
      "Took to collect: 7.907599925994873\n",
      "Took to train: 6.479703664779663\n",
      "\n",
      " Cycle 13 22\n",
      "Took to collect: 8.19090747833252\n",
      "Took to train: 6.514948844909668\n",
      "\n",
      " Cycle 14 22\n",
      "Took to collect: 6.995614767074585\n",
      "Took to train: 6.502686262130737\n",
      "\n",
      " Cycle 15 22\n",
      "Took to collect: 6.925585985183716\n",
      "Took to train: 6.503729581832886\n",
      "\n",
      " Cycle 16 22\n",
      "Took to collect: 8.875614643096924\n",
      "Took to train: 6.492311239242554\n",
      "\n",
      " Cycle 17 22\n",
      "Took to collect: 7.337379217147827\n",
      "Took to train: 6.508812189102173\n",
      "\n",
      " Cycle 18 22\n",
      "Took to collect: 6.9288365840911865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.392401456832886\n",
      "\n",
      " Cycle 19 22\n",
      "Took to collect: 8.797861099243164\n",
      "Took to train: 6.456406593322754\n",
      "\n",
      " Cycle 20 22\n",
      "Took to collect: 8.96248197555542\n",
      "Took to train: 6.483520030975342\n",
      "\n",
      " Cycle 21 22\n",
      "Took to collect: 7.909155607223511\n",
      "Took to train: 6.522102355957031\n",
      "\n",
      " Cycle 22 22\n",
      "Took to collect: 8.344345331192017\n",
      "Took to train: 6.340822696685791\n",
      "\n",
      " Cycle 23 22\n",
      "Took to collect: 8.238951921463013\n",
      "Took to train: 6.348430871963501\n",
      "\n",
      " Cycle 24 22\n",
      "Took to collect: 7.303746938705444\n",
      "Took to train: 6.387957572937012\n",
      "\n",
      " Cycle 25 22\n",
      "Took to collect: 7.976907968521118\n",
      "Took to train: 6.444760084152222\n",
      "\n",
      " Cycle 26 22\n",
      "Took to collect: 9.015056371688843\n",
      "Took to train: 6.517360687255859\n",
      "\n",
      " Cycle 27 22\n",
      "Took to collect: 9.019794940948486\n",
      "Took to train: 6.4682066440582275\n",
      "\n",
      " Cycle 28 22\n",
      "Took to collect: 8.008968114852905\n",
      "Took to train: 6.458425521850586\n",
      "\n",
      " Cycle 29 22\n",
      "Took to collect: 9.820497274398804\n",
      "Took to train: 6.467533588409424\n",
      "\n",
      " Cycle 30 22\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.587386608123779\n",
      "Took to train: 6.4470202922821045\n",
      "\n",
      " Cycle 31 22\n",
      "Took to collect: 8.699227333068848\n",
      "Took to train: 6.345147132873535\n",
      "\n",
      " Cycle 32 22\n",
      "Took to collect: 8.31503939628601\n",
      "Took to train: 6.467135429382324\n",
      "\n",
      " Cycle 33 22\n",
      "Took to collect: 7.806813478469849\n",
      "Took to train: 6.488884449005127\n",
      "\n",
      " Cycle 34 22\n",
      "Took to collect: 8.24593997001648\n",
      "Took to train: 6.43855619430542\n",
      "\n",
      " Cycle 35 22\n",
      "Took to collect: 7.5035080909729\n",
      "Took to train: 6.481575965881348\n",
      "\n",
      " Cycle 36 22\n",
      "Took to collect: 8.828492879867554\n",
      "Took to train: 6.493487596511841\n",
      "\n",
      " Cycle 37 22\n",
      "Took to collect: 8.91787052154541\n",
      "Took to train: 6.5037267208099365\n",
      "\n",
      " Cycle 38 22\n",
      "Took to collect: 7.965566396713257\n",
      "Took to train: 6.522492408752441\n",
      "\n",
      " Cycle 39 22\n",
      "Took to collect: 9.096615076065063\n",
      "Took to train: 6.514240741729736\n",
      "\n",
      " Cycle 40 22\n",
      "Took to collect: 7.335116147994995\n",
      "Took to train: 6.5024261474609375\n",
      "\n",
      " Cycle 41 22\n",
      "Took to collect: 9.868846654891968\n",
      "Took to train: 6.513614177703857\n",
      "\n",
      " Cycle 42 22\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 5.556978464126587\n",
      "Took to train: 6.447244644165039\n",
      "\n",
      " Cycle 43 22\n",
      "Took to collect: 8.969530820846558\n",
      "Took to train: 6.444029092788696\n",
      "\n",
      " Cycle 44 22\n",
      "Took to collect: 8.104186296463013\n",
      "Took to train: 6.430479526519775\n",
      "\n",
      " Cycle 45 22\n",
      "Took to collect: 8.495872259140015\n",
      "Took to train: 6.510002136230469\n",
      "\n",
      " Cycle 46 22\n",
      "Took to collect: 8.97138524055481\n",
      "Took to train: 6.52094841003418\n",
      "\n",
      " Cycle 47 22\n",
      "Took to collect: 6.152681112289429\n",
      "Took to train: 6.4001359939575195\n",
      "\n",
      " Cycle 48 22\n",
      "Took to collect: 8.517976760864258\n",
      "Took to train: 6.331214904785156\n",
      "\n",
      " Cycle 49 22\n",
      "Took to collect: 9.11162281036377\n",
      "Took to train: 6.330796718597412\n",
      "\n",
      " Cycle 50 22\n",
      "Took to collect: 9.413315057754517\n",
      "Took to train: 6.450879812240601\n",
      "\n",
      " Cycle 51 22\n",
      "Took to collect: 9.576846599578857\n",
      "Took to train: 6.394507646560669\n",
      "\n",
      " Cycle 52 22\n",
      "Took to collect: 7.017743825912476\n",
      "Took to train: 6.342182874679565\n",
      "\n",
      " Cycle 53 22\n",
      "Took to collect: 9.127390623092651\n",
      "Took to train: 6.5169408321380615\n",
      "\n",
      " Cycle 54 22\n",
      "Took to collect: 6.783669710159302\n",
      "Took to train: 6.4089860916137695\n",
      "\n",
      " Cycle 55 22\n",
      "Took to collect: 10.132987976074219\n",
      "Took to train: 6.485279321670532\n",
      "\n",
      " Cycle 56 22\n",
      "Took to collect: 8.497831344604492\n",
      "Took to train: 6.497202634811401\n",
      "\n",
      " Cycle 57 22\n",
      "Took to collect: 8.372323751449585\n",
      "Took to train: 6.481613874435425\n",
      "\n",
      " Cycle 58 22\n",
      "Took to collect: 6.990649223327637\n",
      "Took to train: 6.460767030715942\n",
      "\n",
      " Cycle 59 22\n",
      "Took to collect: 7.86836051940918\n",
      "Took to train: 6.451954126358032\n",
      "\n",
      " Cycle 60 22\n",
      "Took to collect: 7.879210948944092\n",
      "Took to train: 6.423285961151123\n",
      "\n",
      " Cycle 61 22\n",
      "Took to collect: 7.5690648555755615\n",
      "Took to train: 6.422877550125122\n",
      "\n",
      " Cycle 62 22\n",
      "Took to collect: 8.370763540267944\n",
      "Took to train: 6.433760643005371\n",
      "\n",
      " Cycle 63 22\n",
      "Took to collect: 6.70592737197876\n",
      "Took to train: 6.440629005432129\n",
      "\n",
      " Cycle 64 22\n",
      "Took to collect: 6.955882787704468\n",
      "Took to train: 6.444085121154785\n",
      "\n",
      " Cycle 65 22\n",
      "Took to collect: 8.458019018173218\n",
      "Took to train: 6.444953918457031\n",
      "\n",
      " Cycle 66 22\n",
      "Took to collect: 7.31750750541687\n",
      "Took to train: 6.5142199993133545\n",
      "\n",
      " Cycle 67 22\n",
      "Took to collect: 8.456299543380737\n",
      "Took to train: 6.363951683044434\n",
      "\n",
      " Cycle 68 22\n",
      "Took to collect: 9.126176118850708\n",
      "Took to train: 6.272155523300171\n",
      "\n",
      " Cycle 69 22\n",
      "Took to collect: 8.625487327575684\n",
      "Took to train: 6.4392290115356445\n",
      "\n",
      " Cycle 70 22\n",
      "Took to collect: 7.990749835968018\n",
      "Took to train: 6.46259617805481\n",
      "\n",
      " Cycle 71 22\n",
      "Took to collect: 7.996849536895752\n",
      "Took to train: 6.462759017944336\n",
      "\n",
      " Cycle 72 22\n",
      "Took to collect: 7.088733911514282\n",
      "Took to train: 6.4156787395477295\n",
      "\n",
      " Cycle 73 22\n",
      "Took to collect: 7.396927833557129\n",
      "Took to train: 6.459531307220459\n",
      "\n",
      " Cycle 74 22\n",
      "Took to collect: 9.643927574157715\n",
      "Took to train: 6.459792137145996\n",
      "\n",
      " Cycle 75 22\n",
      "Took to collect: 7.6854164600372314\n",
      "Took to train: 6.418361186981201\n",
      "\n",
      " Cycle 76 22\n",
      "Took to collect: 7.378297567367554\n",
      "Took to train: 6.453331470489502\n",
      "\n",
      " Cycle 77 22\n",
      "Took to collect: 7.073930025100708\n",
      "Took to train: 6.431805610656738\n",
      "\n",
      " Cycle 78 22\n",
      "Took to collect: 7.817754030227661\n",
      "Took to train: 6.361555337905884\n",
      "\n",
      " Cycle 79 22\n",
      "Took to collect: 7.319077253341675\n",
      "Took to train: 6.278165340423584\n",
      "\n",
      " Cycle 80 22\n",
      "Took to collect: 5.859226226806641\n",
      "Took to train: 6.391402721405029\n",
      "\n",
      " Cycle 81 22\n",
      "Took to collect: 8.493538618087769\n",
      "Took to train: 6.430338382720947\n",
      "\n",
      " Cycle 82 22\n",
      "Took to collect: 5.907278060913086\n",
      "Took to train: 6.343786716461182\n",
      "\n",
      " Cycle 83 22\n",
      "Took to collect: 6.612351417541504\n",
      "Took to train: 6.406070947647095\n",
      "\n",
      " Cycle 84 22\n",
      "Took to collect: 7.338349103927612\n",
      "Took to train: 6.364982604980469\n",
      "\n",
      " Cycle 85 22\n",
      "Took to collect: 8.81443738937378\n",
      "Took to train: 6.304771184921265\n",
      "\n",
      " Cycle 86 22\n",
      "Took to collect: 9.136220693588257\n",
      "Took to train: 6.407621622085571\n",
      "\n",
      " Cycle 87 22\n",
      "Took to collect: 6.568187475204468\n",
      "Took to train: 6.287877798080444\n",
      "\n",
      " Cycle 88 22\n",
      "Took to collect: 9.134289503097534\n",
      "Took to train: 6.366223573684692\n",
      "\n",
      " Cycle 89 22\n",
      "Took to collect: 7.345991611480713\n",
      "Took to train: 6.444063186645508\n",
      "\n",
      " Cycle 90 22\n",
      "Took to collect: 8.328499555587769\n",
      "Took to train: 6.415862798690796\n",
      "\n",
      " Cycle 91 22\n",
      "Took to collect: 6.7041168212890625\n",
      "Took to train: 6.438333034515381\n",
      "\n",
      " Cycle 92 22\n",
      "Took to collect: 6.578204393386841\n",
      "Took to train: 6.414932012557983\n",
      "\n",
      " Cycle 93 22\n",
      "Took to collect: 7.231822490692139\n",
      "Took to train: 6.332071304321289\n",
      "\n",
      " Cycle 94 22\n",
      "Took to collect: 6.256964683532715\n",
      "Took to train: 6.315712928771973\n",
      "\n",
      " Cycle 95 22\n",
      "Took to collect: 7.3444600105285645\n",
      "Took to train: 6.227751016616821\n",
      "\n",
      " Cycle 96 22\n",
      "Took to collect: 7.557358503341675\n",
      "Took to train: 6.263704061508179\n",
      "\n",
      " Cycle 97 22\n",
      "Took to collect: 10.600280046463013\n",
      "Took to train: 6.354597091674805\n",
      "\n",
      " Cycle 98 22\n",
      "Took to collect: 7.269894123077393\n",
      "Took to train: 6.360103368759155\n",
      "\n",
      " Cycle 99 22\n",
      "Took to collect: 9.162595272064209\n",
      "Took to train: 6.6069111824035645\n",
      "Time collect avg cycle: 8.06392501115799\n",
      "Time train avg cycle: 6.43070812702179\n",
      "Total avg cycle: 14.50495815038681\n",
      "Ending epoch\n",
      "2020-10-26 06:32:28.334707 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 22 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.476899\n",
      "trainer/QF2 Loss                                    0.486679\n",
      "trainer/Policy Loss                                44.0379\n",
      "trainer/Q1 Predictions Mean                       -44.0604\n",
      "trainer/Q1 Predictions Std                         35.7236\n",
      "trainer/Q1 Predictions Max                         14.8359\n",
      "trainer/Q1 Predictions Min                       -106.153\n",
      "trainer/Q2 Predictions Mean                       -44.1387\n",
      "trainer/Q2 Predictions Std                         35.6796\n",
      "trainer/Q2 Predictions Max                         13.8184\n",
      "trainer/Q2 Predictions Min                       -106.062\n",
      "trainer/Q Targets Mean                            -44.088\n",
      "trainer/Q Targets Std                              35.7893\n",
      "trainer/Q Targets Max                              14.2297\n",
      "trainer/Q Targets Min                            -106.624\n",
      "trainer/Log Pis Mean                                3.27237\n",
      "trainer/Log Pis Std                                 2.48638\n",
      "trainer/Log Pis Max                                12.2366\n",
      "trainer/Log Pis Min                                -5.44405\n",
      "trainer/policy/mean Mean                           -0.347237\n",
      "trainer/policy/mean Std                             0.645812\n",
      "trainer/policy/mean Max                             0.990513\n",
      "trainer/policy/mean Min                            -0.998943\n",
      "trainer/policy/normal/std Mean                      0.389096\n",
      "trainer/policy/normal/std Std                       0.249854\n",
      "trainer/policy/normal/std Max                       1.52227\n",
      "trainer/policy/normal/std Min                       0.0382273\n",
      "trainer/policy/normal/log_std Mean                 -1.20034\n",
      "trainer/policy/normal/log_std Std                   0.78774\n",
      "trainer/policy/normal/log_std Max                   0.420205\n",
      "trainer/policy/normal/log_std Min                  -3.26421\n",
      "trainer/Alpha                                       0.0114433\n",
      "trainer/Alpha Loss                                  1.2176\n",
      "exploration/num steps total                    231000\n",
      "exploration/num paths total                      4638\n",
      "exploration/path length Mean                       49.505\n",
      "exploration/path length Std                         4.14734\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         9\n",
      "exploration/Rewards Mean                           -0.9998\n",
      "exploration/Rewards Std                             0.0141407\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.495\n",
      "exploration/Returns Std                             4.2441\n",
      "exploration/Returns Max                            -8\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.268146\n",
      "exploration/Actions Std                             0.687793\n",
      "exploration/Actions Max                             1\n",
      "exploration/Actions Min                            -0.999793\n",
      "exploration/Num Paths                             202\n",
      "exploration/Average Returns                       -49.495\n",
      "exploration/env_infos/final/is_success Mean         0.00990099\n",
      "exploration/env_infos/final/is_success Std          0.0990099\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0002\n",
      "exploration/env_infos/is_success Std                0.0141407\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      11390\n",
      "evaluation/num paths total                        231\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.430037\n",
      "evaluation/Actions Std                              0.684586\n",
      "evaluation/Actions Max                              0.988332\n",
      "evaluation/Actions Min                             -0.9771\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               1.00679\n",
      "time/evaluation sampling (s)                       42.8577\n",
      "time/exploration sampling (s)                     806.412\n",
      "time/logging (s)                                    0.0268141\n",
      "time/sac training (s)                             199.992\n",
      "time/saving (s)                                     0.0137919\n",
      "time/training (s)                                   0.0070954\n",
      "time/epoch (s)                                   1050.32\n",
      "time/total (s)                                  32020.9\n",
      "Epoch                                              22\n",
      "---------------------------------------------  ---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 23\n",
      "\n",
      " Cycle 0 23\n",
      "Took to collect: 9.91431713104248\n",
      "Took to train: 6.451608657836914\n",
      "\n",
      " Cycle 1 23\n",
      "Took to collect: 8.069838523864746\n",
      "Took to train: 6.477284908294678\n",
      "\n",
      " Cycle 2 23\n",
      "Took to collect: 7.824021100997925\n",
      "Took to train: 6.461902379989624\n",
      "\n",
      " Cycle 3 23\n",
      "Took to collect: 7.067220449447632\n",
      "Took to train: 6.463048696517944\n",
      "\n",
      " Cycle 4 23\n",
      "Took to collect: 7.501711845397949\n",
      "Took to train: 6.50118350982666\n",
      "\n",
      " Cycle 5 23\n",
      "Took to collect: 8.436868906021118\n",
      "Took to train: 6.502561092376709\n",
      "\n",
      " Cycle 6 23\n",
      "Took to collect: 8.220127820968628\n",
      "Took to train: 6.4965174198150635\n",
      "\n",
      " Cycle 7 23\n",
      "Took to collect: 8.939707279205322\n",
      "Took to train: 6.465102910995483\n",
      "\n",
      " Cycle 8 23\n",
      "Took to collect: 7.820319652557373\n",
      "Took to train: 6.447517156600952\n",
      "\n",
      " Cycle 9 23\n",
      "Took to collect: 7.759204387664795\n",
      "Took to train: 6.489028453826904\n",
      "\n",
      " Cycle 10 23\n",
      "Took to collect: 8.40775728225708\n",
      "Took to train: 6.481997489929199\n",
      "\n",
      " Cycle 11 23\n",
      "Took to collect: 7.9565253257751465\n",
      "Took to train: 6.454921722412109\n",
      "\n",
      " Cycle 12 23\n",
      "Took to collect: 9.833326816558838\n",
      "Took to train: 6.5044028759002686\n",
      "\n",
      " Cycle 13 23\n",
      "Took to collect: 10.016740322113037\n",
      "Took to train: 6.501200199127197\n",
      "\n",
      " Cycle 14 23\n",
      "Took to collect: 8.053251028060913\n",
      "Took to train: 6.495469093322754\n",
      "\n",
      " Cycle 15 23\n",
      "Took to collect: 8.92598581314087\n",
      "Took to train: 6.494813442230225\n",
      "\n",
      " Cycle 16 23\n",
      "Took to collect: 6.926868677139282\n",
      "Took to train: 6.490068674087524\n",
      "\n",
      " Cycle 17 23\n",
      "Took to collect: 6.141434669494629\n",
      "Took to train: 6.470504522323608\n",
      "\n",
      " Cycle 18 23\n",
      "Took to collect: 8.902658939361572\n",
      "Took to train: 6.481389999389648\n",
      "\n",
      " Cycle 19 23\n",
      "Took to collect: 9.254161357879639\n",
      "Took to train: 6.376385450363159\n",
      "\n",
      " Cycle 20 23\n",
      "Took to collect: 6.14349102973938\n",
      "Took to train: 6.264747142791748\n",
      "\n",
      " Cycle 21 23\n",
      "Took to collect: 6.700040102005005\n",
      "Took to train: 6.311657190322876\n",
      "\n",
      " Cycle 22 23\n",
      "Took to collect: 7.409430265426636\n",
      "Took to train: 6.375115871429443\n",
      "\n",
      " Cycle 23 23\n",
      "Took to collect: 8.042470216751099\n",
      "Took to train: 6.437387943267822\n",
      "\n",
      " Cycle 24 23\n",
      "Took to collect: 9.449604749679565\n",
      "Took to train: 6.459348917007446\n",
      "\n",
      " Cycle 25 23\n",
      "Took to collect: 7.1433916091918945\n",
      "Took to train: 6.413576126098633\n",
      "\n",
      " Cycle 26 23\n",
      "Took to collect: 9.32681918144226\n",
      "Took to train: 6.390409231185913\n",
      "\n",
      " Cycle 27 23\n",
      "Took to collect: 8.173756837844849\n",
      "Took to train: 6.421018123626709\n",
      "\n",
      " Cycle 28 23\n",
      "Took to collect: 7.7715935707092285\n",
      "Took to train: 6.4232776165008545\n",
      "\n",
      " Cycle 29 23\n",
      "Took to collect: 6.911688566207886\n",
      "Took to train: 6.416088581085205\n",
      "\n",
      " Cycle 30 23\n",
      "Took to collect: 9.227543354034424\n",
      "Took to train: 6.42556357383728\n",
      "\n",
      " Cycle 31 23\n",
      "Took to collect: 7.9834043979644775\n",
      "Took to train: 6.35800838470459\n",
      "\n",
      " Cycle 32 23\n",
      "Took to collect: 7.379894733428955\n",
      "Took to train: 6.29215931892395\n",
      "\n",
      " Cycle 33 23\n",
      "Took to collect: 8.439230918884277\n",
      "Took to train: 6.440715312957764\n",
      "\n",
      " Cycle 34 23\n",
      "Took to collect: 7.333461284637451\n",
      "Took to train: 6.254588603973389\n",
      "\n",
      " Cycle 35 23\n",
      "Took to collect: 4.986614942550659\n",
      "Took to train: 6.422714948654175\n",
      "\n",
      " Cycle 36 23\n",
      "Took to collect: 7.363932371139526\n",
      "Took to train: 6.367192029953003\n",
      "\n",
      " Cycle 37 23\n",
      "Took to collect: 6.028803586959839\n",
      "Took to train: 6.38187050819397\n",
      "\n",
      " Cycle 38 23\n",
      "Took to collect: 7.254236936569214\n",
      "Took to train: 6.39382791519165\n",
      "\n",
      " Cycle 39 23\n",
      "Took to collect: 6.46308445930481\n",
      "Took to train: 6.399392127990723\n",
      "\n",
      " Cycle 40 23\n",
      "Took to collect: 7.338780641555786\n",
      "Took to train: 6.280292987823486\n",
      "\n",
      " Cycle 41 23\n",
      "Took to collect: 6.991879463195801\n",
      "Took to train: 6.382089853286743\n",
      "\n",
      " Cycle 42 23\n",
      "Took to collect: 6.856300115585327\n",
      "Took to train: 6.36740255355835\n",
      "\n",
      " Cycle 43 23\n",
      "Took to collect: 6.178761959075928\n",
      "Took to train: 6.351372241973877\n",
      "\n",
      " Cycle 44 23\n",
      "Took to collect: 6.4091668128967285\n",
      "Took to train: 6.375269174575806\n",
      "\n",
      " Cycle 45 23\n",
      "Took to collect: 7.5336408615112305\n",
      "Took to train: 6.347920894622803\n",
      "\n",
      " Cycle 46 23\n",
      "Took to collect: 6.757730484008789\n",
      "Took to train: 6.341902494430542\n",
      "\n",
      " Cycle 47 23\n",
      "Took to collect: 7.302187204360962\n",
      "Took to train: 6.326569557189941\n",
      "\n",
      " Cycle 48 23\n",
      "Took to collect: 6.081803321838379\n",
      "Took to train: 6.357943534851074\n",
      "\n",
      " Cycle 49 23\n",
      "Took to collect: 7.415848016738892\n",
      "Took to train: 6.439607620239258\n",
      "\n",
      " Cycle 50 23\n",
      "Took to collect: 6.322872877120972\n",
      "Took to train: 6.438475608825684\n",
      "\n",
      " Cycle 51 23\n",
      "Took to collect: 7.528640270233154\n",
      "Took to train: 6.463885068893433\n",
      "\n",
      " Cycle 52 23\n",
      "Took to collect: 7.245054483413696\n",
      "Took to train: 6.665676832199097\n",
      "\n",
      " Cycle 53 23\n",
      "Took to collect: 8.64849591255188\n",
      "Took to train: 7.040912628173828\n",
      "\n",
      " Cycle 54 23\n",
      "Took to collect: 6.899045705795288\n",
      "Took to train: 7.121116638183594\n",
      "\n",
      " Cycle 55 23\n",
      "Took to collect: 10.038797616958618\n",
      "Took to train: 7.002150535583496\n",
      "\n",
      " Cycle 56 23\n",
      "Took to collect: 9.506071329116821\n",
      "Took to train: 6.969688177108765\n",
      "\n",
      " Cycle 57 23\n",
      "Took to collect: 11.051501750946045\n",
      "Took to train: 7.0660240650177\n",
      "\n",
      " Cycle 58 23\n",
      "Took to collect: 7.726668834686279\n",
      "Took to train: 6.80522608757019\n",
      "\n",
      " Cycle 59 23\n",
      "Took to collect: 7.861816167831421\n",
      "Took to train: 7.05481219291687\n",
      "\n",
      " Cycle 60 23\n",
      "Took to collect: 6.8223183155059814\n",
      "Took to train: 7.049738645553589\n",
      "\n",
      " Cycle 61 23\n",
      "Took to collect: 7.93939995765686\n",
      "Took to train: 6.593869924545288\n",
      "\n",
      " Cycle 62 23\n",
      "Took to collect: 8.27638292312622\n",
      "Took to train: 6.638085603713989\n",
      "\n",
      " Cycle 63 23\n",
      "Took to collect: 8.40464735031128\n",
      "Took to train: 7.095757722854614\n",
      "\n",
      " Cycle 64 23\n",
      "Took to collect: 6.050854682922363\n",
      "Took to train: 7.031784772872925\n",
      "\n",
      " Cycle 65 23\n",
      "Took to collect: 7.009605407714844\n",
      "Took to train: 7.0435333251953125\n",
      "\n",
      " Cycle 66 23\n",
      "Took to collect: 7.996506690979004\n",
      "Took to train: 7.0915820598602295\n",
      "\n",
      " Cycle 67 23\n",
      "Took to collect: 7.988912105560303\n",
      "Took to train: 6.980618715286255\n",
      "\n",
      " Cycle 68 23\n",
      "Took to collect: 8.257631063461304\n",
      "Took to train: 7.045598268508911\n",
      "\n",
      " Cycle 69 23\n",
      "Took to collect: 6.424893140792847\n",
      "Took to train: 6.949904918670654\n",
      "\n",
      " Cycle 70 23\n",
      "Took to collect: 7.9167258739471436\n",
      "Took to train: 7.045812129974365\n",
      "\n",
      " Cycle 71 23\n",
      "Took to collect: 8.67449402809143\n",
      "Took to train: 7.088074684143066\n",
      "\n",
      " Cycle 72 23\n",
      "Took to collect: 6.114479064941406\n",
      "Took to train: 7.161550283432007\n",
      "\n",
      " Cycle 73 23\n",
      "Took to collect: 7.497912645339966\n",
      "Took to train: 6.956595182418823\n",
      "\n",
      " Cycle 74 23\n",
      "Took to collect: 8.650792360305786\n",
      "Took to train: 7.122139930725098\n",
      "\n",
      " Cycle 75 23\n",
      "Took to collect: 9.804938316345215\n",
      "Took to train: 7.002626657485962\n",
      "\n",
      " Cycle 76 23\n",
      "Took to collect: 6.2262420654296875\n",
      "Took to train: 7.099464178085327\n",
      "\n",
      " Cycle 77 23\n",
      "Took to collect: 9.107483863830566\n",
      "Took to train: 7.096984624862671\n",
      "\n",
      " Cycle 78 23\n",
      "Took to collect: 7.231496810913086\n",
      "Took to train: 6.997842788696289\n",
      "\n",
      " Cycle 79 23\n",
      "Took to collect: 8.117287635803223\n",
      "Took to train: 7.040421962738037\n",
      "\n",
      " Cycle 80 23\n",
      "Took to collect: 7.596506834030151\n",
      "Took to train: 7.071990013122559\n",
      "\n",
      " Cycle 81 23\n",
      "Took to collect: 9.143059968948364\n",
      "Took to train: 6.927082061767578\n",
      "\n",
      " Cycle 82 23\n",
      "Took to collect: 10.282222270965576\n",
      "Took to train: 7.0624895095825195\n",
      "\n",
      " Cycle 83 23\n",
      "Took to collect: 9.384242534637451\n",
      "Took to train: 6.981736898422241\n",
      "\n",
      " Cycle 84 23\n",
      "Took to collect: 8.447364330291748\n",
      "Took to train: 6.99892258644104\n",
      "\n",
      " Cycle 85 23\n",
      "Took to collect: 7.635588884353638\n",
      "Took to train: 6.998656988143921\n",
      "\n",
      " Cycle 86 23\n",
      "Took to collect: 7.574389219284058\n",
      "Took to train: 6.399623870849609\n",
      "\n",
      " Cycle 87 23\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.410871744155884\n",
      "Took to train: 6.360414028167725\n",
      "\n",
      " Cycle 88 23\n",
      "Took to collect: 6.912690877914429\n",
      "Took to train: 6.358392953872681\n",
      "\n",
      " Cycle 89 23\n",
      "Took to collect: 8.355664014816284\n",
      "Took to train: 6.381922721862793\n",
      "\n",
      " Cycle 90 23\n",
      "Took to collect: 8.388626098632812\n",
      "Took to train: 6.352428913116455\n",
      "\n",
      " Cycle 91 23\n",
      "Took to collect: 7.751718044281006\n",
      "Took to train: 6.3441712856292725\n",
      "\n",
      " Cycle 92 23\n",
      "Took to collect: 6.817462205886841\n",
      "Took to train: 6.245166063308716\n",
      "\n",
      " Cycle 93 23\n",
      "Took to collect: 6.444364786148071\n",
      "Took to train: 6.443364381790161\n",
      "\n",
      " Cycle 94 23\n",
      "Took to collect: 8.184811353683472\n",
      "Took to train: 6.405255079269409\n",
      "\n",
      " Cycle 95 23\n",
      "Took to collect: 7.061649799346924\n",
      "Took to train: 6.239144802093506\n",
      "\n",
      " Cycle 96 23\n",
      "Took to collect: 6.6077353954315186\n",
      "Took to train: 6.288766622543335\n",
      "\n",
      " Cycle 97 23\n",
      "Took to collect: 8.277685165405273\n",
      "Took to train: 6.362403631210327\n",
      "\n",
      " Cycle 98 23\n",
      "Took to collect: 6.820952653884888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.377645015716553\n",
      "\n",
      " Cycle 99 23\n",
      "Took to collect: 4.6804540157318115\n",
      "Took to train: 6.585381269454956\n",
      "Time collect avg cycle: 7.754906687736511\n",
      "Time train avg cycle: 6.6067085194587705\n",
      "Total avg cycle: 14.37217549085617\n",
      "Ending epoch\n",
      "2020-10-26 06:57:10.201836 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 23 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.701641\n",
      "trainer/QF2 Loss                                    0.794869\n",
      "trainer/Policy Loss                                44.6962\n",
      "trainer/Q1 Predictions Mean                       -44.7721\n",
      "trainer/Q1 Predictions Std                         35.6233\n",
      "trainer/Q1 Predictions Max                          4.41709\n",
      "trainer/Q1 Predictions Min                       -105.968\n",
      "trainer/Q2 Predictions Mean                       -44.5964\n",
      "trainer/Q2 Predictions Std                         35.6662\n",
      "trainer/Q2 Predictions Max                          4.81027\n",
      "trainer/Q2 Predictions Min                       -106.054\n",
      "trainer/Q Targets Mean                            -44.8739\n",
      "trainer/Q Targets Std                              35.5905\n",
      "trainer/Q Targets Max                               4.46785\n",
      "trainer/Q Targets Min                            -106.006\n",
      "trainer/Log Pis Mean                                3.50549\n",
      "trainer/Log Pis Std                                 2.5544\n",
      "trainer/Log Pis Max                                11.3985\n",
      "trainer/Log Pis Min                                -5.33139\n",
      "trainer/policy/mean Mean                           -0.461479\n",
      "trainer/policy/mean Std                             0.608417\n",
      "trainer/policy/mean Max                             0.994167\n",
      "trainer/policy/mean Min                            -0.995598\n",
      "trainer/policy/normal/std Mean                      0.402948\n",
      "trainer/policy/normal/std Std                       0.2429\n",
      "trainer/policy/normal/std Max                       1.71083\n",
      "trainer/policy/normal/std Min                       0.0451148\n",
      "trainer/policy/normal/log_std Mean                 -1.12631\n",
      "trainer/policy/normal/log_std Std                   0.723356\n",
      "trainer/policy/normal/log_std Max                   0.536979\n",
      "trainer/policy/normal/log_std Min                  -3.09854\n",
      "trainer/Alpha                                       0.0117974\n",
      "trainer/Alpha Loss                                  2.2443\n",
      "exploration/num steps total                    241000\n",
      "exploration/num paths total                      4839\n",
      "exploration/path length Mean                       49.7512\n",
      "exploration/path length Std                         2.9503\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         9\n",
      "exploration/Rewards Mean                           -0.9996\n",
      "exploration/Rewards Std                             0.019996\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.7313\n",
      "exploration/Returns Std                             3.02189\n",
      "exploration/Returns Max                            -8\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.328372\n",
      "exploration/Actions Std                             0.62785\n",
      "exploration/Actions Max                             0.999706\n",
      "exploration/Actions Min                            -0.999987\n",
      "exploration/Num Paths                             201\n",
      "exploration/Average Returns                       -49.7313\n",
      "exploration/env_infos/final/is_success Mean         0.00497512\n",
      "exploration/env_infos/final/is_success Std          0.0703589\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0001\n",
      "exploration/env_infos/is_success Std                0.0099995\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      11890\n",
      "evaluation/num paths total                        241\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.32786\n",
      "evaluation/Actions Std                              0.60172\n",
      "evaluation/Actions Max                              0.976156\n",
      "evaluation/Actions Min                             -0.987781\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               1.03086\n",
      "time/evaluation sampling (s)                       44.5867\n",
      "time/exploration sampling (s)                     775.51\n",
      "time/logging (s)                                    0.027554\n",
      "time/sac training (s)                             207.276\n",
      "time/saving (s)                                     0.0139883\n",
      "time/training (s)                                   0.0072588\n",
      "time/epoch (s)                                   1028.45\n",
      "time/total (s)                                  33502.5\n",
      "Epoch                                              23\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 24\n",
      "\n",
      " Cycle 0 24\n",
      "Took to collect: 6.149813413619995\n",
      "Took to train: 6.442811965942383\n",
      "\n",
      " Cycle 1 24\n",
      "Took to collect: 6.718575716018677\n",
      "Took to train: 6.449995040893555\n",
      "\n",
      " Cycle 2 24\n",
      "Took to collect: 7.964174747467041\n",
      "Took to train: 6.399798154830933\n",
      "\n",
      " Cycle 3 24\n",
      "Took to collect: 6.283048868179321\n",
      "Took to train: 6.3135786056518555\n",
      "\n",
      " Cycle 4 24\n",
      "Took to collect: 6.106838226318359\n",
      "Took to train: 6.461331129074097\n",
      "\n",
      " Cycle 5 24\n",
      "Took to collect: 8.564683675765991\n",
      "Took to train: 6.380706310272217\n",
      "\n",
      " Cycle 6 24\n",
      "Took to collect: 5.0053980350494385\n",
      "Took to train: 6.263824939727783\n",
      "\n",
      " Cycle 7 24\n",
      "Took to collect: 8.802167892456055\n",
      "Took to train: 6.264901876449585\n",
      "\n",
      " Cycle 8 24\n",
      "Took to collect: 5.572741508483887\n",
      "Took to train: 6.396821975708008\n",
      "\n",
      " Cycle 9 24\n",
      "Took to collect: 6.503051519393921\n",
      "Took to train: 6.378475904464722\n",
      "\n",
      " Cycle 10 24\n",
      "Took to collect: 6.105487823486328\n",
      "Took to train: 6.342855215072632\n",
      "\n",
      " Cycle 11 24\n",
      "Took to collect: 6.499735116958618\n",
      "Took to train: 6.280506372451782\n",
      "\n",
      " Cycle 12 24\n",
      "Took to collect: 8.233055830001831\n",
      "Took to train: 6.2740960121154785\n",
      "\n",
      " Cycle 13 24\n",
      "Took to collect: 6.7610204219818115\n",
      "Took to train: 6.251833200454712\n",
      "\n",
      " Cycle 14 24\n",
      "Took to collect: 8.722022294998169\n",
      "Took to train: 6.34927225112915\n",
      "\n",
      " Cycle 15 24\n",
      "Took to collect: 5.7218711376190186\n",
      "Took to train: 6.257540702819824\n",
      "\n",
      " Cycle 16 24\n",
      "Took to collect: 5.0108888149261475\n",
      "Took to train: 6.281647682189941\n",
      "\n",
      " Cycle 17 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 6.283668756484985\n",
      "Took to train: 6.301550388336182\n",
      "\n",
      " Cycle 18 24\n",
      "Took to collect: 8.189974308013916\n",
      "Took to train: 6.2744059562683105\n",
      "\n",
      " Cycle 19 24\n",
      "Took to collect: 6.399562120437622\n",
      "Took to train: 6.349358558654785\n",
      "\n",
      " Cycle 20 24\n",
      "Took to collect: 7.517413139343262\n",
      "Took to train: 6.419907331466675\n",
      "\n",
      " Cycle 21 24\n",
      "Took to collect: 7.323500633239746\n",
      "Took to train: 6.363654136657715\n",
      "\n",
      " Cycle 22 24\n",
      "Took to collect: 10.355395317077637\n",
      "Took to train: 6.266920804977417\n",
      "\n",
      " Cycle 23 24\n",
      "Took to collect: 7.1460230350494385\n",
      "Took to train: 6.4001123905181885\n",
      "\n",
      " Cycle 24 24\n",
      "Took to collect: 8.879082679748535\n",
      "Took to train: 6.457708358764648\n",
      "\n",
      " Cycle 25 24\n",
      "Took to collect: 6.534735679626465\n",
      "Took to train: 6.435291051864624\n",
      "\n",
      " Cycle 26 24\n",
      "Took to collect: 8.327135801315308\n",
      "Took to train: 6.469274997711182\n",
      "\n",
      " Cycle 27 24\n",
      "Took to collect: 7.557042598724365\n",
      "Took to train: 6.473151922225952\n",
      "\n",
      " Cycle 28 24\n",
      "Took to collect: 6.749902963638306\n",
      "Took to train: 6.450872421264648\n",
      "\n",
      " Cycle 29 24\n",
      "Took to collect: 9.788885831832886\n",
      "Took to train: 6.397021770477295\n",
      "\n",
      " Cycle 30 24\n",
      "Took to collect: 5.260098934173584\n",
      "Took to train: 6.433657646179199\n",
      "\n",
      " Cycle 31 24\n",
      "Took to collect: 8.439191341400146\n",
      "Took to train: 6.423574924468994\n",
      "\n",
      " Cycle 32 24\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.997847557067871\n",
      "Took to train: 6.450032949447632\n",
      "\n",
      " Cycle 33 24\n",
      "Took to collect: 6.5179243087768555\n",
      "Took to train: 6.43629789352417\n",
      "\n",
      " Cycle 34 24\n",
      "Took to collect: 8.014580011367798\n",
      "Took to train: 6.471910715103149\n",
      "\n",
      " Cycle 35 24\n",
      "Took to collect: 6.732736825942993\n",
      "Took to train: 6.476873874664307\n",
      "\n",
      " Cycle 36 24\n",
      "Took to collect: 6.345054626464844\n",
      "Took to train: 6.474665641784668\n",
      "\n",
      " Cycle 37 24\n",
      "Took to collect: 6.292740821838379\n",
      "Took to train: 6.461449384689331\n",
      "\n",
      " Cycle 38 24\n",
      "Took to collect: 7.152976751327515\n",
      "Took to train: 6.4361066818237305\n",
      "\n",
      " Cycle 39 24\n",
      "Took to collect: 8.467087030410767\n",
      "Took to train: 6.382012605667114\n",
      "\n",
      " Cycle 40 24\n",
      "Took to collect: 8.246229887008667\n",
      "Took to train: 6.371425628662109\n",
      "\n",
      " Cycle 41 24\n",
      "Took to collect: 6.857403755187988\n",
      "Took to train: 6.368146896362305\n",
      "\n",
      " Cycle 42 24\n",
      "Took to collect: 7.290331602096558\n",
      "Took to train: 6.36867880821228\n",
      "\n",
      " Cycle 43 24\n",
      "Took to collect: 9.612350463867188\n",
      "Took to train: 6.2470598220825195\n",
      "\n",
      " Cycle 44 24\n",
      "Took to collect: 9.371556282043457\n",
      "Took to train: 6.242821216583252\n",
      "\n",
      " Cycle 45 24\n",
      "Took to collect: 7.25961971282959\n",
      "Took to train: 6.371466398239136\n",
      "\n",
      " Cycle 46 24\n",
      "Took to collect: 5.624277830123901\n",
      "Took to train: 6.382056951522827\n",
      "\n",
      " Cycle 47 24\n",
      "Took to collect: 6.275832891464233\n",
      "Took to train: 6.383957386016846\n",
      "\n",
      " Cycle 48 24\n",
      "Took to collect: 6.339942693710327\n",
      "Took to train: 6.4214630126953125\n",
      "\n",
      " Cycle 49 24\n",
      "Took to collect: 6.414494037628174\n",
      "Took to train: 6.4672698974609375\n",
      "\n",
      " Cycle 50 24\n",
      "Took to collect: 7.10885763168335\n",
      "Took to train: 6.46197247505188\n",
      "\n",
      " Cycle 51 24\n",
      "Took to collect: 7.900959730148315\n",
      "Took to train: 6.469961166381836\n",
      "\n",
      " Cycle 52 24\n",
      "Took to collect: 6.23002552986145\n",
      "Took to train: 6.448551654815674\n",
      "\n",
      " Cycle 53 24\n",
      "Took to collect: 6.580042600631714\n",
      "Took to train: 6.438732862472534\n",
      "\n",
      " Cycle 54 24\n",
      "Took to collect: 8.505385160446167\n",
      "Took to train: 6.463797569274902\n",
      "\n",
      " Cycle 55 24\n",
      "Took to collect: 7.602534770965576\n",
      "Took to train: 6.461969614028931\n",
      "\n",
      " Cycle 56 24\n",
      "Took to collect: 7.194917678833008\n",
      "Took to train: 6.444416522979736\n",
      "\n",
      " Cycle 57 24\n",
      "Took to collect: 7.501543045043945\n",
      "Took to train: 6.463992595672607\n",
      "\n",
      " Cycle 58 24\n",
      "Took to collect: 7.214385747909546\n",
      "Took to train: 6.485127925872803\n",
      "\n",
      " Cycle 59 24\n",
      "Took to collect: 8.020199060440063\n",
      "Took to train: 6.5522847175598145\n",
      "\n",
      " Cycle 60 24\n",
      "Took to collect: 5.977581262588501\n",
      "Took to train: 6.473273515701294\n",
      "\n",
      " Cycle 61 24\n",
      "Took to collect: 8.35207748413086\n",
      "Took to train: 6.365824460983276\n",
      "\n",
      " Cycle 62 24\n",
      "Took to collect: 8.260915994644165\n",
      "Took to train: 6.437111854553223\n",
      "\n",
      " Cycle 63 24\n",
      "Took to collect: 6.9644694328308105\n",
      "Took to train: 6.426676511764526\n",
      "\n",
      " Cycle 64 24\n",
      "Took to collect: 6.880836486816406\n",
      "Took to train: 6.414947986602783\n",
      "\n",
      " Cycle 65 24\n",
      "Took to collect: 7.840609550476074\n",
      "Took to train: 6.394771337509155\n",
      "\n",
      " Cycle 66 24\n",
      "Took to collect: 9.80808424949646\n",
      "Took to train: 6.385488510131836\n",
      "\n",
      " Cycle 67 24\n",
      "Took to collect: 8.503142595291138\n",
      "Took to train: 6.445544242858887\n",
      "\n",
      " Cycle 68 24\n",
      "Took to collect: 7.595683813095093\n",
      "Took to train: 6.39137077331543\n",
      "\n",
      " Cycle 69 24\n",
      "Took to collect: 7.733536720275879\n",
      "Took to train: 6.419651508331299\n",
      "\n",
      " Cycle 70 24\n",
      "Took to collect: 7.638871431350708\n",
      "Took to train: 6.435078382492065\n",
      "\n",
      " Cycle 71 24\n",
      "Took to collect: 7.669088125228882\n",
      "Took to train: 6.514649391174316\n",
      "\n",
      " Cycle 72 24\n",
      "Took to collect: 8.429599285125732\n",
      "Took to train: 6.366390228271484\n",
      "\n",
      " Cycle 73 24\n",
      "Took to collect: 7.941828727722168\n",
      "Took to train: 6.405163526535034\n",
      "\n",
      " Cycle 74 24\n",
      "Took to collect: 8.1390860080719\n",
      "Took to train: 6.500359296798706\n",
      "\n",
      " Cycle 75 24\n",
      "Took to collect: 7.3571178913116455\n",
      "Took to train: 6.415902853012085\n",
      "\n",
      " Cycle 76 24\n",
      "Took to collect: 8.509580135345459\n",
      "Took to train: 6.457833766937256\n",
      "\n",
      " Cycle 77 24\n",
      "Took to collect: 8.893452644348145\n",
      "Took to train: 6.459009408950806\n",
      "\n",
      " Cycle 78 24\n",
      "Took to collect: 7.205185651779175\n",
      "Took to train: 6.446282386779785\n",
      "\n",
      " Cycle 79 24\n",
      "Took to collect: 6.769840717315674\n",
      "Took to train: 6.4636125564575195\n",
      "\n",
      " Cycle 80 24\n",
      "Took to collect: 7.200433969497681\n",
      "Took to train: 6.447808504104614\n",
      "\n",
      " Cycle 81 24\n",
      "Took to collect: 7.7156922817230225\n",
      "Took to train: 6.4380857944488525\n",
      "\n",
      " Cycle 82 24\n",
      "Took to collect: 7.775129318237305\n",
      "Took to train: 6.38178825378418\n",
      "\n",
      " Cycle 83 24\n",
      "Took to collect: 7.366404294967651\n",
      "Took to train: 6.363335847854614\n",
      "\n",
      " Cycle 84 24\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 6.467011451721191\n",
      "Took to train: 6.420119285583496\n",
      "\n",
      " Cycle 85 24\n",
      "Took to collect: 8.139362812042236\n",
      "Took to train: 6.433750867843628\n",
      "\n",
      " Cycle 86 24\n",
      "Took to collect: 10.33123254776001\n",
      "Took to train: 6.4337427616119385\n",
      "\n",
      " Cycle 87 24\n",
      "Took to collect: 9.10986328125\n",
      "Took to train: 6.450472116470337\n",
      "\n",
      " Cycle 88 24\n",
      "Took to collect: 8.062259912490845\n",
      "Took to train: 6.456689119338989\n",
      "\n",
      " Cycle 89 24\n",
      "Took to collect: 7.035839796066284\n",
      "Took to train: 6.415220022201538\n",
      "\n",
      " Cycle 90 24\n",
      "Took to collect: 6.555840492248535\n",
      "Took to train: 6.431018352508545\n",
      "\n",
      " Cycle 91 24\n",
      "Took to collect: 7.148380517959595\n",
      "Took to train: 6.435443878173828\n",
      "\n",
      " Cycle 92 24\n",
      "Took to collect: 7.808114528656006\n",
      "Took to train: 6.298887729644775\n",
      "\n",
      " Cycle 93 24\n",
      "Took to collect: 7.6530921459198\n",
      "Took to train: 6.2899980545043945\n",
      "\n",
      " Cycle 94 24\n",
      "Took to collect: 7.4456987380981445\n",
      "Took to train: 6.2524733543396\n",
      "\n",
      " Cycle 95 24\n",
      "Took to collect: 8.539088249206543\n",
      "Took to train: 6.400062084197998\n",
      "\n",
      " Cycle 96 24\n",
      "Took to collect: 7.778100967407227\n",
      "Took to train: 6.445358753204346\n",
      "\n",
      " Cycle 97 24\n",
      "Took to collect: 8.637974739074707\n",
      "Took to train: 6.582021713256836\n",
      "\n",
      " Cycle 98 24\n",
      "Took to collect: 9.364288091659546\n",
      "Took to train: 6.59992241859436\n",
      "\n",
      " Cycle 99 24\n",
      "Took to collect: 6.566756248474121\n",
      "Took to train: 6.662211894989014\n",
      "Time collect avg cycle: 7.473191788196564\n",
      "Time train avg cycle: 6.408683161735535\n",
      "Total avg cycle: 13.891777713298797\n",
      "Ending epoch\n",
      "2020-10-26 07:20:47.102090 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 24 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.743788\n",
      "trainer/QF2 Loss                                    0.578859\n",
      "trainer/Policy Loss                                48.5919\n",
      "trainer/Q1 Predictions Mean                       -48.4718\n",
      "trainer/Q1 Predictions Std                         36.627\n",
      "trainer/Q1 Predictions Max                         10.1052\n",
      "trainer/Q1 Predictions Min                       -106.273\n",
      "trainer/Q2 Predictions Mean                       -48.6722\n",
      "trainer/Q2 Predictions Std                         36.5973\n",
      "trainer/Q2 Predictions Max                         10.4711\n",
      "trainer/Q2 Predictions Min                       -106.389\n",
      "trainer/Q Targets Mean                            -48.9918\n",
      "trainer/Q Targets Std                              36.5193\n",
      "trainer/Q Targets Max                               9.42312\n",
      "trainer/Q Targets Min                            -106.589\n",
      "trainer/Log Pis Mean                                3.04725\n",
      "trainer/Log Pis Std                                 2.50769\n",
      "trainer/Log Pis Max                                11.9419\n",
      "trainer/Log Pis Min                                -3.41266\n",
      "trainer/policy/mean Mean                           -0.327715\n",
      "trainer/policy/mean Std                             0.673216\n",
      "trainer/policy/mean Max                             0.993004\n",
      "trainer/policy/mean Min                            -0.996224\n",
      "trainer/policy/normal/std Mean                      0.410078\n",
      "trainer/policy/normal/std Std                       0.199788\n",
      "trainer/policy/normal/std Max                       1.4306\n",
      "trainer/policy/normal/std Min                       0.0398466\n",
      "trainer/policy/normal/log_std Mean                 -1.04973\n",
      "trainer/policy/normal/log_std Std                   0.629478\n",
      "trainer/policy/normal/log_std Max                   0.358091\n",
      "trainer/policy/normal/log_std Min                  -3.22272\n",
      "trainer/Alpha                                       0.0109659\n",
      "trainer/Alpha Loss                                  0.21325\n",
      "exploration/num steps total                    251000\n",
      "exploration/num paths total                      5041\n",
      "exploration/path length Mean                       49.505\n",
      "exploration/path length Std                         4.01143\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         9\n",
      "exploration/Rewards Mean                           -0.9998\n",
      "exploration/Rewards Std                             0.0141407\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.495\n",
      "exploration/Returns Std                             4.10656\n",
      "exploration/Returns Max                            -8\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.326102\n",
      "exploration/Actions Std                             0.612479\n",
      "exploration/Actions Max                             0.999703\n",
      "exploration/Actions Min                            -0.99985\n",
      "exploration/Num Paths                             202\n",
      "exploration/Average Returns                       -49.495\n",
      "exploration/env_infos/final/is_success Mean         0.00990099\n",
      "exploration/env_infos/final/is_success Std          0.0990099\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0002\n",
      "exploration/env_infos/is_success Std                0.0141407\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      12390\n",
      "evaluation/num paths total                        251\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.294888\n",
      "evaluation/Actions Std                              0.614796\n",
      "evaluation/Actions Max                              0.969891\n",
      "evaluation/Actions Min                             -0.982559\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.964746\n",
      "time/evaluation sampling (s)                       27.6588\n",
      "time/exploration sampling (s)                     747.339\n",
      "time/logging (s)                                    0.0349096\n",
      "time/sac training (s)                             199.394\n",
      "time/saving (s)                                     0.0141363\n",
      "time/training (s)                                   0.00699689\n",
      "time/epoch (s)                                    975.412\n",
      "time/total (s)                                  34919.2\n",
      "Epoch                                              24\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 25\n",
      "\n",
      " Cycle 0 25\n",
      "Took to collect: 8.779018878936768\n",
      "Took to train: 6.32904314994812\n",
      "\n",
      " Cycle 1 25\n",
      "Took to collect: 9.377351760864258\n",
      "Took to train: 6.2836949825286865\n",
      "\n",
      " Cycle 2 25\n",
      "Took to collect: 7.395514249801636\n",
      "Took to train: 6.296569347381592\n",
      "\n",
      " Cycle 3 25\n",
      "Took to collect: 8.59938097000122\n",
      "Took to train: 6.458070755004883\n",
      "\n",
      " Cycle 4 25\n",
      "Took to collect: 8.043916940689087\n",
      "Took to train: 6.425026893615723\n",
      "\n",
      " Cycle 5 25\n",
      "Took to collect: 8.559100151062012\n",
      "Took to train: 6.379774570465088\n",
      "\n",
      " Cycle 6 25\n",
      "Took to collect: 10.709076881408691\n",
      "Took to train: 6.377202272415161\n",
      "\n",
      " Cycle 7 25\n",
      "Took to collect: 6.875360012054443\n",
      "Took to train: 6.3767921924591064\n",
      "\n",
      " Cycle 8 25\n",
      "Took to collect: 8.549175500869751\n",
      "Took to train: 6.35757851600647\n",
      "\n",
      " Cycle 9 25\n",
      "Took to collect: 9.550841093063354\n",
      "Took to train: 6.408669710159302\n",
      "\n",
      " Cycle 10 25\n",
      "Took to collect: 6.901610612869263\n",
      "Took to train: 6.373686075210571\n",
      "\n",
      " Cycle 11 25\n",
      "Took to collect: 8.17647647857666\n",
      "Took to train: 6.2648749351501465\n",
      "\n",
      " Cycle 12 25\n",
      "Took to collect: 6.377591609954834\n",
      "Took to train: 6.254355430603027\n",
      "\n",
      " Cycle 13 25\n",
      "Took to collect: 7.400737285614014\n",
      "Took to train: 6.268611431121826\n",
      "\n",
      " Cycle 14 25\n",
      "Took to collect: 10.08959698677063\n",
      "Took to train: 6.2653889656066895\n",
      "\n",
      " Cycle 15 25\n",
      "Took to collect: 6.53649115562439\n",
      "Took to train: 6.253852844238281\n",
      "\n",
      " Cycle 16 25\n",
      "Took to collect: 6.6532933712005615\n",
      "Took to train: 6.245944261550903\n",
      "\n",
      " Cycle 17 25\n",
      "Took to collect: 7.946988821029663\n",
      "Took to train: 6.3615007400512695\n",
      "\n",
      " Cycle 18 25\n",
      "Took to collect: 7.957876205444336\n",
      "Took to train: 6.3769752979278564\n",
      "\n",
      " Cycle 19 25\n",
      "Took to collect: 8.21500039100647\n",
      "Took to train: 6.426879644393921\n",
      "\n",
      " Cycle 20 25\n",
      "Took to collect: 6.430124759674072\n",
      "Took to train: 6.478905916213989\n",
      "\n",
      " Cycle 21 25\n",
      "Took to collect: 7.24864935874939\n",
      "Took to train: 6.4783477783203125\n",
      "\n",
      " Cycle 22 25\n",
      "Took to collect: 6.707388877868652\n",
      "Took to train: 6.45500636100769\n",
      "\n",
      " Cycle 23 25\n",
      "Took to collect: 6.627026081085205\n",
      "Took to train: 6.45929479598999\n",
      "\n",
      " Cycle 24 25\n",
      "Took to collect: 7.620805740356445\n",
      "Took to train: 6.444410085678101\n",
      "\n",
      " Cycle 25 25\n",
      "Took to collect: 6.9120166301727295\n",
      "Took to train: 6.447502136230469\n",
      "\n",
      " Cycle 26 25\n",
      "Took to collect: 7.5111775398254395\n",
      "Took to train: 6.421562910079956\n",
      "\n",
      " Cycle 27 25\n",
      "Took to collect: 9.255336284637451\n",
      "Took to train: 6.408898830413818\n",
      "\n",
      " Cycle 28 25\n",
      "Took to collect: 8.277235984802246\n",
      "Took to train: 6.418266296386719\n",
      "\n",
      " Cycle 29 25\n",
      "Took to collect: 8.203264951705933\n",
      "Took to train: 6.438645601272583\n",
      "\n",
      " Cycle 30 25\n",
      "Took to collect: 8.399647951126099\n",
      "Took to train: 6.447503566741943\n",
      "\n",
      " Cycle 31 25\n",
      "Took to collect: 8.801403045654297\n",
      "Took to train: 6.432819604873657\n",
      "\n",
      " Cycle 32 25\n",
      "Took to collect: 7.360859155654907\n",
      "Took to train: 6.436017036437988\n",
      "\n",
      " Cycle 33 25\n",
      "Took to collect: 9.359878778457642\n",
      "Took to train: 6.396266222000122\n",
      "\n",
      " Cycle 34 25\n",
      "Took to collect: 6.677595615386963\n",
      "Took to train: 6.379070281982422\n",
      "\n",
      " Cycle 35 25\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 6.955726861953735\n",
      "Took to train: 6.3277342319488525\n",
      "\n",
      " Cycle 36 25\n",
      "Took to collect: 7.563865423202515\n",
      "Took to train: 6.2909417152404785\n",
      "\n",
      " Cycle 37 25\n",
      "Took to collect: 9.383336067199707\n",
      "Took to train: 6.502345323562622\n",
      "\n",
      " Cycle 38 25\n",
      "Took to collect: 6.718907117843628\n",
      "Took to train: 6.506839752197266\n",
      "\n",
      " Cycle 39 25\n",
      "Took to collect: 9.242198705673218\n",
      "Took to train: 6.407012701034546\n",
      "\n",
      " Cycle 40 25\n",
      "Took to collect: 8.580416440963745\n",
      "Took to train: 6.434771776199341\n",
      "\n",
      " Cycle 41 25\n",
      "Took to collect: 8.285143613815308\n",
      "Took to train: 6.317532539367676\n",
      "\n",
      " Cycle 42 25\n",
      "Took to collect: 7.407283782958984\n",
      "Took to train: 6.328725337982178\n",
      "\n",
      " Cycle 43 25\n",
      "Took to collect: 7.052944898605347\n",
      "Took to train: 6.333015203475952\n",
      "\n",
      " Cycle 44 25\n",
      "Took to collect: 5.857952833175659\n",
      "Took to train: 6.315064191818237\n",
      "\n",
      " Cycle 45 25\n",
      "Took to collect: 8.889240741729736\n",
      "Took to train: 6.313755750656128\n",
      "\n",
      " Cycle 46 25\n",
      "Took to collect: 8.768521070480347\n",
      "Took to train: 6.319006443023682\n",
      "\n",
      " Cycle 47 25\n",
      "Took to collect: 7.938175201416016\n",
      "Took to train: 6.500093460083008\n",
      "\n",
      " Cycle 48 25\n",
      "Took to collect: 6.962584495544434\n",
      "Took to train: 6.435673952102661\n",
      "\n",
      " Cycle 49 25\n",
      "Took to collect: 7.908010005950928\n",
      "Took to train: 6.501748323440552\n",
      "\n",
      " Cycle 50 25\n",
      "Took to collect: 6.779847621917725\n",
      "Took to train: 6.522534370422363\n",
      "\n",
      " Cycle 51 25\n",
      "Took to collect: 5.856572389602661\n",
      "Took to train: 6.519246339797974\n",
      "\n",
      " Cycle 52 25\n",
      "Took to collect: 8.768136739730835\n",
      "Took to train: 6.384980201721191\n",
      "\n",
      " Cycle 53 25\n",
      "Took to collect: 7.366076707839966\n",
      "Took to train: 6.38324499130249\n",
      "\n",
      " Cycle 54 25\n",
      "Took to collect: 6.176399230957031\n",
      "Took to train: 6.3943493366241455\n",
      "\n",
      " Cycle 55 25\n",
      "Took to collect: 8.982900142669678\n",
      "Took to train: 6.387194395065308\n",
      "\n",
      " Cycle 56 25\n",
      "Took to collect: 5.77737832069397\n",
      "Took to train: 6.327227354049683\n",
      "\n",
      " Cycle 57 25\n",
      "Took to collect: 6.0710389614105225\n",
      "Took to train: 6.326652526855469\n",
      "\n",
      " Cycle 58 25\n",
      "Took to collect: 5.69327449798584\n",
      "Took to train: 6.377650499343872\n",
      "\n",
      " Cycle 59 25\n",
      "Took to collect: 9.502699851989746\n",
      "Took to train: 6.490102529525757\n",
      "\n",
      " Cycle 60 25\n",
      "Took to collect: 9.101882934570312\n",
      "Took to train: 6.388634443283081\n",
      "\n",
      " Cycle 61 25\n",
      "Took to collect: 8.719268321990967\n",
      "Took to train: 6.382759094238281\n",
      "\n",
      " Cycle 62 25\n",
      "Took to collect: 7.391433238983154\n",
      "Took to train: 6.437207937240601\n",
      "\n",
      " Cycle 63 25\n",
      "Took to collect: 5.975870609283447\n",
      "Took to train: 6.415733337402344\n",
      "\n",
      " Cycle 64 25\n",
      "Took to collect: 10.019376754760742\n",
      "Took to train: 6.510507822036743\n",
      "\n",
      " Cycle 65 25\n",
      "Took to collect: 7.340657472610474\n",
      "Took to train: 6.463830232620239\n",
      "\n",
      " Cycle 66 25\n",
      "Took to collect: 8.838794946670532\n",
      "Took to train: 6.459449052810669\n",
      "\n",
      " Cycle 67 25\n",
      "Took to collect: 5.9721386432647705\n",
      "Took to train: 6.455129384994507\n",
      "\n",
      " Cycle 68 25\n",
      "Took to collect: 8.52985692024231\n",
      "Took to train: 6.436914682388306\n",
      "\n",
      " Cycle 69 25\n",
      "Took to collect: 9.719139337539673\n",
      "Took to train: 6.474081039428711\n",
      "\n",
      " Cycle 70 25\n",
      "Took to collect: 10.459598064422607\n",
      "Took to train: 6.31905460357666\n",
      "\n",
      " Cycle 71 25\n",
      "Took to collect: 6.970826864242554\n",
      "Took to train: 6.28114128112793\n",
      "\n",
      " Cycle 72 25\n",
      "Took to collect: 7.435445070266724\n",
      "Took to train: 6.316687107086182\n",
      "\n",
      " Cycle 73 25\n",
      "Took to collect: 5.61143684387207\n",
      "Took to train: 6.394221305847168\n",
      "\n",
      " Cycle 74 25\n",
      "Took to collect: 7.099582195281982\n",
      "Took to train: 6.401228904724121\n",
      "\n",
      " Cycle 75 25\n",
      "Took to collect: 7.694618463516235\n",
      "Took to train: 6.387170314788818\n",
      "\n",
      " Cycle 76 25\n",
      "Took to collect: 7.267827987670898\n",
      "Took to train: 6.3349714279174805\n",
      "\n",
      " Cycle 77 25\n",
      "Took to collect: 5.740660667419434\n",
      "Took to train: 6.3553173542022705\n",
      "\n",
      " Cycle 78 25\n",
      "Took to collect: 5.36778998374939\n",
      "Took to train: 6.425136566162109\n",
      "\n",
      " Cycle 79 25\n",
      "Took to collect: 8.638977289199829\n",
      "Took to train: 6.346110582351685\n",
      "\n",
      " Cycle 80 25\n",
      "Took to collect: 6.508658170700073\n",
      "Took to train: 6.291509628295898\n",
      "\n",
      " Cycle 81 25\n",
      "Took to collect: 5.337836027145386\n",
      "Took to train: 6.445272445678711\n",
      "\n",
      " Cycle 82 25\n",
      "Took to collect: 7.8864641189575195\n",
      "Took to train: 6.434551954269409\n",
      "\n",
      " Cycle 83 25\n",
      "Took to collect: 5.895373106002808\n",
      "Took to train: 6.427226781845093\n",
      "\n",
      " Cycle 84 25\n",
      "Took to collect: 8.069472551345825\n",
      "Took to train: 6.452045202255249\n",
      "\n",
      " Cycle 85 25\n",
      "Took to collect: 7.924068927764893\n",
      "Took to train: 6.428695201873779\n",
      "\n",
      " Cycle 86 25\n",
      "Took to collect: 6.157958030700684\n",
      "Took to train: 6.431922912597656\n",
      "\n",
      " Cycle 87 25\n",
      "Took to collect: 7.159078121185303\n",
      "Took to train: 6.440209865570068\n",
      "\n",
      " Cycle 88 25\n",
      "Took to collect: 5.741007328033447\n",
      "Took to train: 6.365845441818237\n",
      "\n",
      " Cycle 89 25\n",
      "Took to collect: 5.6996259689331055\n",
      "Took to train: 6.357932090759277\n",
      "\n",
      " Cycle 90 25\n",
      "Took to collect: 6.243543386459351\n",
      "Took to train: 6.343951940536499\n",
      "\n",
      " Cycle 91 25\n",
      "Took to collect: 8.839783430099487\n",
      "Took to train: 6.358248710632324\n",
      "\n",
      " Cycle 92 25\n",
      "Took to collect: 6.995669603347778\n",
      "Took to train: 6.215975046157837\n",
      "\n",
      " Cycle 93 25\n",
      "Took to collect: 6.0079755783081055\n",
      "Took to train: 6.278762578964233\n",
      "\n",
      " Cycle 94 25\n",
      "Took to collect: 6.705747365951538\n",
      "Took to train: 6.221717596054077\n",
      "\n",
      " Cycle 95 25\n",
      "Took to collect: 7.4552693367004395\n",
      "Took to train: 6.30207371711731\n",
      "\n",
      " Cycle 96 25\n",
      "Took to collect: 7.706973314285278\n",
      "Took to train: 6.285694599151611\n",
      "\n",
      " Cycle 97 25\n",
      "Took to collect: 5.812186002731323\n",
      "Took to train: 6.415552377700806\n",
      "\n",
      " Cycle 98 25\n",
      "Took to collect: 9.997143268585205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.537410259246826\n",
      "\n",
      " Cycle 99 25\n",
      "Took to collect: 7.301793336868286\n",
      "Took to train: 6.646255970001221\n",
      "Time collect avg cycle: 7.599162514209747\n",
      "Time train avg cycle: 6.389405934810639\n",
      "Total avg cycle: 13.998581204414368\n",
      "Ending epoch\n",
      "2020-10-26 07:44:48.456432 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 25 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.657318\n",
      "trainer/QF2 Loss                                    0.589652\n",
      "trainer/Policy Loss                                50.1194\n",
      "trainer/Q1 Predictions Mean                       -50.1275\n",
      "trainer/Q1 Predictions Std                         35.6772\n",
      "trainer/Q1 Predictions Max                          5.65963\n",
      "trainer/Q1 Predictions Min                       -106.437\n",
      "trainer/Q2 Predictions Mean                       -50.2524\n",
      "trainer/Q2 Predictions Std                         35.6393\n",
      "trainer/Q2 Predictions Max                          5.47662\n",
      "trainer/Q2 Predictions Min                       -106.388\n",
      "trainer/Q Targets Mean                            -50.0822\n",
      "trainer/Q Targets Std                              35.8097\n",
      "trainer/Q Targets Max                               5.56143\n",
      "trainer/Q Targets Min                            -106.405\n",
      "trainer/Log Pis Mean                                2.98296\n",
      "trainer/Log Pis Std                                 2.46982\n",
      "trainer/Log Pis Max                                 9.66404\n",
      "trainer/Log Pis Min                                -3.87645\n",
      "trainer/policy/mean Mean                           -0.369378\n",
      "trainer/policy/mean Std                             0.645273\n",
      "trainer/policy/mean Max                             0.99413\n",
      "trainer/policy/mean Min                            -0.996206\n",
      "trainer/policy/normal/std Mean                      0.41875\n",
      "trainer/policy/normal/std Std                       0.23336\n",
      "trainer/policy/normal/std Max                       1.904\n",
      "trainer/policy/normal/std Min                       0.0431765\n",
      "trainer/policy/normal/log_std Mean                 -1.05986\n",
      "trainer/policy/normal/log_std Std                   0.676674\n",
      "trainer/policy/normal/log_std Max                   0.643959\n",
      "trainer/policy/normal/log_std Min                  -3.14246\n",
      "trainer/Alpha                                       0.0107711\n",
      "trainer/Alpha Loss                                 -0.0772135\n",
      "exploration/num steps total                    261000\n",
      "exploration/num paths total                      5242\n",
      "exploration/path length Mean                       49.7512\n",
      "exploration/path length Std                         2.75497\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        13\n",
      "exploration/Rewards Mean                           -0.9999\n",
      "exploration/Rewards Std                             0.0099995\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.7463\n",
      "exploration/Returns Std                             2.82144\n",
      "exploration/Returns Max                           -12\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.386798\n",
      "exploration/Actions Std                             0.610951\n",
      "exploration/Actions Max                             0.999514\n",
      "exploration/Actions Min                            -0.999742\n",
      "exploration/Num Paths                             201\n",
      "exploration/Average Returns                       -49.7463\n",
      "exploration/env_infos/final/is_success Mean         0.00497512\n",
      "exploration/env_infos/final/is_success Std          0.0703589\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0001\n",
      "exploration/env_infos/is_success Std                0.0099995\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      12890\n",
      "evaluation/num paths total                        261\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.405542\n",
      "evaluation/Actions Std                              0.486782\n",
      "evaluation/Actions Max                              0.972526\n",
      "evaluation/Actions Min                             -0.98526\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.975435\n",
      "time/evaluation sampling (s)                       41.4258\n",
      "time/exploration sampling (s)                     759.936\n",
      "time/logging (s)                                    0.0270717\n",
      "time/sac training (s)                             199.071\n",
      "time/saving (s)                                     0.0142665\n",
      "time/training (s)                                   0.00701353\n",
      "time/epoch (s)                                   1001.46\n",
      "time/total (s)                                  36360.4\n",
      "Epoch                                              25\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 26\n",
      "\n",
      " Cycle 0 26\n",
      "Took to collect: 6.451687574386597\n",
      "Took to train: 6.338268280029297\n",
      "\n",
      " Cycle 1 26\n",
      "Took to collect: 6.5718770027160645\n",
      "Took to train: 6.35428261756897\n",
      "\n",
      " Cycle 2 26\n",
      "Took to collect: 8.328681945800781\n",
      "Took to train: 6.2673020362854\n",
      "\n",
      " Cycle 3 26\n",
      "Took to collect: 7.472306728363037\n",
      "Took to train: 6.26693320274353\n",
      "\n",
      " Cycle 4 26\n",
      "Took to collect: 8.465164184570312\n",
      "Took to train: 6.269862174987793\n",
      "\n",
      " Cycle 5 26\n",
      "Took to collect: 4.501111745834351\n",
      "Took to train: 6.250337839126587\n",
      "\n",
      " Cycle 6 26\n",
      "Took to collect: 8.631367444992065\n",
      "Took to train: 6.279174566268921\n",
      "\n",
      " Cycle 7 26\n",
      "Took to collect: 7.59539532661438\n",
      "Took to train: 6.3650221824646\n",
      "\n",
      " Cycle 8 26\n",
      "Took to collect: 8.030167579650879\n",
      "Took to train: 6.2621917724609375\n",
      "\n",
      " Cycle 9 26\n",
      "Took to collect: 7.1415181159973145\n",
      "Took to train: 6.2928619384765625\n",
      "\n",
      " Cycle 10 26\n",
      "Took to collect: 4.977477788925171\n",
      "Took to train: 6.383029937744141\n",
      "\n",
      " Cycle 11 26\n",
      "Took to collect: 5.961007356643677\n",
      "Took to train: 6.4108216762542725\n",
      "\n",
      " Cycle 12 26\n",
      "Took to collect: 5.644863128662109\n",
      "Took to train: 6.433856010437012\n",
      "\n",
      " Cycle 13 26\n",
      "Took to collect: 7.73545503616333\n",
      "Took to train: 6.415597915649414\n",
      "\n",
      " Cycle 14 26\n",
      "Took to collect: 3.9234189987182617\n",
      "Took to train: 6.416579008102417\n",
      "\n",
      " Cycle 15 26\n",
      "Took to collect: 6.133448123931885\n",
      "Took to train: 6.399051904678345\n",
      "\n",
      " Cycle 16 26\n",
      "Took to collect: 7.601568937301636\n",
      "Took to train: 6.463519334793091\n",
      "\n",
      " Cycle 17 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 3.7363011837005615\n",
      "Took to train: 6.44533371925354\n",
      "\n",
      " Cycle 18 26\n",
      "Took to collect: 6.938819408416748\n",
      "Took to train: 6.375711679458618\n",
      "\n",
      " Cycle 19 26\n",
      "Took to collect: 2.704409599304199\n",
      "Took to train: 6.381256580352783\n",
      "\n",
      " Cycle 20 26\n",
      "Took to collect: 6.5012195110321045\n",
      "Took to train: 6.374129056930542\n",
      "\n",
      " Cycle 21 26\n",
      "Took to collect: 5.889787197113037\n",
      "Took to train: 6.35394287109375\n",
      "\n",
      " Cycle 22 26\n",
      "Took to collect: 5.134658098220825\n",
      "Took to train: 6.399912118911743\n",
      "\n",
      " Cycle 23 26\n",
      "Took to collect: 6.564244985580444\n",
      "Took to train: 6.445362329483032\n",
      "\n",
      " Cycle 24 26\n",
      "Took to collect: 6.27365255355835\n",
      "Took to train: 6.329755067825317\n",
      "\n",
      " Cycle 25 26\n",
      "Took to collect: 6.913243293762207\n",
      "Took to train: 6.246077537536621\n",
      "\n",
      " Cycle 26 26\n",
      "Took to collect: 4.199362754821777\n",
      "Took to train: 6.2622971534729\n",
      "\n",
      " Cycle 27 26\n",
      "Took to collect: 8.194783926010132\n",
      "Took to train: 6.372164964675903\n",
      "\n",
      " Cycle 28 26\n",
      "Took to collect: 6.075155258178711\n",
      "Took to train: 6.445628643035889\n",
      "\n",
      " Cycle 29 26\n",
      "Took to collect: 7.953239917755127\n",
      "Took to train: 6.407986879348755\n",
      "\n",
      " Cycle 30 26\n",
      "Took to collect: 8.608707666397095\n",
      "Took to train: 6.43446159362793\n",
      "\n",
      " Cycle 31 26\n",
      "Took to collect: 8.616205930709839\n",
      "Took to train: 6.490481853485107\n",
      "\n",
      " Cycle 32 26\n",
      "Took to collect: 6.469861745834351\n",
      "Took to train: 6.4751975536346436\n",
      "\n",
      " Cycle 33 26\n",
      "Took to collect: 7.9115681648254395\n",
      "Took to train: 6.339059114456177\n",
      "\n",
      " Cycle 34 26\n",
      "Took to collect: 5.910662889480591\n",
      "Took to train: 6.414781093597412\n",
      "\n",
      " Cycle 35 26\n",
      "Took to collect: 6.148648977279663\n",
      "Took to train: 6.361142158508301\n",
      "\n",
      " Cycle 36 26\n",
      "Took to collect: 6.454551935195923\n",
      "Took to train: 6.289306163787842\n",
      "\n",
      " Cycle 37 26\n",
      "Took to collect: 8.04128623008728\n",
      "Took to train: 6.286312580108643\n",
      "\n",
      " Cycle 38 26\n",
      "Took to collect: 6.268454074859619\n",
      "Took to train: 6.468496799468994\n",
      "\n",
      " Cycle 39 26\n",
      "Took to collect: 6.830378532409668\n",
      "Took to train: 6.533763408660889\n",
      "\n",
      " Cycle 40 26\n",
      "Took to collect: 5.770276308059692\n",
      "Took to train: 6.36281156539917\n",
      "\n",
      " Cycle 41 26\n",
      "Took to collect: 6.863018989562988\n",
      "Took to train: 6.3379106521606445\n",
      "\n",
      " Cycle 42 26\n",
      "Took to collect: 7.951258182525635\n",
      "Took to train: 6.48329496383667\n",
      "\n",
      " Cycle 43 26\n",
      "Took to collect: 9.187815189361572\n",
      "Took to train: 6.433158874511719\n",
      "\n",
      " Cycle 44 26\n",
      "Took to collect: 6.6625306606292725\n",
      "Took to train: 6.402967691421509\n",
      "\n",
      " Cycle 45 26\n",
      "Took to collect: 7.264434814453125\n",
      "Took to train: 6.900506019592285\n",
      "\n",
      " Cycle 46 26\n",
      "Took to collect: 8.713104248046875\n",
      "Took to train: 6.554685354232788\n",
      "\n",
      " Cycle 47 26\n",
      "Took to collect: 9.22515869140625\n",
      "Took to train: 6.529420375823975\n",
      "\n",
      " Cycle 48 26\n",
      "Took to collect: 6.987133026123047\n",
      "Took to train: 6.557924509048462\n",
      "\n",
      " Cycle 49 26\n",
      "Took to collect: 6.953978538513184\n",
      "Took to train: 6.54986047744751\n",
      "\n",
      " Cycle 50 26\n",
      "Took to collect: 7.716912508010864\n",
      "Took to train: 6.5268027782440186\n",
      "\n",
      " Cycle 51 26\n",
      "Took to collect: 8.841163158416748\n",
      "Took to train: 6.567744731903076\n",
      "\n",
      " Cycle 52 26\n",
      "Took to collect: 7.579780340194702\n",
      "Took to train: 6.493007183074951\n",
      "\n",
      " Cycle 53 26\n",
      "Took to collect: 7.887964248657227\n",
      "Took to train: 6.435748100280762\n",
      "\n",
      " Cycle 54 26\n",
      "Took to collect: 7.433663368225098\n",
      "Took to train: 6.5088701248168945\n",
      "\n",
      " Cycle 55 26\n",
      "Took to collect: 8.184107542037964\n",
      "Took to train: 6.52826189994812\n",
      "\n",
      " Cycle 56 26\n",
      "Took to collect: 6.964146852493286\n",
      "Took to train: 6.578582286834717\n",
      "\n",
      " Cycle 57 26\n",
      "Took to collect: 8.332053422927856\n",
      "Took to train: 6.530789613723755\n",
      "\n",
      " Cycle 58 26\n",
      "Took to collect: 7.413818836212158\n",
      "Took to train: 6.547685861587524\n",
      "\n",
      " Cycle 59 26\n",
      "Took to collect: 8.508177995681763\n",
      "Took to train: 6.535987138748169\n",
      "\n",
      " Cycle 60 26\n",
      "Took to collect: 9.905961990356445\n",
      "Took to train: 6.538350343704224\n",
      "\n",
      " Cycle 61 26\n",
      "Took to collect: 8.736838817596436\n",
      "Took to train: 6.4542741775512695\n",
      "\n",
      " Cycle 62 26\n",
      "Took to collect: 8.487775564193726\n",
      "Took to train: 6.390182256698608\n",
      "\n",
      " Cycle 63 26\n",
      "Took to collect: 10.499919891357422\n",
      "Took to train: 6.389010906219482\n",
      "\n",
      " Cycle 64 26\n",
      "Took to collect: 10.098987579345703\n",
      "Took to train: 6.444420576095581\n",
      "\n",
      " Cycle 65 26\n",
      "Took to collect: 7.391551971435547\n",
      "Took to train: 6.385399580001831\n",
      "\n",
      " Cycle 66 26\n",
      "Took to collect: 9.513086557388306\n",
      "Took to train: 6.5490148067474365\n",
      "\n",
      " Cycle 67 26\n",
      "Took to collect: 6.353858947753906\n",
      "Took to train: 6.405837059020996\n",
      "\n",
      " Cycle 68 26\n",
      "Took to collect: 6.7064149379730225\n",
      "Took to train: 6.393343210220337\n",
      "\n",
      " Cycle 69 26\n",
      "Took to collect: 8.662352800369263\n",
      "Took to train: 6.400570869445801\n",
      "\n",
      " Cycle 70 26\n",
      "Took to collect: 7.649579048156738\n",
      "Took to train: 6.3206799030303955\n",
      "\n",
      " Cycle 71 26\n",
      "Took to collect: 7.7569899559021\n",
      "Took to train: 6.469987154006958\n",
      "\n",
      " Cycle 72 26\n",
      "Took to collect: 8.369485855102539\n",
      "Took to train: 6.494804620742798\n",
      "\n",
      " Cycle 73 26\n",
      "Took to collect: 6.28629732131958\n",
      "Took to train: 6.362386703491211\n",
      "\n",
      " Cycle 74 26\n",
      "Took to collect: 5.8627307415008545\n",
      "Took to train: 6.344704627990723\n",
      "\n",
      " Cycle 75 26\n",
      "Took to collect: 7.25978946685791\n",
      "Took to train: 6.359915494918823\n",
      "\n",
      " Cycle 76 26\n",
      "Took to collect: 6.10908055305481\n",
      "Took to train: 6.364531755447388\n",
      "\n",
      " Cycle 77 26\n",
      "Took to collect: 6.572249412536621\n",
      "Took to train: 6.493668556213379\n",
      "\n",
      " Cycle 78 26\n",
      "Took to collect: 6.317516326904297\n",
      "Took to train: 6.487496614456177\n",
      "\n",
      " Cycle 79 26\n",
      "Took to collect: 7.429042339324951\n",
      "Took to train: 6.5116283893585205\n",
      "\n",
      " Cycle 80 26\n",
      "Took to collect: 7.942376613616943\n",
      "Took to train: 6.4729673862457275\n",
      "\n",
      " Cycle 81 26\n",
      "Took to collect: 7.883450746536255\n",
      "Took to train: 6.50154185295105\n",
      "\n",
      " Cycle 82 26\n",
      "Took to collect: 8.415375232696533\n",
      "Took to train: 6.453099489212036\n",
      "\n",
      " Cycle 83 26\n",
      "Took to collect: 7.588690519332886\n",
      "Took to train: 6.486541748046875\n",
      "\n",
      " Cycle 84 26\n",
      "Took to collect: 8.752089977264404\n",
      "Took to train: 6.467464923858643\n",
      "\n",
      " Cycle 85 26\n",
      "Took to collect: 8.198620557785034\n",
      "Took to train: 6.489020824432373\n",
      "\n",
      " Cycle 86 26\n",
      "Took to collect: 7.3554065227508545\n",
      "Took to train: 6.508418321609497\n",
      "\n",
      " Cycle 87 26\n",
      "Took to collect: 8.053865671157837\n",
      "Took to train: 6.350208282470703\n",
      "\n",
      " Cycle 88 26\n",
      "Took to collect: 7.517083406448364\n",
      "Took to train: 6.314764022827148\n",
      "\n",
      " Cycle 89 26\n",
      "Took to collect: 6.144954442977905\n",
      "Took to train: 6.381739139556885\n",
      "\n",
      " Cycle 90 26\n",
      "Took to collect: 6.1378865242004395\n",
      "Took to train: 6.453360557556152\n",
      "\n",
      " Cycle 91 26\n",
      "Took to collect: 5.404203653335571\n",
      "Took to train: 6.447442293167114\n",
      "\n",
      " Cycle 92 26\n",
      "Took to collect: 8.370894432067871\n",
      "Took to train: 6.3660242557525635\n",
      "\n",
      " Cycle 93 26\n",
      "Took to collect: 9.476369142532349\n",
      "Took to train: 6.436012268066406\n",
      "\n",
      " Cycle 94 26\n",
      "Took to collect: 7.603369474411011\n",
      "Took to train: 6.2971296310424805\n",
      "\n",
      " Cycle 95 26\n",
      "Took to collect: 6.776419639587402\n",
      "Took to train: 6.2851643562316895\n",
      "\n",
      " Cycle 96 26\n",
      "Took to collect: 9.625659704208374\n",
      "Took to train: 6.289865016937256\n",
      "\n",
      " Cycle 97 26\n",
      "Took to collect: 7.311925411224365\n",
      "Took to train: 6.352125644683838\n",
      "\n",
      " Cycle 98 26\n",
      "Took to collect: 8.474252700805664\n",
      "Took to train: 6.419351816177368\n",
      "\n",
      " Cycle 99 26\n",
      "Took to collect: 7.830583810806274\n",
      "Took to train: 6.659502983093262\n",
      "Time collect avg cycle: 7.287792060375214\n",
      "Time train avg cycle: 6.421592259407044\n",
      "Total avg cycle: 13.719365572929382\n",
      "Ending epoch\n",
      "2020-10-26 08:08:14.658328 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 26 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.482997\n",
      "trainer/QF2 Loss                                    0.515943\n",
      "trainer/Policy Loss                                46.2232\n",
      "trainer/Q1 Predictions Mean                       -46.2913\n",
      "trainer/Q1 Predictions Std                         36.7418\n",
      "trainer/Q1 Predictions Max                         17.4152\n",
      "trainer/Q1 Predictions Min                       -106.366\n",
      "trainer/Q2 Predictions Mean                       -46.2636\n",
      "trainer/Q2 Predictions Std                         36.7145\n",
      "trainer/Q2 Predictions Max                         17.0612\n",
      "trainer/Q2 Predictions Min                       -106.242\n",
      "trainer/Q Targets Mean                            -46.2617\n",
      "trainer/Q Targets Std                              36.7489\n",
      "trainer/Q Targets Max                              17.4594\n",
      "trainer/Q Targets Min                            -105.991\n",
      "trainer/Log Pis Mean                                2.96281\n",
      "trainer/Log Pis Std                                 2.47348\n",
      "trainer/Log Pis Max                                 9.12429\n",
      "trainer/Log Pis Min                                -4.22048\n",
      "trainer/policy/mean Mean                           -0.364237\n",
      "trainer/policy/mean Std                             0.647367\n",
      "trainer/policy/mean Max                             0.996297\n",
      "trainer/policy/mean Min                            -0.995906\n",
      "trainer/policy/normal/std Mean                      0.413554\n",
      "trainer/policy/normal/std Std                       0.237539\n",
      "trainer/policy/normal/std Max                       1.61171\n",
      "trainer/policy/normal/std Min                       0.0479119\n",
      "trainer/policy/normal/log_std Mean                 -1.06881\n",
      "trainer/policy/normal/log_std Std                   0.656415\n",
      "trainer/policy/normal/log_std Max                   0.477297\n",
      "trainer/policy/normal/log_std Min                  -3.03839\n",
      "trainer/Alpha                                       0.0105967\n",
      "trainer/Alpha Loss                                 -0.169124\n",
      "exploration/num steps total                    271000\n",
      "exploration/num paths total                      5442\n",
      "exploration/path length Mean                       50\n",
      "exploration/path length Std                         0\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        50\n",
      "exploration/Rewards Mean                           -0.9979\n",
      "exploration/Rewards Std                             0.0457776\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.895\n",
      "exploration/Returns Std                             1.01685\n",
      "exploration/Returns Max                           -37\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.269115\n",
      "exploration/Actions Std                             0.628842\n",
      "exploration/Actions Max                             0.999666\n",
      "exploration/Actions Min                            -0.999959\n",
      "exploration/Num Paths                             200\n",
      "exploration/Average Returns                       -49.895\n",
      "exploration/env_infos/final/is_success Mean         0\n",
      "exploration/env_infos/final/is_success Std          0\n",
      "exploration/env_infos/final/is_success Max          0\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0\n",
      "exploration/env_infos/is_success Std                0\n",
      "exploration/env_infos/is_success Max                0\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      13390\n",
      "evaluation/num paths total                        271\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.20469\n",
      "evaluation/Actions Std                              0.510067\n",
      "evaluation/Actions Max                              0.976464\n",
      "evaluation/Actions Min                             -0.986495\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.972792\n",
      "time/evaluation sampling (s)                       34.2025\n",
      "time/exploration sampling (s)                     728.798\n",
      "time/logging (s)                                    0.0270912\n",
      "time/sac training (s)                             199.307\n",
      "time/saving (s)                                     0.0140575\n",
      "time/training (s)                                   0.00697089\n",
      "time/epoch (s)                                    963.329\n",
      "time/total (s)                                  37766.4\n",
      "Epoch                                              26\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 27\n",
      "\n",
      " Cycle 0 27\n",
      "Took to collect: 9.094917297363281\n",
      "Took to train: 6.396380424499512\n",
      "\n",
      " Cycle 1 27\n",
      "Took to collect: 5.098679065704346\n",
      "Took to train: 6.374662399291992\n",
      "\n",
      " Cycle 2 27\n",
      "Took to collect: 8.737049341201782\n",
      "Took to train: 6.362062454223633\n",
      "\n",
      " Cycle 3 27\n",
      "Took to collect: 5.488302707672119\n",
      "Took to train: 6.404896259307861\n",
      "\n",
      " Cycle 4 27\n",
      "Took to collect: 7.098102569580078\n",
      "Took to train: 6.485505104064941\n",
      "\n",
      " Cycle 5 27\n",
      "Took to collect: 6.798503160476685\n",
      "Took to train: 6.427329778671265\n",
      "\n",
      " Cycle 6 27\n",
      "Took to collect: 7.9551849365234375\n",
      "Took to train: 6.458908319473267\n",
      "\n",
      " Cycle 7 27\n",
      "Took to collect: 7.6456921100616455\n",
      "Took to train: 6.485169410705566\n",
      "\n",
      " Cycle 8 27\n",
      "Took to collect: 7.460787773132324\n",
      "Took to train: 6.530203580856323\n",
      "\n",
      " Cycle 9 27\n",
      "Took to collect: 7.269456624984741\n",
      "Took to train: 6.442212820053101\n",
      "\n",
      " Cycle 10 27\n",
      "Took to collect: 8.6625394821167\n",
      "Took to train: 6.299409627914429\n",
      "\n",
      " Cycle 11 27\n",
      "Took to collect: 7.891931533813477\n",
      "Took to train: 6.290997266769409\n",
      "\n",
      " Cycle 12 27\n",
      "Took to collect: 6.8880228996276855\n",
      "Took to train: 6.420411109924316\n",
      "\n",
      " Cycle 13 27\n",
      "Took to collect: 6.326385259628296\n",
      "Took to train: 6.415910482406616\n",
      "\n",
      " Cycle 14 27\n",
      "Took to collect: 7.527974843978882\n",
      "Took to train: 6.291364908218384\n",
      "\n",
      " Cycle 15 27\n",
      "Took to collect: 7.267353773117065\n",
      "Took to train: 6.287001609802246\n",
      "\n",
      " Cycle 16 27\n",
      "Took to collect: 8.44792652130127\n",
      "Took to train: 6.391120672225952\n",
      "\n",
      " Cycle 17 27\n",
      "Took to collect: 7.697343349456787\n",
      "Took to train: 6.503002166748047\n",
      "\n",
      " Cycle 18 27\n",
      "Took to collect: 7.375340700149536\n",
      "Took to train: 6.442980527877808\n",
      "\n",
      " Cycle 19 27\n",
      "Took to collect: 9.11406135559082\n",
      "Took to train: 6.4175896644592285\n",
      "\n",
      " Cycle 20 27\n",
      "Took to collect: 8.081889390945435\n",
      "Took to train: 6.4425342082977295\n",
      "\n",
      " Cycle 21 27\n",
      "Took to collect: 8.538463115692139\n",
      "Took to train: 6.480100393295288\n",
      "\n",
      " Cycle 22 27\n",
      "Took to collect: 7.022273778915405\n",
      "Took to train: 6.4995436668396\n",
      "\n",
      " Cycle 23 27\n",
      "Took to collect: 8.618555307388306\n",
      "Took to train: 6.45160984992981\n",
      "\n",
      " Cycle 24 27\n",
      "Took to collect: 7.824070453643799\n",
      "Took to train: 6.303743839263916\n",
      "\n",
      " Cycle 25 27\n",
      "Took to collect: 8.020506381988525\n",
      "Took to train: 6.315263509750366\n",
      "\n",
      " Cycle 26 27\n",
      "Took to collect: 8.43987250328064\n",
      "Took to train: 6.3393778800964355\n",
      "\n",
      " Cycle 27 27\n",
      "Took to collect: 8.288044214248657\n",
      "Took to train: 6.414071083068848\n",
      "\n",
      " Cycle 28 27\n",
      "Took to collect: 7.4618635177612305\n",
      "Took to train: 6.411785364151001\n",
      "\n",
      " Cycle 29 27\n",
      "Took to collect: 7.823732614517212\n",
      "Took to train: 6.306804656982422\n",
      "\n",
      " Cycle 30 27\n",
      "Took to collect: 6.732519865036011\n",
      "Took to train: 6.434138536453247\n",
      "\n",
      " Cycle 31 27\n",
      "Took to collect: 9.425542116165161\n",
      "Took to train: 6.409368991851807\n",
      "\n",
      " Cycle 32 27\n",
      "Took to collect: 8.399826526641846\n",
      "Took to train: 6.418507814407349\n",
      "\n",
      " Cycle 33 27\n",
      "Took to collect: 7.048297166824341\n",
      "Took to train: 6.399005889892578\n",
      "\n",
      " Cycle 34 27\n",
      "Took to collect: 6.695611238479614\n",
      "Took to train: 6.300046920776367\n",
      "\n",
      " Cycle 35 27\n",
      "Took to collect: 7.966001033782959\n",
      "Took to train: 6.402005910873413\n",
      "\n",
      " Cycle 36 27\n",
      "Took to collect: 7.9796202182769775\n",
      "Took to train: 6.295925855636597\n",
      "\n",
      " Cycle 37 27\n",
      "Took to collect: 8.476983308792114\n",
      "Took to train: 6.301709890365601\n",
      "\n",
      " Cycle 38 27\n",
      "Took to collect: 6.175957202911377\n",
      "Took to train: 6.340371608734131\n",
      "\n",
      " Cycle 39 27\n",
      "Took to collect: 7.741382360458374\n",
      "Took to train: 6.4696948528289795\n",
      "\n",
      " Cycle 40 27\n",
      "Took to collect: 6.561158895492554\n",
      "Took to train: 6.444214105606079\n",
      "\n",
      " Cycle 41 27\n",
      "Took to collect: 9.083683967590332\n",
      "Took to train: 6.448346853256226\n",
      "\n",
      " Cycle 42 27\n",
      "Took to collect: 8.424503087997437\n",
      "Took to train: 6.4494242668151855\n",
      "\n",
      " Cycle 43 27\n",
      "Took to collect: 8.286987781524658\n",
      "Took to train: 6.405666828155518\n",
      "\n",
      " Cycle 44 27\n",
      "Took to collect: 9.897857427597046\n",
      "Took to train: 6.45571756362915\n",
      "\n",
      " Cycle 45 27\n",
      "Took to collect: 8.643599033355713\n",
      "Took to train: 6.437883615493774\n",
      "\n",
      " Cycle 46 27\n",
      "Took to collect: 9.286558866500854\n",
      "Took to train: 6.525110483169556\n",
      "\n",
      " Cycle 47 27\n",
      "Took to collect: 8.687096357345581\n",
      "Took to train: 6.502689361572266\n",
      "\n",
      " Cycle 48 27\n",
      "Took to collect: 8.267700672149658\n",
      "Took to train: 6.529212713241577\n",
      "\n",
      " Cycle 49 27\n",
      "Took to collect: 9.523132085800171\n",
      "Took to train: 6.460467100143433\n",
      "\n",
      " Cycle 50 27\n",
      "Took to collect: 8.89525032043457\n",
      "Took to train: 6.381751775741577\n",
      "\n",
      " Cycle 51 27\n",
      "Took to collect: 7.489183664321899\n",
      "Took to train: 6.486255407333374\n",
      "\n",
      " Cycle 52 27\n",
      "Took to collect: 8.463701963424683\n",
      "Took to train: 6.502959489822388\n",
      "\n",
      " Cycle 53 27\n",
      "Took to collect: 7.365448951721191\n",
      "Took to train: 6.4275102615356445\n",
      "\n",
      " Cycle 54 27\n",
      "Took to collect: 9.654360055923462\n",
      "Took to train: 6.499118328094482\n",
      "\n",
      " Cycle 55 27\n",
      "Took to collect: 8.203411102294922\n",
      "Took to train: 6.515624523162842\n",
      "\n",
      " Cycle 56 27\n",
      "Took to collect: 8.545572519302368\n",
      "Took to train: 6.521453380584717\n",
      "\n",
      " Cycle 57 27\n",
      "Took to collect: 6.9404802322387695\n",
      "Took to train: 6.485666751861572\n",
      "\n",
      " Cycle 58 27\n",
      "Took to collect: 8.309006690979004\n",
      "Took to train: 6.467259645462036\n",
      "\n",
      " Cycle 59 27\n",
      "Took to collect: 8.2959303855896\n",
      "Took to train: 6.510977029800415\n",
      "\n",
      " Cycle 60 27\n",
      "Took to collect: 8.480892896652222\n",
      "Took to train: 6.515848398208618\n",
      "\n",
      " Cycle 61 27\n",
      "Took to collect: 9.035144090652466\n",
      "Took to train: 6.509534120559692\n",
      "\n",
      " Cycle 62 27\n",
      "Took to collect: 7.657130241394043\n",
      "Took to train: 6.490225315093994\n",
      "\n",
      " Cycle 63 27\n",
      "Took to collect: 7.231401443481445\n",
      "Took to train: 6.5246946811676025\n",
      "\n",
      " Cycle 64 27\n",
      "Took to collect: 9.035564422607422\n",
      "Took to train: 6.5227370262146\n",
      "\n",
      " Cycle 65 27\n",
      "Took to collect: 6.968816518783569\n",
      "Took to train: 6.323120832443237\n",
      "\n",
      " Cycle 66 27\n",
      "Took to collect: 7.917122840881348\n",
      "Took to train: 6.263250112533569\n",
      "\n",
      " Cycle 67 27\n",
      "Took to collect: 6.38013482093811\n",
      "Took to train: 6.258858919143677\n",
      "\n",
      " Cycle 68 27\n",
      "Took to collect: 7.94185733795166\n",
      "Took to train: 6.388803958892822\n",
      "\n",
      " Cycle 69 27\n",
      "Took to collect: 9.04220962524414\n",
      "Took to train: 6.395245313644409\n",
      "\n",
      " Cycle 70 27\n",
      "Took to collect: 7.877079486846924\n",
      "Took to train: 6.365962266921997\n",
      "\n",
      " Cycle 71 27\n",
      "Took to collect: 6.982207536697388\n",
      "Took to train: 6.404447317123413\n",
      "\n",
      " Cycle 72 27\n",
      "Took to collect: 7.956338882446289\n",
      "Took to train: 6.26323127746582\n",
      "\n",
      " Cycle 73 27\n",
      "Took to collect: 7.758746147155762\n",
      "Took to train: 6.265628814697266\n",
      "\n",
      " Cycle 74 27\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 8.528199195861816\n",
      "Took to train: 6.315204381942749\n",
      "\n",
      " Cycle 75 27\n",
      "Took to collect: 9.860862016677856\n",
      "Took to train: 6.425311326980591\n",
      "\n",
      " Cycle 76 27\n",
      "Took to collect: 7.209594011306763\n",
      "Took to train: 6.279268980026245\n",
      "\n",
      " Cycle 77 27\n",
      "Took to collect: 7.648655891418457\n",
      "Took to train: 6.365934610366821\n",
      "\n",
      " Cycle 78 27\n",
      "Took to collect: 8.327548503875732\n",
      "Took to train: 6.358205318450928\n",
      "\n",
      " Cycle 79 27\n",
      "Took to collect: 7.739556550979614\n",
      "Took to train: 6.355336427688599\n",
      "\n",
      " Cycle 80 27\n",
      "Took to collect: 7.932675838470459\n",
      "Took to train: 6.365139722824097\n",
      "\n",
      " Cycle 81 27\n",
      "Took to collect: 8.448487281799316\n",
      "Took to train: 6.3761069774627686\n",
      "\n",
      " Cycle 82 27\n",
      "Took to collect: 8.556937456130981\n",
      "Took to train: 6.352928638458252\n",
      "\n",
      " Cycle 83 27\n",
      "Took to collect: 7.904700040817261\n",
      "Took to train: 6.275227069854736\n",
      "\n",
      " Cycle 84 27\n",
      "Took to collect: 8.797421216964722\n",
      "Took to train: 6.259733438491821\n",
      "\n",
      " Cycle 85 27\n",
      "Took to collect: 7.686465263366699\n",
      "Took to train: 6.25510311126709\n",
      "\n",
      " Cycle 86 27\n",
      "Took to collect: 8.598825216293335\n",
      "Took to train: 6.237870216369629\n",
      "\n",
      " Cycle 87 27\n",
      "Took to collect: 7.958609580993652\n",
      "Took to train: 6.264813184738159\n",
      "\n",
      " Cycle 88 27\n",
      "Took to collect: 8.532690286636353\n",
      "Took to train: 6.341786861419678\n",
      "\n",
      " Cycle 89 27\n",
      "Took to collect: 8.166532039642334\n",
      "Took to train: 6.386601448059082\n",
      "\n",
      " Cycle 90 27\n",
      "Took to collect: 8.866149187088013\n",
      "Took to train: 6.4337639808654785\n",
      "\n",
      " Cycle 91 27\n",
      "Took to collect: 9.958975553512573\n",
      "Took to train: 6.319656848907471\n",
      "\n",
      " Cycle 92 27\n",
      "Took to collect: 7.4628119468688965\n",
      "Took to train: 6.2840330600738525\n",
      "\n",
      " Cycle 93 27\n",
      "Took to collect: 8.431283712387085\n",
      "Took to train: 6.3391759395599365\n",
      "\n",
      " Cycle 94 27\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.508349180221558\n",
      "Took to train: 6.275943756103516\n",
      "\n",
      " Cycle 95 27\n",
      "Took to collect: 8.412890434265137\n",
      "Took to train: 6.407251596450806\n",
      "\n",
      " Cycle 96 27\n",
      "Took to collect: 9.656819343566895\n",
      "Took to train: 6.432530164718628\n",
      "\n",
      " Cycle 97 27\n",
      "Took to collect: 7.898974418640137\n",
      "Took to train: 6.539710283279419\n",
      "\n",
      " Cycle 98 27\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 8.629947423934937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.514090061187744\n",
      "\n",
      " Cycle 99 27\n",
      "Took to collect: 8.168192625045776\n",
      "Took to train: 6.601067066192627\n",
      "Time collect avg cycle: 8.025879921913146\n",
      "Time train avg cycle: 6.401734216213226\n",
      "Total avg cycle: 14.437714903354644\n",
      "Ending epoch\n",
      "2020-10-26 08:32:54.292657 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 27 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.602331\n",
      "trainer/QF2 Loss                                    0.580652\n",
      "trainer/Policy Loss                                47.9329\n",
      "trainer/Q1 Predictions Mean                       -48.0063\n",
      "trainer/Q1 Predictions Std                         36.362\n",
      "trainer/Q1 Predictions Max                         17.2874\n",
      "trainer/Q1 Predictions Min                       -106.045\n",
      "trainer/Q2 Predictions Mean                       -47.9686\n",
      "trainer/Q2 Predictions Std                         36.3312\n",
      "trainer/Q2 Predictions Max                         17.8422\n",
      "trainer/Q2 Predictions Min                       -105.946\n",
      "trainer/Q Targets Mean                            -47.6864\n",
      "trainer/Q Targets Std                              36.4244\n",
      "trainer/Q Targets Max                              17.9796\n",
      "trainer/Q Targets Min                            -105.809\n",
      "trainer/Log Pis Mean                                2.80525\n",
      "trainer/Log Pis Std                                 2.18712\n",
      "trainer/Log Pis Max                                10.0533\n",
      "trainer/Log Pis Min                                -5.39843\n",
      "trainer/policy/mean Mean                           -0.348444\n",
      "trainer/policy/mean Std                             0.613924\n",
      "trainer/policy/mean Max                             0.993105\n",
      "trainer/policy/mean Min                            -0.9928\n",
      "trainer/policy/normal/std Mean                      0.377432\n",
      "trainer/policy/normal/std Std                       0.239029\n",
      "trainer/policy/normal/std Max                       1.4072\n",
      "trainer/policy/normal/std Min                       0.045009\n",
      "trainer/policy/normal/log_std Mean                 -1.20389\n",
      "trainer/policy/normal/log_std Std                   0.724884\n",
      "trainer/policy/normal/log_std Max                   0.341603\n",
      "trainer/policy/normal/log_std Min                  -3.10089\n",
      "trainer/Alpha                                       0.0105549\n",
      "trainer/Alpha Loss                                 -0.886362\n",
      "exploration/num steps total                    281000\n",
      "exploration/num paths total                      5645\n",
      "exploration/path length Mean                       49.2611\n",
      "exploration/path length Std                         4.96548\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         8\n",
      "exploration/Rewards Mean                           -0.9931\n",
      "exploration/Rewards Std                             0.0827792\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -48.9212\n",
      "exploration/Returns Std                             5.52769\n",
      "exploration/Returns Max                            -7\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.331325\n",
      "exploration/Actions Std                             0.594726\n",
      "exploration/Actions Max                             0.999586\n",
      "exploration/Actions Min                            -0.999993\n",
      "exploration/Num Paths                             203\n",
      "exploration/Average Returns                       -48.9212\n",
      "exploration/env_infos/final/is_success Mean         0.0147783\n",
      "exploration/env_infos/final/is_success Std          0.120665\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0003\n",
      "exploration/env_infos/is_success Std                0.0173179\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      13890\n",
      "evaluation/num paths total                        281\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.59029\n",
      "evaluation/Actions Std                              0.472444\n",
      "evaluation/Actions Max                              0.969522\n",
      "evaluation/Actions Min                             -0.979645\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.984344\n",
      "time/evaluation sampling (s)                       35.7974\n",
      "time/exploration sampling (s)                     802.607\n",
      "time/logging (s)                                    0.0283193\n",
      "time/sac training (s)                             199.147\n",
      "time/saving (s)                                     0.014231\n",
      "time/training (s)                                   0.00695614\n",
      "time/epoch (s)                                   1038.59\n",
      "time/total (s)                                  39245.8\n",
      "Epoch                                              27\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 28\n",
      "\n",
      " Cycle 0 28\n",
      "Took to collect: 6.621570110321045\n",
      "Took to train: 6.408163785934448\n",
      "\n",
      " Cycle 1 28\n",
      "Took to collect: 8.013801097869873\n",
      "Took to train: 6.406804084777832\n",
      "\n",
      " Cycle 2 28\n",
      "Took to collect: 4.701362133026123\n",
      "Took to train: 6.414913654327393\n",
      "\n",
      " Cycle 3 28\n",
      "Took to collect: 6.513159275054932\n",
      "Took to train: 6.474095821380615\n",
      "\n",
      " Cycle 4 28\n",
      "Took to collect: 7.31925892829895\n",
      "Took to train: 6.510056734085083\n",
      "\n",
      " Cycle 5 28\n",
      "Took to collect: 8.372760772705078\n",
      "Took to train: 6.4471046924591064\n",
      "\n",
      " Cycle 6 28\n",
      "Took to collect: 6.941202402114868\n",
      "Took to train: 6.4598469734191895\n",
      "\n",
      " Cycle 7 28\n",
      "Took to collect: 6.107538938522339\n",
      "Took to train: 6.486051321029663\n",
      "\n",
      " Cycle 8 28\n",
      "Took to collect: 8.703168630599976\n",
      "Took to train: 6.492904901504517\n",
      "\n",
      " Cycle 9 28\n",
      "Took to collect: 7.3423707485198975\n",
      "Took to train: 6.479696035385132\n",
      "\n",
      " Cycle 10 28\n",
      "Took to collect: 9.317498922348022\n",
      "Took to train: 6.442057371139526\n",
      "\n",
      " Cycle 11 28\n",
      "Took to collect: 8.740539312362671\n",
      "Took to train: 6.460587739944458\n",
      "\n",
      " Cycle 12 28\n",
      "Took to collect: 9.245994329452515\n",
      "Took to train: 6.4567718505859375\n",
      "\n",
      " Cycle 13 28\n",
      "Took to collect: 5.719192743301392\n",
      "Took to train: 6.447409152984619\n",
      "\n",
      " Cycle 14 28\n",
      "Took to collect: 8.64884901046753\n",
      "Took to train: 6.450050592422485\n",
      "\n",
      " Cycle 15 28\n",
      "Took to collect: 7.086562871932983\n",
      "Took to train: 6.530242204666138\n",
      "\n",
      " Cycle 16 28\n",
      "Took to collect: 8.554746389389038\n",
      "Took to train: 6.542919397354126\n",
      "\n",
      " Cycle 17 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 7.373707294464111\n",
      "Took to train: 6.532153606414795\n",
      "\n",
      " Cycle 18 28\n",
      "Took to collect: 9.020413160324097\n",
      "Took to train: 6.535706520080566\n",
      "\n",
      " Cycle 19 28\n",
      "Took to collect: 7.137653589248657\n",
      "Took to train: 6.465540170669556\n",
      "\n",
      " Cycle 20 28\n",
      "Took to collect: 6.522043466567993\n",
      "Took to train: 6.468079328536987\n",
      "\n",
      " Cycle 21 28\n",
      "Took to collect: 8.352689504623413\n",
      "Took to train: 6.466280698776245\n",
      "\n",
      " Cycle 22 28\n",
      "Took to collect: 7.825707912445068\n",
      "Took to train: 6.523825645446777\n",
      "\n",
      " Cycle 23 28\n",
      "Took to collect: 8.470199823379517\n",
      "Took to train: 6.464315176010132\n",
      "\n",
      " Cycle 24 28\n",
      "Took to collect: 8.44074273109436\n",
      "Took to train: 6.5050389766693115\n",
      "\n",
      " Cycle 25 28\n",
      "Took to collect: 7.615242958068848\n",
      "Took to train: 6.505212068557739\n",
      "\n",
      " Cycle 26 28\n",
      "Took to collect: 8.452497720718384\n",
      "Took to train: 6.505215167999268\n",
      "\n",
      " Cycle 27 28\n",
      "Took to collect: 7.875146389007568\n",
      "Took to train: 6.335993528366089\n",
      "\n",
      " Cycle 28 28\n",
      "Took to collect: 9.247496604919434\n",
      "Took to train: 6.46200704574585\n",
      "\n",
      " Cycle 29 28\n",
      "Took to collect: 6.684308290481567\n",
      "Took to train: 6.42983865737915\n",
      "\n",
      " Cycle 30 28\n",
      "Took to collect: 7.691833972930908\n",
      "Took to train: 6.443050146102905\n",
      "\n",
      " Cycle 31 28\n",
      "Took to collect: 7.029286861419678\n",
      "Took to train: 6.471698760986328\n",
      "\n",
      " Cycle 32 28\n",
      "Took to collect: 6.064225196838379\n",
      "Took to train: 6.434641599655151\n",
      "\n",
      " Cycle 33 28\n",
      "Took to collect: 7.774761915206909\n",
      "Took to train: 6.440640926361084\n",
      "\n",
      " Cycle 34 28\n",
      "Took to collect: 7.9995505809783936\n",
      "Took to train: 6.450481176376343\n",
      "\n",
      " Cycle 35 28\n",
      "Took to collect: 7.912012100219727\n",
      "Took to train: 6.391565799713135\n",
      "\n",
      " Cycle 36 28\n",
      "Took to collect: 8.755920648574829\n",
      "Took to train: 6.327194690704346\n",
      "\n",
      " Cycle 37 28\n",
      "Took to collect: 8.706885814666748\n",
      "Took to train: 6.2980170249938965\n",
      "\n",
      " Cycle 38 28\n",
      "Took to collect: 7.693196535110474\n",
      "Took to train: 6.314264535903931\n",
      "\n",
      " Cycle 39 28\n",
      "Took to collect: 7.905116081237793\n",
      "Took to train: 6.3488054275512695\n",
      "\n",
      " Cycle 40 28\n",
      "Took to collect: 7.897733926773071\n",
      "Took to train: 6.428845643997192\n",
      "\n",
      " Cycle 41 28\n",
      "Took to collect: 6.925447702407837\n",
      "Took to train: 6.4268958568573\n",
      "\n",
      " Cycle 42 28\n",
      "Took to collect: 7.3392014503479\n",
      "Took to train: 6.451923370361328\n",
      "\n",
      " Cycle 43 28\n",
      "Took to collect: 8.164411067962646\n",
      "Took to train: 6.4340081214904785\n",
      "\n",
      " Cycle 44 28\n",
      "Took to collect: 6.962550640106201\n",
      "Took to train: 6.425844192504883\n",
      "\n",
      " Cycle 45 28\n",
      "Took to collect: 7.552882671356201\n",
      "Took to train: 6.422667741775513\n",
      "\n",
      " Cycle 46 28\n",
      "Took to collect: 6.6833367347717285\n",
      "Took to train: 6.412519454956055\n",
      "\n",
      " Cycle 47 28\n",
      "Took to collect: 8.530826091766357\n",
      "Took to train: 6.512197971343994\n",
      "\n",
      " Cycle 48 28\n",
      "Took to collect: 8.505259037017822\n",
      "Took to train: 6.391169786453247\n",
      "\n",
      " Cycle 49 28\n",
      "Took to collect: 7.426895380020142\n",
      "Took to train: 6.4071738719940186\n",
      "\n",
      " Cycle 50 28\n",
      "Took to collect: 6.854055166244507\n",
      "Took to train: 6.400838136672974\n",
      "\n",
      " Cycle 51 28\n",
      "Took to collect: 7.763104677200317\n",
      "Took to train: 6.411708831787109\n",
      "\n",
      " Cycle 52 28\n",
      "Took to collect: 8.524405479431152\n",
      "Took to train: 6.417534351348877\n",
      "\n",
      " Cycle 53 28\n",
      "Took to collect: 8.580660104751587\n",
      "Took to train: 6.402533054351807\n",
      "\n",
      " Cycle 54 28\n",
      "Took to collect: 6.589182376861572\n",
      "Took to train: 6.506314754486084\n",
      "\n",
      " Cycle 55 28\n",
      "Took to collect: 8.032782793045044\n",
      "Took to train: 6.424537658691406\n",
      "\n",
      " Cycle 56 28\n",
      "Took to collect: 7.215566873550415\n",
      "Took to train: 6.494502305984497\n",
      "\n",
      " Cycle 57 28\n",
      "Took to collect: 7.589514255523682\n",
      "Took to train: 6.483307600021362\n",
      "\n",
      " Cycle 58 28\n",
      "Took to collect: 8.001591920852661\n",
      "Took to train: 6.446008682250977\n",
      "\n",
      " Cycle 59 28\n",
      "Took to collect: 7.365570545196533\n",
      "Took to train: 6.473190784454346\n",
      "\n",
      " Cycle 60 28\n",
      "Took to collect: 6.7293572425842285\n",
      "Took to train: 6.476527452468872\n",
      "\n",
      " Cycle 61 28\n",
      "Took to collect: 8.277464151382446\n",
      "Took to train: 6.475337743759155\n",
      "\n",
      " Cycle 62 28\n",
      "Took to collect: 6.1243650913238525\n",
      "Took to train: 6.46432089805603\n",
      "\n",
      " Cycle 63 28\n",
      "Took to collect: 9.060242891311646\n",
      "Took to train: 6.4455907344818115\n",
      "\n",
      " Cycle 64 28\n",
      "Took to collect: 7.44972038269043\n",
      "Took to train: 6.473963260650635\n",
      "\n",
      " Cycle 65 28\n",
      "Took to collect: 8.66518783569336\n",
      "Took to train: 6.443551778793335\n",
      "\n",
      " Cycle 66 28\n",
      "Took to collect: 8.121916770935059\n",
      "Took to train: 6.406808614730835\n",
      "\n",
      " Cycle 67 28\n",
      "Took to collect: 8.79746699333191\n",
      "Took to train: 6.267459392547607\n",
      "\n",
      " Cycle 68 28\n",
      "Took to collect: 8.374628782272339\n",
      "Took to train: 6.2763190269470215\n",
      "\n",
      " Cycle 69 28\n",
      "Took to collect: 7.684903383255005\n",
      "Took to train: 6.4004127979278564\n",
      "\n",
      " Cycle 70 28\n",
      "Took to collect: 8.744109392166138\n",
      "Took to train: 6.294622182846069\n",
      "\n",
      " Cycle 71 28\n",
      "Took to collect: 6.766015529632568\n",
      "Took to train: 6.342383623123169\n",
      "\n",
      " Cycle 72 28\n",
      "Took to collect: 8.866462469100952\n",
      "Took to train: 6.290164947509766\n",
      "\n",
      " Cycle 73 28\n",
      "Took to collect: 8.735191822052002\n",
      "Took to train: 6.469456434249878\n",
      "\n",
      " Cycle 74 28\n",
      "Took to collect: 8.286928415298462\n",
      "Took to train: 6.4435999393463135\n",
      "\n",
      " Cycle 75 28\n",
      "Took to collect: 10.112030744552612\n",
      "Took to train: 6.392674922943115\n",
      "\n",
      " Cycle 76 28\n",
      "Took to collect: 8.55537724494934\n",
      "Took to train: 6.4163243770599365\n",
      "\n",
      " Cycle 77 28\n",
      "Took to collect: 7.884739398956299\n",
      "Took to train: 6.460937738418579\n",
      "\n",
      " Cycle 78 28\n",
      "Took to collect: 9.39937973022461\n",
      "Took to train: 6.387671947479248\n",
      "\n",
      " Cycle 79 28\n",
      "Took to collect: 10.028505563735962\n",
      "Took to train: 6.344191074371338\n",
      "\n",
      " Cycle 80 28\n",
      "Took to collect: 8.100478410720825\n",
      "Took to train: 6.336357116699219\n",
      "\n",
      " Cycle 81 28\n",
      "Took to collect: 8.420008182525635\n",
      "Took to train: 6.353732109069824\n",
      "\n",
      " Cycle 82 28\n",
      "Took to collect: 7.763872385025024\n",
      "Took to train: 6.311205148696899\n",
      "\n",
      " Cycle 83 28\n",
      "Took to collect: 7.563732862472534\n",
      "Took to train: 6.336134672164917\n",
      "\n",
      " Cycle 84 28\n",
      "Took to collect: 7.157801389694214\n",
      "Took to train: 6.405764102935791\n",
      "\n",
      " Cycle 85 28\n",
      "Took to collect: 7.220410108566284\n",
      "Took to train: 6.468268871307373\n",
      "\n",
      " Cycle 86 28\n",
      "Took to collect: 6.139662265777588\n",
      "Took to train: 6.426835060119629\n",
      "\n",
      " Cycle 87 28\n",
      "Took to collect: 9.591582298278809\n",
      "Took to train: 6.34921669960022\n",
      "\n",
      " Cycle 88 28\n",
      "Took to collect: 7.600259065628052\n",
      "Took to train: 6.404500961303711\n",
      "\n",
      " Cycle 89 28\n",
      "Took to collect: 8.182150840759277\n",
      "Took to train: 6.333140134811401\n",
      "\n",
      " Cycle 90 28\n",
      "Took to collect: 6.5821614265441895\n",
      "Took to train: 6.405901908874512\n",
      "\n",
      " Cycle 91 28\n",
      "Took to collect: 9.189273357391357\n",
      "Took to train: 6.445950031280518\n",
      "\n",
      " Cycle 92 28\n",
      "Took to collect: 7.17629337310791\n",
      "Took to train: 6.420412302017212\n",
      "\n",
      " Cycle 93 28\n",
      "Took to collect: 7.12575364112854\n",
      "Took to train: 6.475315809249878\n",
      "\n",
      " Cycle 94 28\n",
      "Took to collect: 8.207098007202148\n",
      "Took to train: 6.389394760131836\n",
      "\n",
      " Cycle 95 28\n",
      "Took to collect: 8.113680839538574\n",
      "Took to train: 6.284555673599243\n",
      "\n",
      " Cycle 96 28\n",
      "Took to collect: 7.360526084899902\n",
      "Took to train: 6.293905019760132\n",
      "\n",
      " Cycle 97 28\n",
      "Took to collect: 7.349438905715942\n",
      "Took to train: 6.384346008300781\n",
      "\n",
      " Cycle 98 28\n",
      "Took to collect: 6.938981533050537\n",
      "Took to train: 6.59512734413147\n",
      "\n",
      " Cycle 99 28\n",
      "Took to collect: 6.6235880851745605\n",
      "Took to train: 6.665624141693115\n",
      "Time collect avg cycle: 7.800759415626526\n",
      "Time train avg cycle: 6.428609719276428\n",
      "Total avg cycle: 14.239572863578797\n",
      "Ending epoch\n",
      "2020-10-26 08:57:19.426727 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 28 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.80277\n",
      "trainer/QF2 Loss                                    0.692332\n",
      "trainer/Policy Loss                                48.1573\n",
      "trainer/Q1 Predictions Mean                       -48.2996\n",
      "trainer/Q1 Predictions Std                         34.8285\n",
      "trainer/Q1 Predictions Max                          4.95067\n",
      "trainer/Q1 Predictions Min                       -105.657\n",
      "trainer/Q2 Predictions Mean                       -48.0739\n",
      "trainer/Q2 Predictions Std                         34.8651\n",
      "trainer/Q2 Predictions Max                          5.85325\n",
      "trainer/Q2 Predictions Min                       -105.566\n",
      "trainer/Q Targets Mean                            -48.1919\n",
      "trainer/Q Targets Std                              34.8965\n",
      "trainer/Q Targets Max                               5.0848\n",
      "trainer/Q Targets Min                            -105.653\n",
      "trainer/Log Pis Mean                                3.24801\n",
      "trainer/Log Pis Std                                 2.47283\n",
      "trainer/Log Pis Max                                10.9705\n",
      "trainer/Log Pis Min                                -6.1292\n",
      "trainer/policy/mean Mean                           -0.3097\n",
      "trainer/policy/mean Std                             0.662403\n",
      "trainer/policy/mean Max                             0.997571\n",
      "trainer/policy/mean Min                            -0.994474\n",
      "trainer/policy/normal/std Mean                      0.393346\n",
      "trainer/policy/normal/std Std                       0.236636\n",
      "trainer/policy/normal/std Max                       1.46632\n",
      "trainer/policy/normal/std Min                       0.0382306\n",
      "trainer/policy/normal/log_std Mean                 -1.15336\n",
      "trainer/policy/normal/log_std Std                   0.724038\n",
      "trainer/policy/normal/log_std Max                   0.382758\n",
      "trainer/policy/normal/log_std Min                  -3.26412\n",
      "trainer/Alpha                                       0.00970681\n",
      "trainer/Alpha Loss                                  1.14951\n",
      "exploration/num steps total                    291000\n",
      "exploration/num paths total                      5845\n",
      "exploration/path length Mean                       50\n",
      "exploration/path length Std                         0\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        50\n",
      "exploration/Rewards Mean                           -0.9995\n",
      "exploration/Rewards Std                             0.0223551\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.975\n",
      "exploration/Returns Std                             0.352668\n",
      "exploration/Returns Max                           -45\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.294006\n",
      "exploration/Actions Std                             0.596397\n",
      "exploration/Actions Max                             0.999752\n",
      "exploration/Actions Min                            -0.999776\n",
      "exploration/Num Paths                             200\n",
      "exploration/Average Returns                       -49.975\n",
      "exploration/env_infos/final/is_success Mean         0\n",
      "exploration/env_infos/final/is_success Std          0\n",
      "exploration/env_infos/final/is_success Max          0\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0\n",
      "exploration/env_infos/is_success Std                0\n",
      "exploration/env_infos/is_success Max                0\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      14390\n",
      "evaluation/num paths total                        291\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.364237\n",
      "evaluation/Actions Std                              0.562647\n",
      "evaluation/Actions Max                              0.975014\n",
      "evaluation/Actions Min                             -0.983576\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.994997\n",
      "time/evaluation sampling (s)                       41.1122\n",
      "time/exploration sampling (s)                     780.095\n",
      "time/logging (s)                                    0.0277363\n",
      "time/sac training (s)                             200.037\n",
      "time/saving (s)                                     0.0139996\n",
      "time/training (s)                                   0.00701328\n",
      "time/epoch (s)                                   1022.29\n",
      "time/total (s)                                  40710.8\n",
      "Epoch                                              28\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 29\n",
      "\n",
      " Cycle 0 29\n",
      "Took to collect: 8.575502872467041\n",
      "Took to train: 6.323089361190796\n",
      "\n",
      " Cycle 1 29\n",
      "Took to collect: 9.31152606010437\n",
      "Took to train: 6.2804529666900635\n",
      "\n",
      " Cycle 2 29\n",
      "Took to collect: 7.973908185958862\n",
      "Took to train: 6.3089587688446045\n",
      "\n",
      " Cycle 3 29\n",
      "Took to collect: 7.186971426010132\n",
      "Took to train: 6.416873216629028\n",
      "\n",
      " Cycle 4 29\n",
      "Took to collect: 8.534658432006836\n",
      "Took to train: 6.285498380661011\n",
      "\n",
      " Cycle 5 29\n",
      "Took to collect: 8.411282062530518\n",
      "Took to train: 6.278506517410278\n",
      "\n",
      " Cycle 6 29\n",
      "Took to collect: 7.744866609573364\n",
      "Took to train: 6.2847981452941895\n",
      "\n",
      " Cycle 7 29\n",
      "Took to collect: 7.970816373825073\n",
      "Took to train: 6.2892372608184814\n",
      "\n",
      " Cycle 8 29\n",
      "Took to collect: 8.745526552200317\n",
      "Took to train: 6.295550107955933\n",
      "\n",
      " Cycle 9 29\n",
      "Took to collect: 7.429262638092041\n",
      "Took to train: 6.330954313278198\n",
      "\n",
      " Cycle 10 29\n",
      "Took to collect: 7.076103210449219\n",
      "Took to train: 6.289653539657593\n",
      "\n",
      " Cycle 11 29\n",
      "Took to collect: 6.910343170166016\n",
      "Took to train: 6.282719373703003\n",
      "\n",
      " Cycle 12 29\n",
      "Took to collect: 8.668912887573242\n",
      "Took to train: 6.274445533752441\n",
      "\n",
      " Cycle 13 29\n",
      "Took to collect: 7.367703676223755\n",
      "Took to train: 6.289567232131958\n",
      "\n",
      " Cycle 14 29\n",
      "Took to collect: 7.462638854980469\n",
      "Took to train: 6.3027544021606445\n",
      "\n",
      " Cycle 15 29\n",
      "Took to collect: 8.490938901901245\n",
      "Took to train: 6.322633743286133\n",
      "\n",
      " Cycle 16 29\n",
      "Took to collect: 8.64579153060913\n",
      "Took to train: 6.4020469188690186\n",
      "\n",
      " Cycle 17 29\n",
      "Took to collect: 7.974061489105225\n",
      "Took to train: 6.4080634117126465\n",
      "\n",
      " Cycle 18 29\n",
      "Took to collect: 8.856996536254883\n",
      "Took to train: 6.370850563049316\n",
      "\n",
      " Cycle 19 29\n",
      "Took to collect: 6.3009960651397705\n",
      "Took to train: 6.39534854888916\n",
      "\n",
      " Cycle 20 29\n",
      "Took to collect: 7.716492414474487\n",
      "Took to train: 6.411778926849365\n",
      "\n",
      " Cycle 21 29\n",
      "Took to collect: 7.379836320877075\n",
      "Took to train: 6.391615390777588\n",
      "\n",
      " Cycle 22 29\n",
      "Took to collect: 9.28228235244751\n",
      "Took to train: 6.3918352127075195\n",
      "\n",
      " Cycle 23 29\n",
      "Took to collect: 7.572316646575928\n",
      "Took to train: 6.423619985580444\n",
      "\n",
      " Cycle 24 29\n",
      "Took to collect: 8.015315771102905\n",
      "Took to train: 6.348507642745972\n",
      "\n",
      " Cycle 25 29\n",
      "Took to collect: 7.472644805908203\n",
      "Took to train: 6.35360050201416\n",
      "\n",
      " Cycle 26 29\n",
      "Took to collect: 7.271190166473389\n",
      "Took to train: 6.336769342422485\n",
      "\n",
      " Cycle 27 29\n",
      "Took to collect: 6.989090442657471\n",
      "Took to train: 6.347560405731201\n",
      "\n",
      " Cycle 28 29\n",
      "Took to collect: 7.118093729019165\n",
      "Took to train: 6.3685853481292725\n",
      "\n",
      " Cycle 29 29\n",
      "Took to collect: 8.0101478099823\n",
      "Took to train: 6.338118076324463\n",
      "\n",
      " Cycle 30 29\n",
      "Took to collect: 7.948197603225708\n",
      "Took to train: 6.381293058395386\n",
      "\n",
      " Cycle 31 29\n",
      "Took to collect: 7.158504009246826\n",
      "Took to train: 6.391439199447632\n",
      "\n",
      " Cycle 32 29\n",
      "Took to collect: 7.252788305282593\n",
      "Took to train: 6.399450063705444\n",
      "\n",
      " Cycle 33 29\n",
      "Took to collect: 7.662382125854492\n",
      "Took to train: 6.406176328659058\n",
      "\n",
      " Cycle 34 29\n",
      "Took to collect: 8.195647478103638\n",
      "Took to train: 6.360683441162109\n",
      "\n",
      " Cycle 35 29\n",
      "Took to collect: 7.9356770515441895\n",
      "Took to train: 6.401325225830078\n",
      "\n",
      " Cycle 36 29\n",
      "Took to collect: 6.742548942565918\n",
      "Took to train: 6.3795318603515625\n",
      "\n",
      " Cycle 37 29\n",
      "Took to collect: 7.686087369918823\n",
      "Took to train: 6.4677510261535645\n",
      "\n",
      " Cycle 38 29\n",
      "Took to collect: 7.129424095153809\n",
      "Took to train: 6.515496015548706\n",
      "\n",
      " Cycle 39 29\n",
      "Took to collect: 7.169684410095215\n",
      "Took to train: 6.525428295135498\n",
      "\n",
      " Cycle 40 29\n",
      "Took to collect: 7.801199436187744\n",
      "Took to train: 6.568369388580322\n",
      "\n",
      " Cycle 41 29\n",
      "Took to collect: 7.040076017379761\n",
      "Took to train: 6.525757789611816\n",
      "\n",
      " Cycle 42 29\n",
      "Took to collect: 7.8715574741363525\n",
      "Took to train: 6.52083158493042\n",
      "\n",
      " Cycle 43 29\n",
      "Took to collect: 7.347122669219971\n",
      "Took to train: 6.49880838394165\n",
      "\n",
      " Cycle 44 29\n",
      "Took to collect: 8.146785259246826\n",
      "Took to train: 6.523716688156128\n",
      "\n",
      " Cycle 45 29\n",
      "Took to collect: 7.509095191955566\n",
      "Took to train: 6.52108097076416\n",
      "\n",
      " Cycle 46 29\n",
      "Took to collect: 8.602195501327515\n",
      "Took to train: 6.517369270324707\n",
      "\n",
      " Cycle 47 29\n",
      "Took to collect: 8.569543838500977\n",
      "Took to train: 6.536272048950195\n",
      "\n",
      " Cycle 48 29\n",
      "Took to collect: 7.364017724990845\n",
      "Took to train: 6.526366233825684\n",
      "\n",
      " Cycle 49 29\n",
      "Took to collect: 8.897944450378418\n",
      "Took to train: 6.498073577880859\n",
      "\n",
      " Cycle 50 29\n",
      "Took to collect: 8.665088653564453\n",
      "Took to train: 6.524576425552368\n",
      "\n",
      " Cycle 51 29\n",
      "Took to collect: 8.549878358840942\n",
      "Took to train: 6.515401601791382\n",
      "\n",
      " Cycle 52 29\n",
      "Took to collect: 7.539453744888306\n",
      "Took to train: 6.519485235214233\n",
      "\n",
      " Cycle 53 29\n",
      "Took to collect: 5.026580333709717\n",
      "Took to train: 6.517547369003296\n",
      "\n",
      " Cycle 54 29\n",
      "Took to collect: 5.857827663421631\n",
      "Took to train: 6.5246806144714355\n",
      "\n",
      " Cycle 55 29\n",
      "Took to collect: 7.870846271514893\n",
      "Took to train: 6.460282564163208\n",
      "\n",
      " Cycle 56 29\n",
      "Took to collect: 7.3638834953308105\n",
      "Took to train: 6.493860721588135\n",
      "\n",
      " Cycle 57 29\n",
      "Took to collect: 8.064918518066406\n",
      "Took to train: 6.493201494216919\n",
      "\n",
      " Cycle 58 29\n",
      "Took to collect: 7.524086236953735\n",
      "Took to train: 6.500332355499268\n",
      "\n",
      " Cycle 59 29\n",
      "Took to collect: 6.680813789367676\n",
      "Took to train: 6.4952802658081055\n",
      "\n",
      " Cycle 60 29\n",
      "Took to collect: 8.858721494674683\n",
      "Took to train: 6.41131591796875\n",
      "\n",
      " Cycle 61 29\n",
      "Took to collect: 8.046658754348755\n",
      "Took to train: 6.4727256298065186\n",
      "\n",
      " Cycle 62 29\n",
      "Took to collect: 6.708439111709595\n",
      "Took to train: 6.412200450897217\n",
      "\n",
      " Cycle 63 29\n",
      "Took to collect: 7.9441914558410645\n",
      "Took to train: 6.356043100357056\n",
      "\n",
      " Cycle 64 29\n",
      "Took to collect: 7.281829833984375\n",
      "Took to train: 6.427649021148682\n",
      "\n",
      " Cycle 65 29\n",
      "Took to collect: 7.642555236816406\n",
      "Took to train: 6.4717442989349365\n",
      "\n",
      " Cycle 66 29\n",
      "Took to collect: 7.847643613815308\n",
      "Took to train: 6.313436269760132\n",
      "\n",
      " Cycle 67 29\n",
      "Took to collect: 7.745906829833984\n",
      "Took to train: 6.354468822479248\n",
      "\n",
      " Cycle 68 29\n",
      "Took to collect: 7.466269493103027\n",
      "Took to train: 6.294962167739868\n",
      "\n",
      " Cycle 69 29\n",
      "Took to collect: 7.621484994888306\n",
      "Took to train: 6.337684631347656\n",
      "\n",
      " Cycle 70 29\n",
      "Took to collect: 5.942898750305176\n",
      "Took to train: 6.395623445510864\n",
      "\n",
      " Cycle 71 29\n",
      "Took to collect: 7.914705514907837\n",
      "Took to train: 6.406866073608398\n",
      "\n",
      " Cycle 72 29\n",
      "Took to collect: 7.480430603027344\n",
      "Took to train: 6.403056621551514\n",
      "\n",
      " Cycle 73 29\n",
      "Took to collect: 8.602328062057495\n",
      "Took to train: 6.391888618469238\n",
      "\n",
      " Cycle 74 29\n",
      "Took to collect: 8.456068277359009\n",
      "Took to train: 6.397423028945923\n",
      "\n",
      " Cycle 75 29\n",
      "Took to collect: 6.611573219299316\n",
      "Took to train: 6.401616811752319\n",
      "\n",
      " Cycle 76 29\n",
      "Took to collect: 6.801025152206421\n",
      "Took to train: 6.3978211879730225\n",
      "\n",
      " Cycle 77 29\n",
      "Took to collect: 8.147084474563599\n",
      "Took to train: 6.396395683288574\n",
      "\n",
      " Cycle 78 29\n",
      "Took to collect: 7.015700817108154\n",
      "Took to train: 6.399441957473755\n",
      "\n",
      " Cycle 79 29\n",
      "Took to collect: 8.334958791732788\n",
      "Took to train: 6.3400843143463135\n",
      "\n",
      " Cycle 80 29\n",
      "Took to collect: 8.278818607330322\n",
      "Took to train: 6.4783735275268555\n",
      "\n",
      " Cycle 81 29\n",
      "Took to collect: 7.678192853927612\n",
      "Took to train: 6.286075592041016\n",
      "\n",
      " Cycle 82 29\n",
      "Took to collect: 8.180612564086914\n",
      "Took to train: 6.367875576019287\n",
      "\n",
      " Cycle 83 29\n",
      "Took to collect: 7.565155744552612\n",
      "Took to train: 6.407660007476807\n",
      "\n",
      " Cycle 84 29\n",
      "Took to collect: 6.936074256896973\n",
      "Took to train: 6.453585147857666\n",
      "\n",
      " Cycle 85 29\n",
      "Took to collect: 7.975735902786255\n",
      "Took to train: 6.464870452880859\n",
      "\n",
      " Cycle 86 29\n",
      "Took to collect: 6.936905860900879\n",
      "Took to train: 6.4030773639678955\n",
      "\n",
      " Cycle 87 29\n",
      "Took to collect: 9.328227519989014\n",
      "Took to train: 6.487851858139038\n",
      "\n",
      " Cycle 88 29\n",
      "Took to collect: 7.380828142166138\n",
      "Took to train: 6.445688962936401\n",
      "\n",
      " Cycle 89 29\n",
      "Took to collect: 8.692092180252075\n",
      "Took to train: 6.404894828796387\n",
      "\n",
      " Cycle 90 29\n",
      "Took to collect: 7.01490044593811\n",
      "Took to train: 6.360874652862549\n",
      "\n",
      " Cycle 91 29\n",
      "Took to collect: 8.144851207733154\n",
      "Took to train: 6.432426691055298\n",
      "\n",
      " Cycle 92 29\n",
      "Took to collect: 8.796813011169434\n",
      "Took to train: 6.437504053115845\n",
      "\n",
      " Cycle 93 29\n",
      "Took to collect: 7.846050977706909\n",
      "Took to train: 6.300205230712891\n",
      "\n",
      " Cycle 94 29\n",
      "Took to collect: 8.176437377929688\n",
      "Took to train: 6.256306171417236\n",
      "\n",
      " Cycle 95 29\n",
      "Took to collect: 8.03133511543274\n",
      "Took to train: 6.299898147583008\n",
      "\n",
      " Cycle 96 29\n",
      "Took to collect: 8.041720867156982\n",
      "Took to train: 6.300470352172852\n",
      "\n",
      " Cycle 97 29\n",
      "Took to collect: 8.553324222564697\n",
      "Took to train: 6.394063472747803\n",
      "\n",
      " Cycle 98 29\n",
      "Took to collect: 8.721421480178833\n",
      "Took to train: 6.382375478744507\n",
      "\n",
      " Cycle 99 29\n",
      "Took to collect: 8.187677383422852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.471326589584351\n",
      "Time collect avg cycle: 7.7657772421836855\n",
      "Time train avg cycle: 6.402717144489288\n",
      "Total avg cycle: 14.17873672246933\n",
      "Ending epoch\n",
      "2020-10-26 09:21:41.576168 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 29 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    1.039\n",
      "trainer/QF2 Loss                                    0.83383\n",
      "trainer/Policy Loss                                44.2046\n",
      "trainer/Q1 Predictions Mean                       -44.2672\n",
      "trainer/Q1 Predictions Std                         37.0813\n",
      "trainer/Q1 Predictions Max                          6.04333\n",
      "trainer/Q1 Predictions Min                       -105.601\n",
      "trainer/Q2 Predictions Mean                       -44.2172\n",
      "trainer/Q2 Predictions Std                         37.0537\n",
      "trainer/Q2 Predictions Max                          5.91066\n",
      "trainer/Q2 Predictions Min                       -105.433\n",
      "trainer/Q Targets Mean                            -44.1689\n",
      "trainer/Q Targets Std                              37.1104\n",
      "trainer/Q Targets Max                               6.04258\n",
      "trainer/Q Targets Min                            -105.481\n",
      "trainer/Log Pis Mean                                2.86516\n",
      "trainer/Log Pis Std                                 2.19284\n",
      "trainer/Log Pis Max                                 9.38602\n",
      "trainer/Log Pis Min                                -3.05546\n",
      "trainer/policy/mean Mean                           -0.276186\n",
      "trainer/policy/mean Std                             0.643432\n",
      "trainer/policy/mean Max                             0.993108\n",
      "trainer/policy/mean Min                            -0.994577\n",
      "trainer/policy/normal/std Mean                      0.381935\n",
      "trainer/policy/normal/std Std                       0.235843\n",
      "trainer/policy/normal/std Max                       1.45033\n",
      "trainer/policy/normal/std Min                       0.0453597\n",
      "trainer/policy/normal/log_std Mean                 -1.18528\n",
      "trainer/policy/normal/log_std Std                   0.713639\n",
      "trainer/policy/normal/log_std Max                   0.371791\n",
      "trainer/policy/normal/log_std Min                  -3.09313\n",
      "trainer/Alpha                                       0.0104732\n",
      "trainer/Alpha Loss                                 -0.614733\n",
      "exploration/num steps total                    301000\n",
      "exploration/num paths total                      6045\n",
      "exploration/path length Mean                       50\n",
      "exploration/path length Std                         0\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        50\n",
      "exploration/Rewards Mean                           -0.9996\n",
      "exploration/Rewards Std                             0.019996\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.98\n",
      "exploration/Returns Std                             0.222711\n",
      "exploration/Returns Max                           -47\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.337796\n",
      "exploration/Actions Std                             0.583053\n",
      "exploration/Actions Max                             0.999291\n",
      "exploration/Actions Min                            -0.99982\n",
      "exploration/Num Paths                             200\n",
      "exploration/Average Returns                       -49.98\n",
      "exploration/env_infos/final/is_success Mean         0\n",
      "exploration/env_infos/final/is_success Std          0\n",
      "exploration/env_infos/final/is_success Max          0\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0\n",
      "exploration/env_infos/is_success Std                0\n",
      "exploration/env_infos/is_success Max                0\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      14890\n",
      "evaluation/num paths total                        301\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.267534\n",
      "evaluation/Actions Std                              0.514217\n",
      "evaluation/Actions Max                              0.987496\n",
      "evaluation/Actions Min                             -0.98376\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.998719\n",
      "time/evaluation sampling (s)                       44.2106\n",
      "time/exploration sampling (s)                     776.597\n",
      "time/logging (s)                                    0.0283727\n",
      "time/sac training (s)                             199.436\n",
      "time/saving (s)                                     0.0142602\n",
      "time/training (s)                                   0.00693207\n",
      "time/epoch (s)                                   1021.29\n",
      "time/total (s)                                  42172.7\n",
      "Epoch                                              29\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 30\n",
      "\n",
      " Cycle 0 30\n",
      "Took to collect: 7.796365261077881\n",
      "Took to train: 6.494429111480713\n",
      "\n",
      " Cycle 1 30\n",
      "Took to collect: 8.543469905853271\n",
      "Took to train: 6.466320753097534\n",
      "\n",
      " Cycle 2 30\n",
      "Took to collect: 9.277247190475464\n",
      "Took to train: 6.465702772140503\n",
      "\n",
      " Cycle 3 30\n",
      "Took to collect: 7.162378549575806\n",
      "Took to train: 6.4726526737213135\n",
      "\n",
      " Cycle 4 30\n",
      "Took to collect: 7.142460107803345\n",
      "Took to train: 6.474352836608887\n",
      "\n",
      " Cycle 5 30\n",
      "Took to collect: 8.30124807357788\n",
      "Took to train: 6.462099075317383\n",
      "\n",
      " Cycle 6 30\n",
      "Took to collect: 6.8043212890625\n",
      "Took to train: 6.4023542404174805\n",
      "\n",
      " Cycle 7 30\n",
      "Took to collect: 8.623724699020386\n",
      "Took to train: 6.410559892654419\n",
      "\n",
      " Cycle 8 30\n",
      "Took to collect: 7.0933778285980225\n",
      "Took to train: 6.411991119384766\n",
      "\n",
      " Cycle 9 30\n",
      "Took to collect: 7.922215223312378\n",
      "Took to train: 6.410710334777832\n",
      "\n",
      " Cycle 10 30\n",
      "Took to collect: 6.707441806793213\n",
      "Took to train: 6.442340135574341\n",
      "\n",
      " Cycle 11 30\n",
      "Took to collect: 8.729427814483643\n",
      "Took to train: 6.448586463928223\n",
      "\n",
      " Cycle 12 30\n",
      "Took to collect: 7.786611557006836\n",
      "Took to train: 6.451461315155029\n",
      "\n",
      " Cycle 13 30\n",
      "Took to collect: 7.438870668411255\n",
      "Took to train: 6.401779890060425\n",
      "\n",
      " Cycle 14 30\n",
      "Took to collect: 7.376622915267944\n",
      "Took to train: 6.308697938919067\n",
      "\n",
      " Cycle 15 30\n",
      "Took to collect: 8.693948030471802\n",
      "Took to train: 6.393317461013794\n",
      "\n",
      " Cycle 16 30\n",
      "Took to collect: 7.8576555252075195\n",
      "Took to train: 6.3703577518463135\n",
      "\n",
      " Cycle 17 30\n",
      "Took to collect: 6.60264253616333\n",
      "Took to train: 6.296125650405884\n",
      "\n",
      " Cycle 18 30\n",
      "Took to collect: 7.303307294845581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.293382883071899\n",
      "\n",
      " Cycle 19 30\n",
      "Took to collect: 7.83220362663269\n",
      "Took to train: 6.3585357666015625\n",
      "\n",
      " Cycle 20 30\n",
      "Took to collect: 8.093209981918335\n",
      "Took to train: 6.463454008102417\n",
      "\n",
      " Cycle 21 30\n",
      "Took to collect: 6.950267791748047\n",
      "Took to train: 6.41548228263855\n",
      "\n",
      " Cycle 22 30\n",
      "Took to collect: 8.048603296279907\n",
      "Took to train: 6.397816181182861\n",
      "\n",
      " Cycle 23 30\n",
      "Took to collect: 7.903846979141235\n",
      "Took to train: 6.42973780632019\n",
      "\n",
      " Cycle 24 30\n",
      "Took to collect: 8.479708909988403\n",
      "Took to train: 6.469173431396484\n",
      "\n",
      " Cycle 25 30\n",
      "Took to collect: 7.320494651794434\n",
      "Took to train: 6.426265478134155\n",
      "\n",
      " Cycle 26 30\n",
      "Took to collect: 7.263582468032837\n",
      "Took to train: 6.311620473861694\n",
      "\n",
      " Cycle 27 30\n",
      "Took to collect: 7.566973924636841\n",
      "Took to train: 6.274041414260864\n",
      "\n",
      " Cycle 28 30\n",
      "Took to collect: 9.369901895523071\n",
      "Took to train: 6.364362716674805\n",
      "\n",
      " Cycle 29 30\n",
      "Took to collect: 7.595022439956665\n",
      "Took to train: 6.425376653671265\n",
      "\n",
      " Cycle 30 30\n",
      "Took to collect: 9.169763803482056\n",
      "Took to train: 6.3908820152282715\n",
      "\n",
      " Cycle 31 30\n",
      "Took to collect: 6.913351774215698\n",
      "Took to train: 6.399968385696411\n",
      "\n",
      " Cycle 32 30\n",
      "Took to collect: 8.194165229797363\n",
      "Took to train: 6.388566255569458\n",
      "\n",
      " Cycle 33 30\n",
      "Took to collect: 7.915957450866699\n",
      "Took to train: 6.43456506729126\n",
      "\n",
      " Cycle 34 30\n",
      "Took to collect: 8.211212873458862\n",
      "Took to train: 6.456852674484253\n",
      "\n",
      " Cycle 35 30\n",
      "Took to collect: 7.882615327835083\n",
      "Took to train: 6.455376148223877\n",
      "\n",
      " Cycle 36 30\n",
      "Took to collect: 8.28640365600586\n",
      "Took to train: 6.436042308807373\n",
      "\n",
      " Cycle 37 30\n",
      "Took to collect: 8.884461641311646\n",
      "Took to train: 6.448312044143677\n",
      "\n",
      " Cycle 38 30\n",
      "Took to collect: 6.987177133560181\n",
      "Took to train: 6.443137168884277\n",
      "\n",
      " Cycle 39 30\n",
      "Took to collect: 8.20334243774414\n",
      "Took to train: 6.456210613250732\n",
      "\n",
      " Cycle 40 30\n",
      "Took to collect: 7.157067775726318\n",
      "Took to train: 6.441608905792236\n",
      "\n",
      " Cycle 41 30\n",
      "Took to collect: 7.575560569763184\n",
      "Took to train: 6.43899393081665\n",
      "\n",
      " Cycle 42 30\n",
      "Took to collect: 7.367838382720947\n",
      "Took to train: 6.443284749984741\n",
      "\n",
      " Cycle 43 30\n",
      "Took to collect: 8.21397614479065\n",
      "Took to train: 6.452625036239624\n",
      "\n",
      " Cycle 44 30\n",
      "Took to collect: 8.39802074432373\n",
      "Took to train: 6.427109718322754\n",
      "\n",
      " Cycle 45 30\n",
      "Took to collect: 8.320904016494751\n",
      "Took to train: 6.410338878631592\n",
      "\n",
      " Cycle 46 30\n",
      "Took to collect: 9.174553632736206\n",
      "Took to train: 6.4040632247924805\n",
      "\n",
      " Cycle 47 30\n",
      "Took to collect: 8.265992879867554\n",
      "Took to train: 6.401325702667236\n",
      "\n",
      " Cycle 48 30\n",
      "Took to collect: 8.361541271209717\n",
      "Took to train: 6.427021503448486\n",
      "\n",
      " Cycle 49 30\n",
      "Took to collect: 8.313919305801392\n",
      "Took to train: 6.459644794464111\n",
      "\n",
      " Cycle 50 30\n",
      "Took to collect: 8.78517746925354\n",
      "Took to train: 6.456915616989136\n",
      "\n",
      " Cycle 51 30\n",
      "Took to collect: 7.466184377670288\n",
      "Took to train: 6.457294940948486\n",
      "\n",
      " Cycle 52 30\n",
      "Took to collect: 8.8276686668396\n",
      "Took to train: 6.401412010192871\n",
      "\n",
      " Cycle 53 30\n",
      "Took to collect: 8.224680423736572\n",
      "Took to train: 6.335720777511597\n",
      "\n",
      " Cycle 54 30\n",
      "Took to collect: 9.387609243392944\n",
      "Took to train: 6.274200677871704\n",
      "\n",
      " Cycle 55 30\n",
      "Took to collect: 8.409335851669312\n",
      "Took to train: 6.32612943649292\n",
      "\n",
      " Cycle 56 30\n",
      "Took to collect: 8.824726104736328\n",
      "Took to train: 6.425990581512451\n",
      "\n",
      " Cycle 57 30\n",
      "Took to collect: 8.036561965942383\n",
      "Took to train: 6.396588087081909\n",
      "\n",
      " Cycle 58 30\n",
      "Took to collect: 8.643362045288086\n",
      "Took to train: 6.39999532699585\n",
      "\n",
      " Cycle 59 30\n",
      "Took to collect: 9.080563306808472\n",
      "Took to train: 6.442385196685791\n",
      "\n",
      " Cycle 60 30\n",
      "Took to collect: 6.429115295410156\n",
      "Took to train: 6.453821182250977\n",
      "\n",
      " Cycle 61 30\n",
      "Took to collect: 7.547150135040283\n",
      "Took to train: 6.397999286651611\n",
      "\n",
      " Cycle 62 30\n",
      "Took to collect: 7.681633949279785\n",
      "Took to train: 6.274377107620239\n",
      "\n",
      " Cycle 63 30\n",
      "Took to collect: 9.03309178352356\n",
      "Took to train: 6.480229377746582\n",
      "\n",
      " Cycle 64 30\n",
      "Took to collect: 7.849952220916748\n",
      "Took to train: 6.529438018798828\n",
      "\n",
      " Cycle 65 30\n",
      "Took to collect: 7.170176982879639\n",
      "Took to train: 6.525256395339966\n",
      "\n",
      " Cycle 66 30\n",
      "Took to collect: 7.340278625488281\n",
      "Took to train: 6.423133611679077\n",
      "\n",
      " Cycle 67 30\n",
      "Took to collect: 6.476359844207764\n",
      "Took to train: 6.5234668254852295\n",
      "\n",
      " Cycle 68 30\n",
      "Took to collect: 6.949612617492676\n",
      "Took to train: 6.51751184463501\n",
      "\n",
      " Cycle 69 30\n",
      "Took to collect: 7.736222267150879\n",
      "Took to train: 6.535653591156006\n",
      "\n",
      " Cycle 70 30\n",
      "Took to collect: 9.330225467681885\n",
      "Took to train: 6.4792704582214355\n",
      "\n",
      " Cycle 71 30\n",
      "Took to collect: 8.001714706420898\n",
      "Took to train: 6.442128419876099\n",
      "\n",
      " Cycle 72 30\n",
      "Took to collect: 8.230184316635132\n",
      "Took to train: 6.443150043487549\n",
      "\n",
      " Cycle 73 30\n",
      "Took to collect: 7.149190902709961\n",
      "Took to train: 6.427632093429565\n",
      "\n",
      " Cycle 74 30\n",
      "Took to collect: 6.2401509284973145\n",
      "Took to train: 6.435670375823975\n",
      "\n",
      " Cycle 75 30\n",
      "Took to collect: 9.68225383758545\n",
      "Took to train: 6.5004565715789795\n",
      "\n",
      " Cycle 76 30\n",
      "Took to collect: 5.298307418823242\n",
      "Took to train: 6.512889385223389\n",
      "\n",
      " Cycle 77 30\n",
      "Took to collect: 6.819547653198242\n",
      "Took to train: 6.450162887573242\n",
      "\n",
      " Cycle 78 30\n",
      "Took to collect: 6.792769908905029\n",
      "Took to train: 6.443197011947632\n",
      "\n",
      " Cycle 79 30\n",
      "Took to collect: 7.144755601882935\n",
      "Took to train: 6.4752161502838135\n",
      "\n",
      " Cycle 80 30\n",
      "Took to collect: 7.87911057472229\n",
      "Took to train: 6.527190923690796\n",
      "\n",
      " Cycle 81 30\n",
      "Took to collect: 9.600517988204956\n",
      "Took to train: 6.475494623184204\n",
      "\n",
      " Cycle 82 30\n",
      "Took to collect: 7.733490228652954\n",
      "Took to train: 6.497471570968628\n",
      "\n",
      " Cycle 83 30\n",
      "Took to collect: 8.094414949417114\n",
      "Took to train: 6.422650337219238\n",
      "\n",
      " Cycle 84 30\n",
      "Took to collect: 8.156949996948242\n",
      "Took to train: 6.32517409324646\n",
      "\n",
      " Cycle 85 30\n",
      "Took to collect: 7.319528102874756\n",
      "Took to train: 6.301658630371094\n",
      "\n",
      " Cycle 86 30\n",
      "Took to collect: 7.8656697273254395\n",
      "Took to train: 6.359532356262207\n",
      "\n",
      " Cycle 87 30\n",
      "Took to collect: 7.157238245010376\n",
      "Took to train: 6.512235879898071\n",
      "\n",
      " Cycle 88 30\n",
      "Took to collect: 8.403889656066895\n",
      "Took to train: 6.459809064865112\n",
      "\n",
      " Cycle 89 30\n",
      "Took to collect: 9.45888090133667\n",
      "Took to train: 6.4944751262664795\n",
      "\n",
      " Cycle 90 30\n",
      "Took to collect: 8.043632984161377\n",
      "Took to train: 6.471978664398193\n",
      "\n",
      " Cycle 91 30\n",
      "Took to collect: 8.106020450592041\n",
      "Took to train: 6.469291687011719\n",
      "\n",
      " Cycle 92 30\n",
      "Took to collect: 6.516129493713379\n",
      "Took to train: 6.442403793334961\n",
      "\n",
      " Cycle 93 30\n",
      "Took to collect: 7.752992630004883\n",
      "Took to train: 6.381837606430054\n",
      "\n",
      " Cycle 94 30\n",
      "Took to collect: 7.358462333679199\n",
      "Took to train: 6.503076076507568\n",
      "\n",
      " Cycle 95 30\n",
      "Took to collect: 6.976226568222046\n",
      "Took to train: 6.455526351928711\n",
      "\n",
      " Cycle 96 30\n",
      "Took to collect: 6.82992696762085\n",
      "Took to train: 6.442739248275757\n",
      "\n",
      " Cycle 97 30\n",
      "Took to collect: 8.844795227050781\n",
      "Took to train: 6.566956520080566\n",
      "\n",
      " Cycle 98 30\n",
      "Took to collect: 7.8598644733428955\n",
      "Took to train: 6.667677879333496\n",
      "\n",
      " Cycle 99 30\n",
      "Took to collect: 7.575634717941284\n",
      "Took to train: 6.7796571254730225\n",
      "Time collect avg cycle: 7.875069184303284\n",
      "Time train avg cycle: 6.435731484889984\n",
      "Total avg cycle: 14.320992736816406\n",
      "Ending epoch\n",
      "2020-10-26 09:46:15.920373 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 30 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.868173\n",
      "trainer/QF2 Loss                                    0.62664\n",
      "trainer/Policy Loss                                46.7988\n",
      "trainer/Q1 Predictions Mean                       -46.9439\n",
      "trainer/Q1 Predictions Std                         35.4281\n",
      "trainer/Q1 Predictions Max                          3.81486\n",
      "trainer/Q1 Predictions Min                       -105.153\n",
      "trainer/Q2 Predictions Mean                       -46.608\n",
      "trainer/Q2 Predictions Std                         35.5497\n",
      "trainer/Q2 Predictions Max                          4.54141\n",
      "trainer/Q2 Predictions Min                       -105.238\n",
      "trainer/Q Targets Mean                            -46.8657\n",
      "trainer/Q Targets Std                              35.4393\n",
      "trainer/Q Targets Max                               3.79695\n",
      "trainer/Q Targets Min                            -105.318\n",
      "trainer/Log Pis Mean                                3.26026\n",
      "trainer/Log Pis Std                                 2.5183\n",
      "trainer/Log Pis Max                                10.7866\n",
      "trainer/Log Pis Min                                -3.99428\n",
      "trainer/policy/mean Mean                           -0.346067\n",
      "trainer/policy/mean Std                             0.629185\n",
      "trainer/policy/mean Max                             0.99605\n",
      "trainer/policy/mean Min                            -0.994019\n",
      "trainer/policy/normal/std Mean                      0.399759\n",
      "trainer/policy/normal/std Std                       0.252393\n",
      "trainer/policy/normal/std Max                       1.3316\n",
      "trainer/policy/normal/std Min                       0.0367764\n",
      "trainer/policy/normal/log_std Mean                 -1.16438\n",
      "trainer/policy/normal/log_std Std                   0.77129\n",
      "trainer/policy/normal/log_std Max                   0.286381\n",
      "trainer/policy/normal/log_std Min                  -3.3029\n",
      "trainer/Alpha                                       0.0102679\n",
      "trainer/Alpha Loss                                  1.19168\n",
      "exploration/num steps total                    311000\n",
      "exploration/num paths total                      6245\n",
      "exploration/path length Mean                       50\n",
      "exploration/path length Std                         0\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        50\n",
      "exploration/Rewards Mean                           -0.9951\n",
      "exploration/Rewards Std                             0.0698283\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.755\n",
      "exploration/Returns Std                             2.21246\n",
      "exploration/Returns Max                           -20\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.260882\n",
      "exploration/Actions Std                             0.598525\n",
      "exploration/Actions Max                             0.999501\n",
      "exploration/Actions Min                            -0.999886\n",
      "exploration/Num Paths                             200\n",
      "exploration/Average Returns                       -49.755\n",
      "exploration/env_infos/final/is_success Mean         0\n",
      "exploration/env_infos/final/is_success Std          0\n",
      "exploration/env_infos/final/is_success Max          0\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0\n",
      "exploration/env_infos/is_success Std                0\n",
      "exploration/env_infos/is_success Max                0\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      15390\n",
      "evaluation/num paths total                        311\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.218476\n",
      "evaluation/Actions Std                              0.446433\n",
      "evaluation/Actions Max                              0.985126\n",
      "evaluation/Actions Min                             -0.990394\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.993248\n",
      "time/evaluation sampling (s)                       42.1793\n",
      "time/exploration sampling (s)                     787.527\n",
      "time/logging (s)                                    0.037606\n",
      "time/sac training (s)                             200.076\n",
      "time/saving (s)                                     0.0158952\n",
      "time/training (s)                                   0.00709953\n",
      "time/epoch (s)                                   1030.84\n",
      "time/total (s)                                  43646.9\n",
      "Epoch                                              30\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 31\n",
      "\n",
      " Cycle 0 31\n",
      "Took to collect: 9.485187530517578\n",
      "Took to train: 6.515171051025391\n",
      "\n",
      " Cycle 1 31\n",
      "Took to collect: 7.154819011688232\n",
      "Took to train: 6.41631817817688\n",
      "\n",
      " Cycle 2 31\n",
      "Took to collect: 8.597981929779053\n",
      "Took to train: 6.48395299911499\n",
      "\n",
      " Cycle 3 31\n",
      "Took to collect: 8.046268224716187\n",
      "Took to train: 6.487720727920532\n",
      "\n",
      " Cycle 4 31\n",
      "Took to collect: 7.311661243438721\n",
      "Took to train: 6.537926435470581\n",
      "\n",
      " Cycle 5 31\n",
      "Took to collect: 8.388993978500366\n",
      "Took to train: 6.5241570472717285\n",
      "\n",
      " Cycle 6 31\n",
      "Took to collect: 6.423563480377197\n",
      "Took to train: 6.550684928894043\n",
      "\n",
      " Cycle 7 31\n",
      "Took to collect: 8.634202480316162\n",
      "Took to train: 6.530720949172974\n",
      "\n",
      " Cycle 8 31\n",
      "Took to collect: 7.60315203666687\n",
      "Took to train: 6.561819076538086\n",
      "\n",
      " Cycle 9 31\n",
      "Took to collect: 9.317949056625366\n",
      "Took to train: 6.5352678298950195\n",
      "\n",
      " Cycle 10 31\n",
      "Took to collect: 6.898940324783325\n",
      "Took to train: 6.481703281402588\n",
      "\n",
      " Cycle 11 31\n",
      "Took to collect: 8.266104459762573\n",
      "Took to train: 6.498281002044678\n",
      "\n",
      " Cycle 12 31\n",
      "Took to collect: 8.249913692474365\n",
      "Took to train: 6.545464992523193\n",
      "\n",
      " Cycle 13 31\n",
      "Took to collect: 7.656010389328003\n",
      "Took to train: 6.526153087615967\n",
      "\n",
      " Cycle 14 31\n",
      "Took to collect: 8.385274648666382\n",
      "Took to train: 6.549464225769043\n",
      "\n",
      " Cycle 15 31\n",
      "Took to collect: 7.341501951217651\n",
      "Took to train: 6.5460193157196045\n",
      "\n",
      " Cycle 16 31\n",
      "Took to collect: 8.626217365264893\n",
      "Took to train: 6.537008285522461\n",
      "\n",
      " Cycle 17 31\n",
      "Took to collect: 9.975862741470337\n",
      "Took to train: 6.507451772689819\n",
      "\n",
      " Cycle 18 31\n",
      "Took to collect: 6.651661396026611\n",
      "Took to train: 6.530707120895386\n",
      "\n",
      " Cycle 19 31\n",
      "Took to collect: 7.53577733039856\n",
      "Took to train: 6.487903833389282\n",
      "\n",
      " Cycle 20 31\n",
      "Took to collect: 6.406454563140869\n",
      "Took to train: 6.527292013168335\n",
      "\n",
      " Cycle 21 31\n",
      "Took to collect: 8.137084007263184\n",
      "Took to train: 6.4913716316223145\n",
      "\n",
      " Cycle 22 31\n",
      "Took to collect: 8.75910472869873\n",
      "Took to train: 6.482323169708252\n",
      "\n",
      " Cycle 23 31\n",
      "Took to collect: 8.610689163208008\n",
      "Took to train: 6.5407445430755615\n",
      "\n",
      " Cycle 24 31\n",
      "Took to collect: 8.834840059280396\n",
      "Took to train: 6.518097639083862\n",
      "\n",
      " Cycle 25 31\n",
      "Took to collect: 8.305340766906738\n",
      "Took to train: 6.534180402755737\n",
      "\n",
      " Cycle 26 31\n",
      "Took to collect: 8.602769613265991\n",
      "Took to train: 6.465188264846802\n",
      "\n",
      " Cycle 27 31\n",
      "Took to collect: 7.715252876281738\n",
      "Took to train: 6.450592279434204\n",
      "\n",
      " Cycle 28 31\n",
      "Took to collect: 7.095570087432861\n",
      "Took to train: 6.490449666976929\n",
      "\n",
      " Cycle 29 31\n",
      "Took to collect: 10.62278413772583\n",
      "Took to train: 6.474286317825317\n",
      "\n",
      " Cycle 30 31\n",
      "Took to collect: 9.028000354766846\n",
      "Took to train: 6.473225116729736\n",
      "\n",
      " Cycle 31 31\n",
      "Took to collect: 6.553636312484741\n",
      "Took to train: 6.461366176605225\n",
      "\n",
      " Cycle 32 31\n",
      "Took to collect: 7.659465312957764\n",
      "Took to train: 6.4656291007995605\n",
      "\n",
      " Cycle 33 31\n",
      "Took to collect: 7.550288677215576\n",
      "Took to train: 6.480316400527954\n",
      "\n",
      " Cycle 34 31\n",
      "Took to collect: 8.280359506607056\n",
      "Took to train: 6.478588104248047\n",
      "\n",
      " Cycle 35 31\n",
      "Took to collect: 8.182543992996216\n",
      "Took to train: 6.462411880493164\n",
      "\n",
      " Cycle 36 31\n",
      "Took to collect: 7.33203125\n",
      "Took to train: 6.435368537902832\n",
      "\n",
      " Cycle 37 31\n",
      "Took to collect: 8.401186466217041\n",
      "Took to train: 6.459913969039917\n",
      "\n",
      " Cycle 38 31\n",
      "Took to collect: 8.029756546020508\n",
      "Took to train: 6.525311231613159\n",
      "\n",
      " Cycle 39 31\n",
      "Took to collect: 8.183686971664429\n",
      "Took to train: 6.549258232116699\n",
      "\n",
      " Cycle 40 31\n",
      "Took to collect: 8.768141508102417\n",
      "Took to train: 6.531828165054321\n",
      "\n",
      " Cycle 41 31\n",
      "Took to collect: 7.891080379486084\n",
      "Took to train: 6.540601015090942\n",
      "\n",
      " Cycle 42 31\n",
      "Took to collect: 6.892646551132202\n",
      "Took to train: 6.4465343952178955\n",
      "\n",
      " Cycle 43 31\n",
      "Took to collect: 7.867794513702393\n",
      "Took to train: 6.3529815673828125\n",
      "\n",
      " Cycle 44 31\n",
      "Took to collect: 6.53885555267334\n",
      "Took to train: 6.4753594398498535\n",
      "\n",
      " Cycle 45 31\n",
      "Took to collect: 8.16811490058899\n",
      "Took to train: 6.509231090545654\n",
      "\n",
      " Cycle 46 31\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 9.73188853263855\n",
      "Took to train: 6.441156387329102\n",
      "\n",
      " Cycle 47 31\n",
      "Took to collect: 7.356940031051636\n",
      "Took to train: 6.495645999908447\n",
      "\n",
      " Cycle 48 31\n",
      "Took to collect: 8.243778228759766\n",
      "Took to train: 6.5163962841033936\n",
      "\n",
      " Cycle 49 31\n",
      "Took to collect: 7.221435308456421\n",
      "Took to train: 6.548324346542358\n",
      "\n",
      " Cycle 50 31\n",
      "Took to collect: 6.99946928024292\n",
      "Took to train: 6.391989231109619\n",
      "\n",
      " Cycle 51 31\n",
      "Took to collect: 6.971308708190918\n",
      "Took to train: 6.49452018737793\n",
      "\n",
      " Cycle 52 31\n",
      "Took to collect: 9.009837865829468\n",
      "Took to train: 6.510474443435669\n",
      "\n",
      " Cycle 53 31\n",
      "Took to collect: 8.369007349014282\n",
      "Took to train: 6.5229926109313965\n",
      "\n",
      " Cycle 54 31\n",
      "Took to collect: 8.504507064819336\n",
      "Took to train: 6.505799770355225\n",
      "\n",
      " Cycle 55 31\n",
      "Took to collect: 8.838478326797485\n",
      "Took to train: 6.4401695728302\n",
      "\n",
      " Cycle 56 31\n",
      "Took to collect: 6.882079362869263\n",
      "Took to train: 6.504416465759277\n",
      "\n",
      " Cycle 57 31\n",
      "Took to collect: 7.136613130569458\n",
      "Took to train: 6.473367929458618\n",
      "\n",
      " Cycle 58 31\n",
      "Took to collect: 8.57452917098999\n",
      "Took to train: 6.420344829559326\n",
      "\n",
      " Cycle 59 31\n",
      "Took to collect: 9.020374536514282\n",
      "Took to train: 6.491621017456055\n",
      "\n",
      " Cycle 60 31\n",
      "Took to collect: 6.9979681968688965\n",
      "Took to train: 6.423418283462524\n",
      "\n",
      " Cycle 61 31\n",
      "Took to collect: 8.674153566360474\n",
      "Took to train: 6.290182113647461\n",
      "\n",
      " Cycle 62 31\n",
      "Took to collect: 8.270688533782959\n",
      "Took to train: 6.383381605148315\n",
      "\n",
      " Cycle 63 31\n",
      "Took to collect: 6.158076524734497\n",
      "Took to train: 6.388254642486572\n",
      "\n",
      " Cycle 64 31\n",
      "Took to collect: 6.958422899246216\n",
      "Took to train: 6.358715534210205\n",
      "\n",
      " Cycle 65 31\n",
      "Took to collect: 6.872225046157837\n",
      "Took to train: 6.352693557739258\n",
      "\n",
      " Cycle 66 31\n",
      "Took to collect: 7.973003625869751\n",
      "Took to train: 6.358713865280151\n",
      "\n",
      " Cycle 67 31\n",
      "Took to collect: 8.03274130821228\n",
      "Took to train: 6.347196102142334\n",
      "\n",
      " Cycle 68 31\n",
      "Took to collect: 7.943616151809692\n",
      "Took to train: 6.35161018371582\n",
      "\n",
      " Cycle 69 31\n",
      "Took to collect: 8.286783933639526\n",
      "Took to train: 6.483974933624268\n",
      "\n",
      " Cycle 70 31\n",
      "Took to collect: 8.736772775650024\n",
      "Took to train: 6.423352956771851\n",
      "\n",
      " Cycle 71 31\n",
      "Took to collect: 7.520701169967651\n",
      "Took to train: 6.396880388259888\n",
      "\n",
      " Cycle 72 31\n",
      "Took to collect: 7.40592360496521\n",
      "Took to train: 6.539386034011841\n",
      "\n",
      " Cycle 73 31\n",
      "Took to collect: 7.521631240844727\n",
      "Took to train: 6.519215822219849\n",
      "\n",
      " Cycle 74 31\n",
      "Took to collect: 8.626740217208862\n",
      "Took to train: 6.377514123916626\n",
      "\n",
      " Cycle 75 31\n",
      "Took to collect: 7.7505152225494385\n",
      "Took to train: 6.401463508605957\n",
      "\n",
      " Cycle 76 31\n",
      "Took to collect: 8.410620927810669\n",
      "Took to train: 6.422328948974609\n",
      "\n",
      " Cycle 77 31\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.159484386444092\n",
      "Took to train: 6.528795003890991\n",
      "\n",
      " Cycle 78 31\n",
      "Took to collect: 7.556963205337524\n",
      "Took to train: 6.559213161468506\n",
      "\n",
      " Cycle 79 31\n",
      "Took to collect: 8.549683570861816\n",
      "Took to train: 6.445132732391357\n",
      "\n",
      " Cycle 80 31\n",
      "Took to collect: 7.603347301483154\n",
      "Took to train: 6.3281638622283936\n",
      "\n",
      " Cycle 81 31\n",
      "Took to collect: 7.848560094833374\n",
      "Took to train: 6.395029544830322\n",
      "\n",
      " Cycle 82 31\n",
      "Took to collect: 6.720468997955322\n",
      "Took to train: 6.404918432235718\n",
      "\n",
      " Cycle 83 31\n",
      "Took to collect: 8.456660985946655\n",
      "Took to train: 6.403335809707642\n",
      "\n",
      " Cycle 84 31\n",
      "Took to collect: 8.737542629241943\n",
      "Took to train: 6.406815528869629\n",
      "\n",
      " Cycle 85 31\n",
      "Took to collect: 8.108621835708618\n",
      "Took to train: 6.408071994781494\n",
      "\n",
      " Cycle 86 31\n",
      "Took to collect: 7.854464054107666\n",
      "Took to train: 6.4181506633758545\n",
      "\n",
      " Cycle 87 31\n",
      "Took to collect: 7.134077548980713\n",
      "Took to train: 6.46519660949707\n",
      "\n",
      " Cycle 88 31\n",
      "Took to collect: 7.901659727096558\n",
      "Took to train: 6.39242148399353\n",
      "\n",
      " Cycle 89 31\n",
      "Took to collect: 7.4711809158325195\n",
      "Took to train: 6.258007287979126\n",
      "\n",
      " Cycle 90 31\n",
      "Took to collect: 7.528853893280029\n",
      "Took to train: 6.238990545272827\n",
      "\n",
      " Cycle 91 31\n",
      "Took to collect: 7.270813703536987\n",
      "Took to train: 6.234548807144165\n",
      "\n",
      " Cycle 92 31\n",
      "Took to collect: 7.8587071895599365\n",
      "Took to train: 6.2275002002716064\n",
      "\n",
      " Cycle 93 31\n",
      "Took to collect: 8.308258771896362\n",
      "Took to train: 6.298027515411377\n",
      "\n",
      " Cycle 94 31\n",
      "Took to collect: 8.067830562591553\n",
      "Took to train: 6.325648546218872\n",
      "\n",
      " Cycle 95 31\n",
      "Took to collect: 7.652781248092651\n",
      "Took to train: 6.417733907699585\n",
      "\n",
      " Cycle 96 31\n",
      "Took to collect: 9.05783486366272\n",
      "Took to train: 6.558313369750977\n",
      "\n",
      " Cycle 97 31\n",
      "Took to collect: 8.285874843597412\n",
      "Took to train: 6.62609076499939\n",
      "\n",
      " Cycle 98 31\n",
      "Took to collect: 7.974943399429321\n",
      "Took to train: 6.669273376464844\n",
      "\n",
      " Cycle 99 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to collect: 7.995142936706543\n",
      "Took to train: 6.692602157592773\n",
      "Time collect avg cycle: 7.950731105804444\n",
      "Time train avg cycle: 6.462538294792175\n",
      "Total avg cycle: 14.423476812839509\n",
      "Ending epoch\n",
      "2020-10-26 10:10:57.606903 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 31 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.764513\n",
      "trainer/QF2 Loss                                    0.738402\n",
      "trainer/Policy Loss                                46.8154\n",
      "trainer/Q1 Predictions Mean                       -46.7147\n",
      "trainer/Q1 Predictions Std                         34.3806\n",
      "trainer/Q1 Predictions Max                          3.86538\n",
      "trainer/Q1 Predictions Min                       -106.055\n",
      "trainer/Q2 Predictions Mean                       -46.9582\n",
      "trainer/Q2 Predictions Std                         34.3294\n",
      "trainer/Q2 Predictions Max                          3.53655\n",
      "trainer/Q2 Predictions Min                       -106.101\n",
      "trainer/Q Targets Mean                            -46.7676\n",
      "trainer/Q Targets Std                              34.3729\n",
      "trainer/Q Targets Max                               3.48166\n",
      "trainer/Q Targets Min                            -105.643\n",
      "trainer/Log Pis Mean                                2.89009\n",
      "trainer/Log Pis Std                                 2.20661\n",
      "trainer/Log Pis Max                                 8.11114\n",
      "trainer/Log Pis Min                                -6.1039\n",
      "trainer/policy/mean Mean                           -0.327439\n",
      "trainer/policy/mean Std                             0.612112\n",
      "trainer/policy/mean Max                             0.995021\n",
      "trainer/policy/mean Min                            -0.994429\n",
      "trainer/policy/normal/std Mean                      0.385709\n",
      "trainer/policy/normal/std Std                       0.237962\n",
      "trainer/policy/normal/std Max                       1.40403\n",
      "trainer/policy/normal/std Min                       0.0313796\n",
      "trainer/policy/normal/log_std Mean                 -1.20028\n",
      "trainer/policy/normal/log_std Std                   0.778327\n",
      "trainer/policy/normal/log_std Max                   0.339348\n",
      "trainer/policy/normal/log_std Min                  -3.4616\n",
      "trainer/Alpha                                       0.0106788\n",
      "trainer/Alpha Loss                                 -0.498922\n",
      "exploration/num steps total                    321000\n",
      "exploration/num paths total                      6447\n",
      "exploration/path length Mean                       49.505\n",
      "exploration/path length Std                         3.88351\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         8\n",
      "exploration/Rewards Mean                           -0.9994\n",
      "exploration/Rewards Std                             0.0244875\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.4752\n",
      "exploration/Returns Std                             3.96543\n",
      "exploration/Returns Max                            -7\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.278555\n",
      "exploration/Actions Std                             0.582717\n",
      "exploration/Actions Max                             0.999792\n",
      "exploration/Actions Min                            -0.999759\n",
      "exploration/Num Paths                             202\n",
      "exploration/Average Returns                       -49.4752\n",
      "exploration/env_infos/final/is_success Mean         0.00990099\n",
      "exploration/env_infos/final/is_success Std          0.0990099\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0002\n",
      "exploration/env_infos/is_success Std                0.0141407\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      15890\n",
      "evaluation/num paths total                        321\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -1\n",
      "evaluation/Rewards Std                              0\n",
      "evaluation/Rewards Max                             -1\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -50\n",
      "evaluation/Returns Std                              0\n",
      "evaluation/Returns Max                            -50\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.321351\n",
      "evaluation/Actions Std                              0.455177\n",
      "evaluation/Actions Max                              0.971308\n",
      "evaluation/Actions Min                             -0.935554\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -50\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.995068\n",
      "time/evaluation sampling (s)                       39.2653\n",
      "time/exploration sampling (s)                     795.093\n",
      "time/logging (s)                                    0.0271764\n",
      "time/sac training (s)                             200.654\n",
      "time/saving (s)                                     0.0144163\n",
      "time/training (s)                                   0.00711682\n",
      "time/epoch (s)                                   1036.06\n",
      "time/total (s)                                  45128.4\n",
      "Epoch                                              31\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 32\n",
      "\n",
      " Cycle 0 32\n",
      "Took to collect: 7.618378162384033\n",
      "Took to train: 6.371999979019165\n",
      "\n",
      " Cycle 1 32\n",
      "Took to collect: 9.186766862869263\n",
      "Took to train: 6.443679571151733\n",
      "\n",
      " Cycle 2 32\n",
      "Took to collect: 8.102242231369019\n",
      "Took to train: 6.54038143157959\n",
      "\n",
      " Cycle 3 32\n",
      "Took to collect: 7.112356662750244\n",
      "Took to train: 6.532766819000244\n",
      "\n",
      " Cycle 4 32\n",
      "Took to collect: 8.054264068603516\n",
      "Took to train: 6.392466068267822\n",
      "\n",
      " Cycle 5 32\n",
      "Took to collect: 7.4980628490448\n",
      "Took to train: 6.390252113342285\n",
      "\n",
      " Cycle 6 32\n",
      "Took to collect: 7.36244010925293\n",
      "Took to train: 6.4937663078308105\n",
      "\n",
      " Cycle 7 32\n",
      "Took to collect: 8.565362215042114\n",
      "Took to train: 6.5060694217681885\n",
      "\n",
      " Cycle 8 32\n",
      "Took to collect: 8.46382451057434\n",
      "Took to train: 6.485596656799316\n",
      "\n",
      " Cycle 9 32\n",
      "Took to collect: 6.998483657836914\n",
      "Took to train: 6.509495496749878\n",
      "\n",
      " Cycle 10 32\n",
      "Took to collect: 8.481345176696777\n",
      "Took to train: 6.479328632354736\n",
      "\n",
      " Cycle 11 32\n",
      "Took to collect: 7.812375068664551\n",
      "Took to train: 6.323259592056274\n",
      "\n",
      " Cycle 12 32\n",
      "Took to collect: 9.454414367675781\n",
      "Took to train: 6.2914698123931885\n",
      "\n",
      " Cycle 13 32\n",
      "Took to collect: 6.88703727722168\n",
      "Took to train: 6.300194025039673\n",
      "\n",
      " Cycle 14 32\n",
      "Took to collect: 8.485534429550171\n",
      "Took to train: 6.29301381111145\n",
      "\n",
      " Cycle 15 32\n",
      "Took to collect: 7.630810499191284\n",
      "Took to train: 6.332327604293823\n",
      "\n",
      " Cycle 16 32\n",
      "Took to collect: 7.931833744049072\n",
      "Took to train: 6.375023603439331\n",
      "\n",
      " Cycle 17 32\n",
      "Took to collect: 8.371544361114502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.4745118618011475\n",
      "\n",
      " Cycle 18 32\n",
      "Took to collect: 9.297932147979736\n",
      "Took to train: 6.469557523727417\n",
      "\n",
      " Cycle 19 32\n",
      "Took to collect: 8.194134950637817\n",
      "Took to train: 6.483316898345947\n",
      "\n",
      " Cycle 20 32\n",
      "Took to collect: 8.166319370269775\n",
      "Took to train: 6.488033056259155\n",
      "\n",
      " Cycle 21 32\n",
      "Took to collect: 8.158948421478271\n",
      "Took to train: 6.481771945953369\n",
      "\n",
      " Cycle 22 32\n",
      "Took to collect: 8.085379362106323\n",
      "Took to train: 6.477275609970093\n",
      "\n",
      " Cycle 23 32\n",
      "Took to collect: 8.0978844165802\n",
      "Took to train: 6.495326519012451\n",
      "\n",
      " Cycle 24 32\n",
      "Took to collect: 8.402179956436157\n",
      "Took to train: 6.4951934814453125\n",
      "\n",
      " Cycle 25 32\n",
      "Took to collect: 9.982718706130981\n",
      "Took to train: 6.434532165527344\n",
      "\n",
      " Cycle 26 32\n",
      "Took to collect: 8.101017475128174\n",
      "Took to train: 6.432300806045532\n",
      "\n",
      " Cycle 27 32\n",
      "Took to collect: 7.155052661895752\n",
      "Took to train: 6.45799994468689\n",
      "\n",
      " Cycle 28 32\n",
      "Took to collect: 7.7089502811431885\n",
      "Took to train: 6.4564337730407715\n",
      "\n",
      " Cycle 29 32\n",
      "Took to collect: 7.494858264923096\n",
      "Took to train: 6.478082180023193\n",
      "\n",
      " Cycle 30 32\n",
      "Took to collect: 9.370649337768555\n",
      "Took to train: 6.471172571182251\n",
      "\n",
      " Cycle 31 32\n",
      "Took to collect: 8.805592060089111\n",
      "Took to train: 6.321556329727173\n",
      "\n",
      " Cycle 32 32\n",
      "Took to collect: 8.820096731185913\n",
      "Took to train: 6.288301944732666\n",
      "\n",
      " Cycle 33 32\n",
      "Took to collect: 8.437422275543213\n",
      "Took to train: 6.449430704116821\n",
      "\n",
      " Cycle 34 32\n",
      "Took to collect: 9.174519300460815\n",
      "Took to train: 7.065803050994873\n",
      "\n",
      " Cycle 35 32\n",
      "Took to collect: 8.618135213851929\n",
      "Took to train: 7.19541335105896\n",
      "\n",
      " Cycle 36 32\n",
      "Took to collect: 8.664577722549438\n",
      "Took to train: 6.580247640609741\n",
      "\n",
      " Cycle 37 32\n",
      "Took to collect: 9.040902614593506\n",
      "Took to train: 6.579894781112671\n",
      "\n",
      " Cycle 38 32\n",
      "Took to collect: 7.877355098724365\n",
      "Took to train: 6.580565929412842\n",
      "\n",
      " Cycle 39 32\n",
      "Took to collect: 8.740177154541016\n",
      "Took to train: 6.565378904342651\n",
      "\n",
      " Cycle 40 32\n",
      "Took to collect: 7.924431800842285\n",
      "Took to train: 6.462777137756348\n",
      "\n",
      " Cycle 41 32\n",
      "Took to collect: 6.414579629898071\n",
      "Took to train: 6.590715646743774\n",
      "\n",
      " Cycle 42 32\n",
      "Took to collect: 8.671440601348877\n",
      "Took to train: 6.560438394546509\n",
      "\n",
      " Cycle 43 32\n",
      "Took to collect: 8.671265125274658\n",
      "Took to train: 6.592992305755615\n",
      "\n",
      " Cycle 44 32\n",
      "Took to collect: 9.156120300292969\n",
      "Took to train: 6.515495300292969\n",
      "\n",
      " Cycle 45 32\n",
      "Took to collect: 9.028145551681519\n",
      "Took to train: 6.466629981994629\n",
      "\n",
      " Cycle 46 32\n",
      "Took to collect: 8.695853233337402\n",
      "Took to train: 6.421551465988159\n",
      "\n",
      " Cycle 47 32\n",
      "Took to collect: 8.208956241607666\n",
      "Took to train: 6.4873456954956055\n",
      "\n",
      " Cycle 48 32\n",
      "Took to collect: 8.644026279449463\n",
      "Took to train: 6.511369705200195\n",
      "\n",
      " Cycle 49 32\n",
      "Took to collect: 9.053498029708862\n",
      "Took to train: 6.4840171337127686\n",
      "\n",
      " Cycle 50 32\n",
      "Took to collect: 9.606460332870483\n",
      "Took to train: 6.476335287094116\n",
      "\n",
      " Cycle 51 32\n",
      "Took to collect: 9.43379259109497\n",
      "Took to train: 6.526740074157715\n",
      "\n",
      " Cycle 52 32\n",
      "Took to collect: 9.464664220809937\n",
      "Took to train: 6.581326007843018\n",
      "\n",
      " Cycle 53 32\n",
      "Took to collect: 9.500663757324219\n",
      "Took to train: 6.557255744934082\n",
      "\n",
      " Cycle 54 32\n",
      "Took to collect: 7.975064516067505\n",
      "Took to train: 6.539295673370361\n",
      "\n",
      " Cycle 55 32\n",
      "Took to collect: 7.599959373474121\n",
      "Took to train: 6.380461931228638\n",
      "\n",
      " Cycle 56 32\n",
      "Took to collect: 7.3336217403411865\n",
      "Took to train: 6.44246244430542\n",
      "\n",
      " Cycle 57 32\n",
      "Took to collect: 8.775244951248169\n",
      "Took to train: 6.2777369022369385\n",
      "\n",
      " Cycle 58 32\n",
      "Took to collect: 8.771608352661133\n",
      "Took to train: 6.34219217300415\n",
      "\n",
      " Cycle 59 32\n",
      "Took to collect: 9.269262790679932\n",
      "Took to train: 6.391826152801514\n",
      "\n",
      " Cycle 60 32\n",
      "Took to collect: 8.365885734558105\n",
      "Took to train: 6.456834316253662\n",
      "\n",
      " Cycle 61 32\n",
      "Took to collect: 8.01091480255127\n",
      "Took to train: 6.507390737533569\n",
      "\n",
      " Cycle 62 32\n",
      "Took to collect: 7.154338598251343\n",
      "Took to train: 6.4775612354278564\n",
      "\n",
      " Cycle 63 32\n",
      "Took to collect: 8.52023983001709\n",
      "Took to train: 6.469686985015869\n",
      "\n",
      " Cycle 64 32\n",
      "Took to collect: 7.554511308670044\n",
      "Took to train: 6.481599807739258\n",
      "\n",
      " Cycle 65 32\n",
      "Took to collect: 7.333037853240967\n",
      "Took to train: 6.4775121212005615\n",
      "\n",
      " Cycle 66 32\n",
      "Took to collect: 8.71401309967041\n",
      "Took to train: 6.487058162689209\n",
      "\n",
      " Cycle 67 32\n",
      "Took to collect: 6.594796657562256\n",
      "Took to train: 6.450639009475708\n",
      "\n",
      " Cycle 68 32\n",
      "Took to collect: 7.6117517948150635\n",
      "Took to train: 6.387336015701294\n",
      "\n",
      " Cycle 69 32\n",
      "Took to collect: 8.254265069961548\n",
      "Took to train: 6.384476661682129\n",
      "\n",
      " Cycle 70 32\n",
      "Took to collect: 8.190821886062622\n",
      "Took to train: 6.395976305007935\n",
      "\n",
      " Cycle 71 32\n",
      "Took to collect: 8.46186900138855\n",
      "Took to train: 6.507726430892944\n",
      "\n",
      " Cycle 72 32\n",
      "Took to collect: 8.197678565979004\n",
      "Took to train: 6.513903856277466\n",
      "\n",
      " Cycle 73 32\n",
      "Took to collect: 7.76561975479126\n",
      "Took to train: 6.328365087509155\n",
      "\n",
      " Cycle 74 32\n",
      "Took to collect: 6.608225107192993\n",
      "Took to train: 6.425829172134399\n",
      "\n",
      " Cycle 75 32\n",
      "Took to collect: 8.249257802963257\n",
      "Took to train: 6.416327714920044\n",
      "\n",
      " Cycle 76 32\n",
      "Took to collect: 7.964144229888916\n",
      "Took to train: 6.499853610992432\n",
      "\n",
      " Cycle 77 32\n",
      "Took to collect: 8.428234815597534\n",
      "Took to train: 6.513508558273315\n",
      "\n",
      " Cycle 78 32\n",
      "Took to collect: 8.038132905960083\n",
      "Took to train: 6.517012357711792\n",
      "\n",
      " Cycle 79 32\n",
      "Took to collect: 8.442202091217041\n",
      "Took to train: 6.4170403480529785\n",
      "\n",
      " Cycle 80 32\n",
      "Took to collect: 7.963160753250122\n",
      "Took to train: 6.463953256607056\n",
      "\n",
      " Cycle 81 32\n",
      "Took to collect: 6.291792392730713\n",
      "Took to train: 6.461836338043213\n",
      "\n",
      " Cycle 82 32\n",
      "Took to collect: 8.735952377319336\n",
      "Took to train: 6.416955471038818\n",
      "\n",
      " Cycle 83 32\n",
      "Took to collect: 8.074882984161377\n",
      "Took to train: 6.395705223083496\n",
      "\n",
      " Cycle 84 32\n",
      "Took to collect: 7.844077110290527\n",
      "Took to train: 6.378671407699585\n",
      "\n",
      " Cycle 85 32\n",
      "Took to collect: 6.968245029449463\n",
      "Took to train: 6.3758625984191895\n",
      "\n",
      " Cycle 86 32\n",
      "Took to collect: 7.365267276763916\n",
      "Took to train: 6.368285894393921\n",
      "\n",
      " Cycle 87 32\n",
      "Took to collect: 7.282142400741577\n",
      "Took to train: 6.2700583934783936\n",
      "\n",
      " Cycle 88 32\n",
      "Took to collect: 8.553377866744995\n",
      "Took to train: 6.349015235900879\n",
      "\n",
      " Cycle 89 32\n",
      "Took to collect: 8.393798589706421\n",
      "Took to train: 6.425615072250366\n",
      "\n",
      " Cycle 90 32\n",
      "Took to collect: 7.507550239562988\n",
      "Took to train: 6.438947677612305\n",
      "\n",
      " Cycle 91 32\n",
      "Took to collect: 6.30363392829895\n",
      "Took to train: 6.399450063705444\n",
      "\n",
      " Cycle 92 32\n",
      "Took to collect: 7.384989023208618\n",
      "Took to train: 6.387077331542969\n",
      "\n",
      " Cycle 93 32\n",
      "Took to collect: 8.227384567260742\n",
      "Took to train: 6.481041669845581\n",
      "\n",
      " Cycle 94 32\n",
      "Took to collect: 8.173022270202637\n",
      "Took to train: 6.375054359436035\n",
      "\n",
      " Cycle 95 32\n",
      "Took to collect: 7.432872533798218\n",
      "Took to train: 6.397975921630859\n",
      "\n",
      " Cycle 96 32\n",
      "Took to collect: 7.940700054168701\n",
      "Took to train: 6.439054489135742\n",
      "\n",
      " Cycle 97 32\n",
      "Took to collect: 8.438445329666138\n",
      "Took to train: 6.557751178741455\n",
      "\n",
      " Cycle 98 32\n",
      "Took to collect: 7.625836372375488\n",
      "Took to train: 6.521255254745483\n",
      "\n",
      " Cycle 99 32\n",
      "Took to collect: 6.820382595062256\n",
      "Took to train: 6.4309210777282715\n",
      "Time collect avg cycle: 8.143979938030244\n",
      "Time train avg cycle: 6.4634228348731995\n",
      "Total avg cycle: 14.617521839141846\n",
      "Ending epoch\n",
      "2020-10-26 10:36:01.586791 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 32 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.54931\n",
      "trainer/QF2 Loss                                    0.689731\n",
      "trainer/Policy Loss                                45.3277\n",
      "trainer/Q1 Predictions Mean                       -45.4654\n",
      "trainer/Q1 Predictions Std                         34.5786\n",
      "trainer/Q1 Predictions Max                          6.79661\n",
      "trainer/Q1 Predictions Min                       -105.821\n",
      "trainer/Q2 Predictions Mean                       -45.3633\n",
      "trainer/Q2 Predictions Std                         34.5737\n",
      "trainer/Q2 Predictions Max                          7.01566\n",
      "trainer/Q2 Predictions Min                       -105.68\n",
      "trainer/Q Targets Mean                            -45.6074\n",
      "trainer/Q Targets Std                              34.5154\n",
      "trainer/Q Targets Max                               6.66231\n",
      "trainer/Q Targets Min                            -105.666\n",
      "trainer/Log Pis Mean                                2.99041\n",
      "trainer/Log Pis Std                                 2.36575\n",
      "trainer/Log Pis Max                                 9.54222\n",
      "trainer/Log Pis Min                                -3.12708\n",
      "trainer/policy/mean Mean                           -0.270611\n",
      "trainer/policy/mean Std                             0.636764\n",
      "trainer/policy/mean Max                             0.99334\n",
      "trainer/policy/mean Min                            -0.995547\n",
      "trainer/policy/normal/std Mean                      0.376421\n",
      "trainer/policy/normal/std Std                       0.236636\n",
      "trainer/policy/normal/std Max                       1.22033\n",
      "trainer/policy/normal/std Min                       0.0365395\n",
      "trainer/policy/normal/log_std Mean                 -1.23145\n",
      "trainer/policy/normal/log_std Std                   0.785077\n",
      "trainer/policy/normal/log_std Max                   0.199119\n",
      "trainer/policy/normal/log_std Min                  -3.30936\n",
      "trainer/Alpha                                       0.0105065\n",
      "trainer/Alpha Loss                                 -0.043687\n",
      "exploration/num steps total                    331000\n",
      "exploration/num paths total                      6647\n",
      "exploration/path length Mean                       50\n",
      "exploration/path length Std                         0\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        50\n",
      "exploration/Rewards Mean                           -0.998\n",
      "exploration/Rewards Std                             0.0446766\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.9\n",
      "exploration/Returns Std                             1.00995\n",
      "exploration/Returns Max                           -36\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.235463\n",
      "exploration/Actions Std                             0.600915\n",
      "exploration/Actions Max                             0.999994\n",
      "exploration/Actions Min                            -0.99987\n",
      "exploration/Num Paths                             200\n",
      "exploration/Average Returns                       -49.9\n",
      "exploration/env_infos/final/is_success Mean         0\n",
      "exploration/env_infos/final/is_success Std          0\n",
      "exploration/env_infos/final/is_success Max          0\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0\n",
      "exploration/env_infos/is_success Std                0\n",
      "exploration/env_infos/is_success Max                0\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      16390\n",
      "evaluation/num paths total                        331\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -0.992\n",
      "evaluation/Rewards Std                              0.0890842\n",
      "evaluation/Rewards Max                             -0\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -49.6\n",
      "evaluation/Returns Std                              1.2\n",
      "evaluation/Returns Max                            -46\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.144577\n",
      "evaluation/Actions Std                              0.420819\n",
      "evaluation/Actions Max                              0.979155\n",
      "evaluation/Actions Min                             -0.991892\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -49.6\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.986333\n",
      "time/evaluation sampling (s)                       42.1639\n",
      "time/exploration sampling (s)                     814.417\n",
      "time/logging (s)                                    0.026932\n",
      "time/sac training (s)                             199.944\n",
      "time/saving (s)                                     0.0143277\n",
      "time/training (s)                                   0.00709984\n",
      "time/epoch (s)                                   1057.56\n",
      "time/total (s)                                  46632.1\n",
      "Epoch                                              32\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation done\n",
      "Epoch 33\n",
      "\n",
      " Cycle 0 33\n",
      "Took to collect: 7.550686597824097\n",
      "Took to train: 6.431702375411987\n",
      "\n",
      " Cycle 1 33\n",
      "Took to collect: 7.48356819152832\n",
      "Took to train: 6.538873195648193\n",
      "\n",
      " Cycle 2 33\n",
      "Took to collect: 9.095187664031982\n",
      "Took to train: 6.499315977096558\n",
      "\n",
      " Cycle 3 33\n",
      "Took to collect: 6.283404350280762\n",
      "Took to train: 6.483246088027954\n",
      "\n",
      " Cycle 4 33\n",
      "Took to collect: 7.314808130264282\n",
      "Took to train: 6.509130477905273\n",
      "\n",
      " Cycle 5 33\n",
      "Took to collect: 8.623228549957275\n",
      "Took to train: 6.438900947570801\n",
      "\n",
      " Cycle 6 33\n",
      "Took to collect: 7.1936681270599365\n",
      "Took to train: 6.3881261348724365\n",
      "\n",
      " Cycle 7 33\n",
      "Took to collect: 8.045294761657715\n",
      "Took to train: 6.496963024139404\n",
      "\n",
      " Cycle 8 33\n",
      "Took to collect: 7.49920392036438\n",
      "Took to train: 6.513092279434204\n",
      "\n",
      " Cycle 9 33\n",
      "Took to collect: 6.9707090854644775\n",
      "Took to train: 6.4991888999938965\n",
      "\n",
      " Cycle 10 33\n",
      "Took to collect: 8.105980396270752\n",
      "Took to train: 6.491002798080444\n",
      "\n",
      " Cycle 11 33\n",
      "Took to collect: 7.3483500480651855\n",
      "Took to train: 6.4480881690979\n",
      "\n",
      " Cycle 12 33\n",
      "Took to collect: 8.150876998901367\n",
      "Took to train: 6.434649467468262\n",
      "\n",
      " Cycle 13 33\n",
      "Took to collect: 8.729067087173462\n",
      "Took to train: 6.492377042770386\n",
      "\n",
      " Cycle 14 33\n",
      "Took to collect: 8.752851486206055\n",
      "Took to train: 6.439408302307129\n",
      "\n",
      " Cycle 15 33\n",
      "Took to collect: 9.295251846313477\n",
      "Took to train: 6.423889875411987\n",
      "\n",
      " Cycle 16 33\n",
      "Took to collect: 8.384647369384766\n",
      "Took to train: 6.436937570571899\n",
      "\n",
      " Cycle 17 33\n",
      "Took to collect: 7.623809337615967\n",
      "Took to train: 6.42515230178833\n",
      "\n",
      " Cycle 18 33\n",
      "Took to collect: 7.577742099761963\n",
      "Took to train: 6.4110283851623535\n",
      "\n",
      " Cycle 19 33\n",
      "Took to collect: 7.982243537902832\n",
      "Took to train: 6.418948650360107\n",
      "\n",
      " Cycle 20 33\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 6.813389301300049\n",
      "Took to train: 6.439768552780151\n",
      "\n",
      " Cycle 21 33\n",
      "Took to collect: 8.321314334869385\n",
      "Took to train: 6.3952882289886475\n",
      "\n",
      " Cycle 22 33\n",
      "Took to collect: 7.564486503601074\n",
      "Took to train: 6.438066482543945\n",
      "\n",
      " Cycle 23 33\n",
      "Took to collect: 7.517998695373535\n",
      "Took to train: 6.432923793792725\n",
      "\n",
      " Cycle 24 33\n",
      "Took to collect: 6.712949752807617\n",
      "Took to train: 6.467929124832153\n",
      "\n",
      " Cycle 25 33\n",
      "Took to collect: 8.49643611907959\n",
      "Took to train: 6.312150478363037\n",
      "\n",
      " Cycle 26 33\n",
      "Took to collect: 6.846233129501343\n",
      "Took to train: 6.322967529296875\n",
      "\n",
      " Cycle 27 33\n",
      "Took to collect: 10.41838002204895\n",
      "Took to train: 6.339018106460571\n",
      "\n",
      " Cycle 28 33\n",
      "Took to collect: 7.459442615509033\n",
      "Took to train: 6.482037544250488\n",
      "\n",
      " Cycle 29 33\n",
      "Took to collect: 8.930710792541504\n",
      "Took to train: 6.447961807250977\n",
      "\n",
      " Cycle 30 33\n",
      "Took to collect: 6.93639063835144\n",
      "Took to train: 6.4238364696502686\n",
      "\n",
      " Cycle 31 33\n",
      "Took to collect: 8.577845335006714\n",
      "Took to train: 6.348921298980713\n",
      "\n",
      " Cycle 32 33\n",
      "Took to collect: 9.026841402053833\n",
      "Took to train: 6.3017964363098145\n",
      "\n",
      " Cycle 33 33\n",
      "Took to collect: 9.128573179244995\n",
      "Took to train: 6.312127590179443\n",
      "\n",
      " Cycle 34 33\n",
      "Took to collect: 8.706827640533447\n",
      "Took to train: 6.3211829662323\n",
      "\n",
      " Cycle 35 33\n",
      "Took to collect: 8.535083770751953\n",
      "Took to train: 6.402738094329834\n",
      "\n",
      " Cycle 36 33\n",
      "Took to collect: 7.615412473678589\n",
      "Took to train: 6.477851629257202\n",
      "\n",
      " Cycle 37 33\n",
      "Took to collect: 7.6250128746032715\n",
      "Took to train: 6.424427509307861\n",
      "\n",
      " Cycle 38 33\n",
      "Took to collect: 7.065073728561401\n",
      "Took to train: 6.314823389053345\n",
      "\n",
      " Cycle 39 33\n",
      "Took to collect: 8.628699541091919\n",
      "Took to train: 6.358416557312012\n",
      "\n",
      " Cycle 40 33\n",
      "Took to collect: 8.011197566986084\n",
      "Took to train: 6.397418975830078\n",
      "\n",
      " Cycle 41 33\n",
      "Took to collect: 8.039436101913452\n",
      "Took to train: 6.413081407546997\n",
      "\n",
      " Cycle 42 33\n",
      "Took to collect: 8.68109917640686\n",
      "Took to train: 6.426267147064209\n",
      "\n",
      " Cycle 43 33\n",
      "Took to collect: 9.730791330337524\n",
      "Took to train: 6.423773527145386\n",
      "\n",
      " Cycle 44 33\n",
      "Took to collect: 7.405632972717285\n",
      "Took to train: 6.408934116363525\n",
      "\n",
      " Cycle 45 33\n",
      "Took to collect: 7.219226121902466\n",
      "Took to train: 6.428020715713501\n",
      "\n",
      " Cycle 46 33\n",
      "Took to collect: 6.969510316848755\n",
      "Took to train: 6.458465814590454\n",
      "\n",
      " Cycle 47 33\n",
      "Took to collect: 7.4923646450042725\n",
      "Took to train: 6.475898265838623\n",
      "\n",
      " Cycle 48 33\n",
      "Took to collect: 8.538834810256958\n",
      "Took to train: 6.424205303192139\n",
      "\n",
      " Cycle 49 33\n",
      "Took to collect: 8.271500825881958\n",
      "Took to train: 6.377853155136108\n",
      "\n",
      " Cycle 50 33\n",
      "Took to collect: 7.864576816558838\n",
      "Took to train: 6.312928199768066\n",
      "\n",
      " Cycle 51 33\n",
      "Took to collect: 7.68336296081543\n",
      "Took to train: 6.398410320281982\n",
      "\n",
      " Cycle 52 33\n",
      "Took to collect: 8.1871976852417\n",
      "Took to train: 6.506279230117798\n",
      "\n",
      " Cycle 53 33\n",
      "Took to collect: 8.914891481399536\n",
      "Took to train: 6.30459189414978\n",
      "\n",
      " Cycle 54 33\n",
      "Took to collect: 7.958551645278931\n",
      "Took to train: 6.313177585601807\n",
      "\n",
      " Cycle 55 33\n",
      "Took to collect: 7.823427677154541\n",
      "Took to train: 6.411422967910767\n",
      "\n",
      " Cycle 56 33\n",
      "Took to collect: 7.164880275726318\n",
      "Took to train: 6.494168519973755\n",
      "\n",
      " Cycle 57 33\n",
      "Took to collect: 7.7694220542907715\n",
      "Took to train: 6.498961687088013\n",
      "\n",
      " Cycle 58 33\n",
      "Took to collect: 9.83848762512207\n",
      "Took to train: 6.473268508911133\n",
      "\n",
      " Cycle 59 33\n",
      "Took to collect: 7.518046617507935\n",
      "Took to train: 6.499887943267822\n",
      "\n",
      " Cycle 60 33\n",
      "Took to collect: 9.058688163757324\n",
      "Took to train: 6.492082834243774\n",
      "\n",
      " Cycle 61 33\n",
      "Took to collect: 7.637167692184448\n",
      "Took to train: 6.5071845054626465\n",
      "\n",
      " Cycle 62 33\n",
      "Took to collect: 7.366774559020996\n",
      "Took to train: 6.48957896232605\n",
      "\n",
      " Cycle 63 33\n",
      "Took to collect: 7.076873302459717\n",
      "Took to train: 6.306165933609009\n",
      "\n",
      " Cycle 64 33\n",
      "Took to collect: 7.891621828079224\n",
      "Took to train: 6.354222059249878\n",
      "\n",
      " Cycle 65 33\n",
      "Took to collect: 6.969649314880371\n",
      "Took to train: 6.468455791473389\n",
      "\n",
      " Cycle 66 33\n",
      "Took to collect: 7.063802480697632\n",
      "Took to train: 6.4592461585998535\n",
      "\n",
      " Cycle 67 33\n",
      "Took to collect: 6.988592147827148\n",
      "Took to train: 6.460901498794556\n",
      "\n",
      " Cycle 68 33\n",
      "Took to collect: 8.175512790679932\n",
      "Took to train: 6.418170928955078\n",
      "\n",
      " Cycle 69 33\n",
      "Took to collect: 6.717569828033447\n",
      "Took to train: 6.400728940963745\n",
      "\n",
      " Cycle 70 33\n",
      "Took to collect: 8.415404558181763\n",
      "Took to train: 6.29285740852356\n",
      "\n",
      " Cycle 71 33\n",
      "Took to collect: 7.522046804428101\n",
      "Took to train: 6.270460605621338\n",
      "\n",
      " Cycle 72 33\n",
      "Took to collect: 8.088295698165894\n",
      "Took to train: 6.280038595199585\n",
      "\n",
      " Cycle 73 33\n",
      "Took to collect: 9.030336380004883\n",
      "Took to train: 6.27822208404541\n",
      "\n",
      " Cycle 74 33\n",
      "Took to collect: 9.358765602111816\n",
      "Took to train: 6.274586200714111\n",
      "\n",
      " Cycle 75 33\n",
      "Took to collect: 8.378926515579224\n",
      "Took to train: 6.277856111526489\n",
      "\n",
      " Cycle 76 33\n",
      "Took to collect: 8.686760425567627\n",
      "Took to train: 6.342629909515381\n",
      "\n",
      " Cycle 77 33\n",
      "Took to collect: 8.662277460098267\n",
      "Took to train: 6.400510311126709\n",
      "\n",
      " Cycle 78 33\n",
      "Took to collect: 9.342339754104614\n",
      "Took to train: 6.400355339050293\n",
      "\n",
      " Cycle 79 33\n",
      "Took to collect: 7.836374998092651\n",
      "Took to train: 6.44288444519043\n",
      "\n",
      " Cycle 80 33\n",
      "Took to collect: 7.874868154525757\n",
      "Took to train: 6.41192364692688\n",
      "\n",
      " Cycle 81 33\n",
      "Took to collect: 8.872675895690918\n",
      "Took to train: 6.4455273151397705\n",
      "\n",
      " Cycle 82 33\n",
      "Took to collect: 8.623759746551514\n",
      "Took to train: 6.379886865615845\n",
      "\n",
      " Cycle 83 33\n",
      "Took to collect: 7.111670732498169\n",
      "Took to train: 6.296691417694092\n",
      "\n",
      " Cycle 84 33\n",
      "Took to collect: 8.723690748214722\n",
      "Took to train: 6.432326078414917\n",
      "\n",
      " Cycle 85 33\n",
      "Took to collect: 8.048302173614502\n",
      "Took to train: 6.3891661167144775\n",
      "\n",
      " Cycle 86 33\n",
      "Took to collect: 6.486596345901489\n",
      "Took to train: 6.292917490005493\n",
      "\n",
      " Cycle 87 33\n",
      "Took to collect: 8.522917032241821\n",
      "Took to train: 6.248747110366821\n",
      "\n",
      " Cycle 88 33\n",
      "Took to collect: 7.53474235534668\n",
      "Took to train: 6.257024049758911\n",
      "\n",
      " Cycle 89 33\n",
      "Took to collect: 9.35143232345581\n",
      "Took to train: 6.271998643875122\n",
      "\n",
      " Cycle 90 33\n",
      "Took to collect: 7.157873153686523\n",
      "Took to train: 6.32439398765564\n",
      "\n",
      " Cycle 91 33\n",
      "Took to collect: 7.150650501251221\n",
      "Took to train: 6.338204622268677\n",
      "\n",
      " Cycle 92 33\n",
      "Took to collect: 8.857359170913696\n",
      "Took to train: 6.285620212554932\n",
      "\n",
      " Cycle 93 33\n",
      "Took to collect: 7.548760652542114\n",
      "Took to train: 6.249840259552002\n",
      "\n",
      " Cycle 94 33\n",
      "Took to collect: 8.178053379058838\n",
      "Took to train: 6.235353946685791\n",
      "\n",
      " Cycle 95 33\n",
      "Took to collect: 8.9786057472229\n",
      "Took to train: 6.386645793914795\n",
      "\n",
      " Cycle 96 33\n",
      "Took to collect: 7.909311771392822\n",
      "Took to train: 6.419828414916992\n",
      "\n",
      " Cycle 97 33\n",
      "Took to collect: 9.219922065734863\n",
      "Took to train: 6.524909257888794\n",
      "\n",
      " Cycle 98 33\n",
      "Took to collect: 7.927809476852417\n",
      "Took to train: 6.577641010284424\n",
      "\n",
      " Cycle 99 33\n",
      "Took to collect: 7.6015543937683105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.693941593170166\n",
      "Time collect avg cycle: 8.019684562683105\n",
      "Time train avg cycle: 6.405109972953796\n",
      "Total avg cycle: 14.434746432304383\n",
      "Ending epoch\n",
      "2020-10-26 11:00:48.986755 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 33 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    0.679269\n",
      "trainer/QF2 Loss                                    0.73947\n",
      "trainer/Policy Loss                                45.4035\n",
      "trainer/Q1 Predictions Mean                       -45.5238\n",
      "trainer/Q1 Predictions Std                         34.832\n",
      "trainer/Q1 Predictions Max                          3.78721\n",
      "trainer/Q1 Predictions Min                       -105.091\n",
      "trainer/Q2 Predictions Mean                       -45.3559\n",
      "trainer/Q2 Predictions Std                         34.8907\n",
      "trainer/Q2 Predictions Max                          4.32996\n",
      "trainer/Q2 Predictions Min                       -105.336\n",
      "trainer/Q Targets Mean                            -45.5726\n",
      "trainer/Q Targets Std                              34.858\n",
      "trainer/Q Targets Max                               4.15451\n",
      "trainer/Q Targets Min                            -105.295\n",
      "trainer/Log Pis Mean                                2.99162\n",
      "trainer/Log Pis Std                                 2.4474\n",
      "trainer/Log Pis Max                                 9.01129\n",
      "trainer/Log Pis Min                                -4.52446\n",
      "trainer/policy/mean Mean                           -0.333239\n",
      "trainer/policy/mean Std                             0.631884\n",
      "trainer/policy/mean Max                             0.992014\n",
      "trainer/policy/mean Min                            -0.992654\n",
      "trainer/policy/normal/std Mean                      0.417182\n",
      "trainer/policy/normal/std Std                       0.267307\n",
      "trainer/policy/normal/std Max                       1.49421\n",
      "trainer/policy/normal/std Min                       0.0357028\n",
      "trainer/policy/normal/log_std Mean                 -1.12996\n",
      "trainer/policy/normal/log_std Std                   0.788379\n",
      "trainer/policy/normal/log_std Max                   0.401597\n",
      "trainer/policy/normal/log_std Min                  -3.33253\n",
      "trainer/Alpha                                       0.0113938\n",
      "trainer/Alpha Loss                                 -0.0375013\n",
      "exploration/num steps total                    341000\n",
      "exploration/num paths total                      6848\n",
      "exploration/path length Mean                       49.7512\n",
      "exploration/path length Std                         2.9503\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         9\n",
      "exploration/Rewards Mean                           -0.9927\n",
      "exploration/Rewards Std                             0.0851276\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.3881\n",
      "exploration/Returns Std                             3.86316\n",
      "exploration/Returns Max                            -8\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.306736\n",
      "exploration/Actions Std                             0.600803\n",
      "exploration/Actions Max                             0.999563\n",
      "exploration/Actions Min                            -0.999997\n",
      "exploration/Num Paths                             201\n",
      "exploration/Average Returns                       -49.3881\n",
      "exploration/env_infos/final/is_success Mean         0.00497512\n",
      "exploration/env_infos/final/is_success Std          0.0703589\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0001\n",
      "exploration/env_infos/is_success Std                0.0099995\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      16890\n",
      "evaluation/num paths total                        341\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -0.996\n",
      "evaluation/Rewards Std                              0.0631189\n",
      "evaluation/Rewards Max                             -0\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -49.8\n",
      "evaluation/Returns Std                              0.6\n",
      "evaluation/Returns Max                            -48\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.224314\n",
      "evaluation/Actions Std                              0.483588\n",
      "evaluation/Actions Max                              0.983385\n",
      "evaluation/Actions Min                             -0.988044\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -49.8\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.969896\n",
      "time/evaluation sampling (s)                       43.8562\n",
      "time/exploration sampling (s)                     801.988\n",
      "time/logging (s)                                    0.0271682\n",
      "time/sac training (s)                             199.032\n",
      "time/saving (s)                                     0.0208465\n",
      "time/training (s)                                   0.00695787\n",
      "time/epoch (s)                                   1045.9\n",
      "time/total (s)                                  48119.3\n",
      "Epoch                                              33\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 34\n",
      "\n",
      " Cycle 0 34\n",
      "Took to collect: 8.289173603057861\n",
      "Took to train: 6.468334197998047\n",
      "\n",
      " Cycle 1 34\n",
      "Took to collect: 8.692209243774414\n",
      "Took to train: 6.483251333236694\n",
      "\n",
      " Cycle 2 34\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 6.837721347808838\n",
      "Took to train: 6.488036394119263\n",
      "\n",
      " Cycle 3 34\n",
      "Took to collect: 8.622068881988525\n",
      "Took to train: 6.479773283004761\n",
      "\n",
      " Cycle 4 34\n",
      "Took to collect: 7.723443031311035\n",
      "Took to train: 6.479229211807251\n",
      "\n",
      " Cycle 5 34\n",
      "Took to collect: 7.254747152328491\n",
      "Took to train: 6.483694314956665\n",
      "\n",
      " Cycle 6 34\n",
      "Took to collect: 8.626744031906128\n",
      "Took to train: 6.395541667938232\n",
      "\n",
      " Cycle 7 34\n",
      "Took to collect: 8.2013258934021\n",
      "Took to train: 6.443119764328003\n",
      "\n",
      " Cycle 8 34\n",
      "Took to collect: 6.59640908241272\n",
      "Took to train: 6.478404998779297\n",
      "\n",
      " Cycle 9 34\n",
      "Took to collect: 8.21941590309143\n",
      "Took to train: 6.451336622238159\n",
      "\n",
      " Cycle 10 34\n",
      "Took to collect: 8.901561260223389\n",
      "Took to train: 6.456918954849243\n",
      "\n",
      " Cycle 11 34\n",
      "Took to collect: 8.625122785568237\n",
      "Took to train: 6.41976261138916\n",
      "\n",
      " Cycle 12 34\n",
      "Took to collect: 8.459137439727783\n",
      "Took to train: 6.278199911117554\n",
      "\n",
      " Cycle 13 34\n",
      "Took to collect: 9.950144529342651\n",
      "Took to train: 6.434687852859497\n",
      "\n",
      " Cycle 14 34\n",
      "Took to collect: 8.483980178833008\n",
      "Took to train: 6.425958633422852\n",
      "\n",
      " Cycle 15 34\n",
      "Took to collect: 8.32733941078186\n",
      "Took to train: 6.420844078063965\n",
      "\n",
      " Cycle 16 34\n",
      "Took to collect: 7.4299468994140625\n",
      "Took to train: 6.400387763977051\n",
      "\n",
      " Cycle 17 34\n",
      "Took to collect: 6.328814744949341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.44244122505188\n",
      "\n",
      " Cycle 18 34\n",
      "Took to collect: 7.058893918991089\n",
      "Took to train: 6.464498281478882\n",
      "\n",
      " Cycle 19 34\n",
      "Took to collect: 7.572503566741943\n",
      "Took to train: 6.449146747589111\n",
      "\n",
      " Cycle 20 34\n",
      "Took to collect: 8.224109888076782\n",
      "Took to train: 6.512136220932007\n",
      "\n",
      " Cycle 21 34\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.022836446762085\n",
      "Took to train: 6.488162279129028\n",
      "\n",
      " Cycle 22 34\n",
      "Took to collect: 6.910131216049194\n",
      "Took to train: 6.4226109981536865\n",
      "\n",
      " Cycle 23 34\n",
      "Took to collect: 7.779046297073364\n",
      "Took to train: 6.522324800491333\n",
      "\n",
      " Cycle 24 34\n",
      "Took to collect: 6.605066537857056\n",
      "Took to train: 6.475920915603638\n",
      "\n",
      " Cycle 25 34\n",
      "Took to collect: 6.729069948196411\n",
      "Took to train: 6.530077934265137\n",
      "\n",
      " Cycle 26 34\n",
      "Took to collect: 7.712394714355469\n",
      "Took to train: 6.526316404342651\n",
      "\n",
      " Cycle 27 34\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 8.079127550125122\n",
      "Took to train: 6.45338773727417\n",
      "\n",
      " Cycle 28 34\n",
      "Took to collect: 6.443731784820557\n",
      "Took to train: 6.459723711013794\n",
      "\n",
      " Cycle 29 34\n",
      "Took to collect: 7.863722562789917\n",
      "Took to train: 6.419016122817993\n",
      "\n",
      " Cycle 30 34\n",
      "Took to collect: 7.129950046539307\n",
      "Took to train: 6.307485818862915\n",
      "\n",
      " Cycle 31 34\n",
      "Took to collect: 7.160938262939453\n",
      "Took to train: 6.412371397018433\n",
      "\n",
      " Cycle 32 34\n",
      "Took to collect: 8.698619842529297\n",
      "Took to train: 6.315663814544678\n",
      "\n",
      " Cycle 33 34\n",
      "Took to collect: 7.318293571472168\n",
      "Took to train: 6.310209035873413\n",
      "\n",
      " Cycle 34 34\n",
      "Took to collect: 6.35551381111145\n",
      "Took to train: 6.321056127548218\n",
      "\n",
      " Cycle 35 34\n",
      "Took to collect: 8.219885110855103\n",
      "Took to train: 6.309390544891357\n",
      "\n",
      " Cycle 36 34\n",
      "Took to collect: 7.743666887283325\n",
      "Took to train: 6.305312871932983\n",
      "\n",
      " Cycle 37 34\n",
      "Took to collect: 6.809525012969971\n",
      "Took to train: 6.483828544616699\n",
      "\n",
      " Cycle 38 34\n",
      "Took to collect: 8.36360502243042\n",
      "Took to train: 6.515911102294922\n",
      "\n",
      " Cycle 39 34\n",
      "Took to collect: 7.7590131759643555\n",
      "Took to train: 6.472233057022095\n",
      "\n",
      " Cycle 40 34\n",
      "Took to collect: 7.725945472717285\n",
      "Took to train: 6.417741298675537\n",
      "\n",
      " Cycle 41 34\n",
      "Took to collect: 8.55048418045044\n",
      "Took to train: 6.416990756988525\n",
      "\n",
      " Cycle 42 34\n",
      "Took to collect: 8.547148942947388\n",
      "Took to train: 6.420980453491211\n",
      "\n",
      " Cycle 43 34\n",
      "Took to collect: 7.139373064041138\n",
      "Took to train: 6.405483245849609\n",
      "\n",
      " Cycle 44 34\n",
      "Took to collect: 7.940827369689941\n",
      "Took to train: 6.492985010147095\n",
      "\n",
      " Cycle 45 34\n",
      "Took to collect: 7.206632375717163\n",
      "Took to train: 6.431433916091919\n",
      "\n",
      " Cycle 46 34\n",
      "Took to collect: 8.61655068397522\n",
      "Took to train: 6.4357476234436035\n",
      "\n",
      " Cycle 47 34\n",
      "Took to collect: 6.859476089477539\n",
      "Took to train: 6.427191495895386\n",
      "\n",
      " Cycle 48 34\n",
      "Took to collect: 7.8368821144104\n",
      "Took to train: 6.438745975494385\n",
      "\n",
      " Cycle 49 34\n",
      "Took to collect: 7.243032693862915\n",
      "Took to train: 6.507319688796997\n",
      "\n",
      " Cycle 50 34\n",
      "Took to collect: 8.318615913391113\n",
      "Took to train: 6.3073225021362305\n",
      "\n",
      " Cycle 51 34\n",
      "Took to collect: 8.323131561279297\n",
      "Took to train: 6.332190752029419\n",
      "\n",
      " Cycle 52 34\n",
      "Took to collect: 8.005419731140137\n",
      "Took to train: 6.43931245803833\n",
      "\n",
      " Cycle 53 34\n",
      "Took to collect: 8.695093393325806\n",
      "Took to train: 6.429863452911377\n",
      "\n",
      " Cycle 54 34\n",
      "Took to collect: 8.547830581665039\n",
      "Took to train: 6.438194990158081\n",
      "\n",
      " Cycle 55 34\n",
      "Took to collect: 6.475060939788818\n",
      "Took to train: 6.424344539642334\n",
      "\n",
      " Cycle 56 34\n",
      "Took to collect: 6.984220743179321\n",
      "Took to train: 6.439822196960449\n",
      "\n",
      " Cycle 57 34\n",
      "Took to collect: 6.5032854080200195\n",
      "Took to train: 6.389605760574341\n",
      "\n",
      " Cycle 58 34\n",
      "Took to collect: 9.1014564037323\n",
      "Took to train: 6.375787258148193\n",
      "\n",
      " Cycle 59 34\n",
      "Took to collect: 6.363159894943237\n",
      "Took to train: 6.4678733348846436\n",
      "\n",
      " Cycle 60 34\n",
      "Took to collect: 7.9115071296691895\n",
      "Took to train: 6.4624433517456055\n",
      "\n",
      " Cycle 61 34\n",
      "Took to collect: 8.085219144821167\n",
      "Took to train: 6.481983423233032\n",
      "\n",
      " Cycle 62 34\n",
      "Took to collect: 7.976369857788086\n",
      "Took to train: 6.338258743286133\n",
      "\n",
      " Cycle 63 34\n",
      "Took to collect: 8.08060073852539\n",
      "Took to train: 6.334123373031616\n",
      "\n",
      " Cycle 64 34\n",
      "Took to collect: 8.624817609786987\n",
      "Took to train: 6.439769506454468\n",
      "\n",
      " Cycle 65 34\n",
      "Took to collect: 7.80847692489624\n",
      "Took to train: 6.284064769744873\n",
      "\n",
      " Cycle 66 34\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 8.142778158187866\n",
      "Took to train: 6.427536725997925\n",
      "\n",
      " Cycle 67 34\n",
      "Took to collect: 7.84592080116272\n",
      "Took to train: 6.460700750350952\n",
      "\n",
      " Cycle 68 34\n",
      "Took to collect: 7.74294376373291\n",
      "Took to train: 6.355639457702637\n",
      "\n",
      " Cycle 69 34\n",
      "Took to collect: 5.998311996459961\n",
      "Took to train: 6.442605257034302\n",
      "\n",
      " Cycle 70 34\n",
      "Took to collect: 7.782225847244263\n",
      "Took to train: 6.470720052719116\n",
      "\n",
      " Cycle 71 34\n",
      "Took to collect: 7.849681615829468\n",
      "Took to train: 6.440677881240845\n",
      "\n",
      " Cycle 72 34\n",
      "Took to collect: 7.249925136566162\n",
      "Took to train: 6.391424655914307\n",
      "\n",
      " Cycle 73 34\n",
      "Took to collect: 6.2221033573150635\n",
      "Took to train: 6.393836498260498\n",
      "\n",
      " Cycle 74 34\n",
      "Took to collect: 6.792536497116089\n",
      "Took to train: 6.400109767913818\n",
      "\n",
      " Cycle 75 34\n",
      "Took to collect: 7.64269495010376\n",
      "Took to train: 6.365157842636108\n",
      "\n",
      " Cycle 76 34\n",
      "Took to collect: 6.976448059082031\n",
      "Took to train: 6.278626441955566\n",
      "\n",
      " Cycle 77 34\n",
      "Took to collect: 8.643965005874634\n",
      "Took to train: 6.267213582992554\n",
      "\n",
      " Cycle 78 34\n",
      "Took to collect: 7.402400016784668\n",
      "Took to train: 6.273706436157227\n",
      "\n",
      " Cycle 79 34\n",
      "Took to collect: 6.954878091812134\n",
      "Took to train: 6.370131015777588\n",
      "\n",
      " Cycle 80 34\n",
      "Took to collect: 7.728494644165039\n",
      "Took to train: 6.380871295928955\n",
      "\n",
      " Cycle 81 34\n",
      "Took to collect: 8.131360054016113\n",
      "Took to train: 6.387744665145874\n",
      "\n",
      " Cycle 82 34\n",
      "Took to collect: 9.01871943473816\n",
      "Took to train: 6.454413175582886\n",
      "\n",
      " Cycle 83 34\n",
      "Took to collect: 9.018712282180786\n",
      "Took to train: 6.454501390457153\n",
      "\n",
      " Cycle 84 34\n",
      "Took to collect: 7.16693639755249\n",
      "Took to train: 6.469613313674927\n",
      "\n",
      " Cycle 85 34\n",
      "Took to collect: 7.310091257095337\n",
      "Took to train: 6.452213764190674\n",
      "\n",
      " Cycle 86 34\n",
      "Took to collect: 8.117344617843628\n",
      "Took to train: 6.4696338176727295\n",
      "\n",
      " Cycle 87 34\n",
      "Took to collect: 7.3086817264556885\n",
      "Took to train: 6.478278160095215\n",
      "\n",
      " Cycle 88 34\n",
      "Took to collect: 8.405641555786133\n",
      "Took to train: 6.449693918228149\n",
      "\n",
      " Cycle 89 34\n",
      "Took to collect: 8.566362619400024\n",
      "Took to train: 6.444093942642212\n",
      "\n",
      " Cycle 90 34\n",
      "Took to collect: 7.516382932662964\n",
      "Took to train: 6.283877372741699\n",
      "\n",
      " Cycle 91 34\n",
      "Took to collect: 6.797657251358032\n",
      "Took to train: 6.262067556381226\n",
      "\n",
      " Cycle 92 34\n",
      "Took to collect: 6.754534959793091\n",
      "Took to train: 6.346708536148071\n",
      "\n",
      " Cycle 93 34\n",
      "Took to collect: 7.714514493942261\n",
      "Took to train: 6.474193096160889\n",
      "\n",
      " Cycle 94 34\n",
      "Took to collect: 6.455602645874023\n",
      "Took to train: 6.445746898651123\n",
      "\n",
      " Cycle 95 34\n",
      "Took to collect: 7.971830129623413\n",
      "Took to train: 6.48621940612793\n",
      "\n",
      " Cycle 96 34\n",
      "Took to collect: 6.443556308746338\n",
      "Took to train: 6.617490291595459\n",
      "\n",
      " Cycle 97 34\n",
      "Took to collect: 9.452512979507446\n",
      "Took to train: 6.5765228271484375\n",
      "\n",
      " Cycle 98 34\n",
      "Took to collect: 7.0115087032318115\n",
      "Took to train: 6.582446813583374\n",
      "\n",
      " Cycle 99 34\n",
      "Took to collect: 8.907304525375366\n",
      "Took to train: 6.665186882019043\n",
      "Time collect avg cycle: 7.716441323757172\n",
      "Time train avg cycle: 6.4270589065551755\n",
      "Total avg cycle: 14.153468928337098\n",
      "Ending epoch\n",
      "2020-10-26 11:25:07.231298 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 34 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    1.05062\n",
      "trainer/QF2 Loss                                    1.02079\n",
      "trainer/Policy Loss                                45.0824\n",
      "trainer/Q1 Predictions Mean                       -45.1867\n",
      "trainer/Q1 Predictions Std                         34.5077\n",
      "trainer/Q1 Predictions Max                          7.70319\n",
      "trainer/Q1 Predictions Min                       -104.65\n",
      "trainer/Q2 Predictions Mean                       -45.1182\n",
      "trainer/Q2 Predictions Std                         34.5138\n",
      "trainer/Q2 Predictions Max                          7.56403\n",
      "trainer/Q2 Predictions Min                       -104.524\n",
      "trainer/Q Targets Mean                            -45.5899\n",
      "trainer/Q Targets Std                              34.4208\n",
      "trainer/Q Targets Max                               7.27721\n",
      "trainer/Q Targets Min                            -104.931\n",
      "trainer/Log Pis Mean                                2.97784\n",
      "trainer/Log Pis Std                                 2.45189\n",
      "trainer/Log Pis Max                                10.5154\n",
      "trainer/Log Pis Min                                -4.31327\n",
      "trainer/policy/mean Mean                           -0.287765\n",
      "trainer/policy/mean Std                             0.621986\n",
      "trainer/policy/mean Max                             0.989879\n",
      "trainer/policy/mean Min                            -0.996454\n",
      "trainer/policy/normal/std Mean                      0.383493\n",
      "trainer/policy/normal/std Std                       0.266472\n",
      "trainer/policy/normal/std Max                       1.3391\n",
      "trainer/policy/normal/std Min                       0.0380015\n",
      "trainer/policy/normal/log_std Mean                 -1.25203\n",
      "trainer/policy/normal/log_std Std                   0.832331\n",
      "trainer/policy/normal/log_std Max                   0.291995\n",
      "trainer/policy/normal/log_std Min                  -3.27013\n",
      "trainer/Alpha                                       0.0111785\n",
      "trainer/Alpha Loss                                 -0.0995655\n",
      "exploration/num steps total                    351000\n",
      "exploration/num paths total                      7052\n",
      "exploration/path length Mean                       49.0196\n",
      "exploration/path length Std                         5.46734\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         8\n",
      "exploration/Rewards Mean                           -0.9861\n",
      "exploration/Rewards Std                             0.117076\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -48.3382\n",
      "exploration/Returns Std                             7.05777\n",
      "exploration/Returns Max                            -7\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.36423\n",
      "exploration/Actions Std                             0.572386\n",
      "exploration/Actions Max                             0.999701\n",
      "exploration/Actions Min                            -0.999896\n",
      "exploration/Num Paths                             204\n",
      "exploration/Average Returns                       -48.3382\n",
      "exploration/env_infos/final/is_success Mean         0.0196078\n",
      "exploration/env_infos/final/is_success Std          0.138648\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0004\n",
      "exploration/env_infos/is_success Std                0.019996\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      17390\n",
      "evaluation/num paths total                        351\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -0.83\n",
      "evaluation/Rewards Std                              0.375633\n",
      "evaluation/Rewards Max                             -0\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -41.5\n",
      "evaluation/Returns Std                             17.0015\n",
      "evaluation/Returns Max                             -7\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.195695\n",
      "evaluation/Actions Std                              0.461941\n",
      "evaluation/Actions Max                              0.98248\n",
      "evaluation/Actions Min                             -0.973859\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -41.5\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.971266\n",
      "time/evaluation sampling (s)                       42.8329\n",
      "time/exploration sampling (s)                     771.664\n",
      "time/logging (s)                                    0.0272002\n",
      "time/sac training (s)                             199.588\n",
      "time/saving (s)                                     0.0157535\n",
      "time/training (s)                                   0.00698929\n",
      "time/epoch (s)                                   1015.11\n",
      "time/total (s)                                  49577.4\n",
      "Epoch                                              34\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Evaluation done\n",
      "Epoch 35\n",
      "\n",
      " Cycle 0 35\n",
      "Took to collect: 7.047950744628906\n",
      "Took to train: 6.455950021743774\n",
      "\n",
      " Cycle 1 35\n",
      "Took to collect: 7.668971061706543\n",
      "Took to train: 6.463033676147461\n",
      "\n",
      " Cycle 2 35\n",
      "Took to collect: 8.295598983764648\n",
      "Took to train: 6.465524911880493\n",
      "\n",
      " Cycle 3 35\n",
      "Took to collect: 8.003862142562866\n",
      "Took to train: 6.469835996627808\n",
      "\n",
      " Cycle 4 35\n",
      "Took to collect: 8.680370807647705\n",
      "Took to train: 6.415374755859375\n",
      "\n",
      " Cycle 5 35\n",
      "Took to collect: 9.036759853363037\n",
      "Took to train: 6.457184791564941\n",
      "\n",
      " Cycle 6 35\n",
      "Took to collect: 8.40054202079773\n",
      "Took to train: 6.465318441390991\n",
      "\n",
      " Cycle 7 35\n",
      "Took to collect: 7.8583784103393555\n",
      "Took to train: 6.501061916351318\n",
      "\n",
      " Cycle 8 35\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.2369890213012695\n",
      "Took to train: 6.478410482406616\n",
      "\n",
      " Cycle 9 35\n",
      "Took to collect: 8.872095346450806\n",
      "Took to train: 6.5463645458221436\n",
      "\n",
      " Cycle 10 35\n",
      "Took to collect: 7.611181974411011\n",
      "Took to train: 6.542773962020874\n",
      "\n",
      " Cycle 11 35\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 6.273487567901611\n",
      "Took to train: 6.527596712112427\n",
      "\n",
      " Cycle 12 35\n",
      "Took to collect: 8.952569484710693\n",
      "Took to train: 6.535528182983398\n",
      "\n",
      " Cycle 13 35\n",
      "Took to collect: 6.5830535888671875\n",
      "Took to train: 6.558286905288696\n",
      "\n",
      " Cycle 14 35\n",
      "Took to collect: 8.437626838684082\n",
      "Took to train: 6.475218057632446\n",
      "\n",
      " Cycle 15 35\n",
      "Took to collect: 8.179163694381714\n",
      "Took to train: 6.4669554233551025\n",
      "\n",
      " Cycle 16 35\n",
      "Took to collect: 7.616830825805664\n",
      "Took to train: 6.509652614593506\n",
      "\n",
      " Cycle 17 35\n",
      "Took to collect: 6.659142017364502\n",
      "Took to train: 6.527114629745483\n",
      "\n",
      " Cycle 18 35\n",
      "Took to collect: 6.798737287521362\n",
      "Took to train: 6.472033977508545\n",
      "\n",
      " Cycle 19 35\n",
      "Took to collect: 7.410108804702759\n",
      "Took to train: 6.45557713508606\n",
      "\n",
      " Cycle 20 35\n",
      "Took to collect: 8.340049028396606\n",
      "Took to train: 6.528155565261841\n",
      "\n",
      " Cycle 21 35\n",
      "Took to collect: 6.462589740753174\n",
      "Took to train: 6.485307216644287\n",
      "\n",
      " Cycle 22 35\n",
      "Took to collect: 8.068270206451416\n",
      "Took to train: 6.524186611175537\n",
      "\n",
      " Cycle 23 35\n",
      "Took to collect: 9.587236881256104\n",
      "Took to train: 6.415424346923828\n",
      "\n",
      " Cycle 24 35\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.96763014793396\n",
      "Took to train: 6.467085123062134\n",
      "\n",
      " Cycle 25 35\n",
      "Took to collect: 5.034933090209961\n",
      "Took to train: 6.467489004135132\n",
      "\n",
      " Cycle 26 35\n",
      "Took to collect: 7.203336000442505\n",
      "Took to train: 6.45391321182251\n",
      "\n",
      " Cycle 27 35\n",
      "Took to collect: 7.07656717300415\n",
      "Took to train: 6.294758081436157\n",
      "\n",
      " Cycle 28 35\n",
      "Took to collect: 7.320287227630615\n",
      "Took to train: 6.361414670944214\n",
      "\n",
      " Cycle 29 35\n",
      "Took to collect: 8.589136123657227\n",
      "Took to train: 6.401057004928589\n",
      "\n",
      " Cycle 30 35\n",
      "Took to collect: 7.765604496002197\n",
      "Took to train: 6.324782848358154\n",
      "\n",
      " Cycle 31 35\n",
      "Took to collect: 6.127383708953857\n",
      "Took to train: 6.348132371902466\n",
      "\n",
      " Cycle 32 35\n",
      "Took to collect: 8.409801959991455\n",
      "Took to train: 6.346005201339722\n",
      "\n",
      " Cycle 33 35\n",
      "Took to collect: 8.207025527954102\n",
      "Took to train: 6.388638257980347\n",
      "\n",
      " Cycle 34 35\n",
      "Took to collect: 7.563536643981934\n",
      "Took to train: 6.437262773513794\n",
      "\n",
      " Cycle 35 35\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.828986167907715\n",
      "Took to train: 6.484296798706055\n",
      "\n",
      " Cycle 36 35\n",
      "Took to collect: 7.859313488006592\n",
      "Took to train: 6.288254022598267\n",
      "\n",
      " Cycle 37 35\n",
      "Took to collect: 8.39694857597351\n",
      "Took to train: 6.281773090362549\n",
      "\n",
      " Cycle 38 35\n",
      "Took to collect: 8.302484273910522\n",
      "Took to train: 6.291433572769165\n",
      "\n",
      " Cycle 39 35\n",
      "Took to collect: 7.314502954483032\n",
      "Took to train: 6.479548454284668\n",
      "\n",
      " Cycle 40 35\n",
      "Took to collect: 8.009620904922485\n",
      "Took to train: 6.449193239212036\n",
      "\n",
      " Cycle 41 35\n",
      "Took to collect: 7.437617301940918\n",
      "Took to train: 6.497986793518066\n",
      "\n",
      " Cycle 42 35\n",
      "Took to collect: 7.429729461669922\n",
      "Took to train: 6.469399929046631\n",
      "\n",
      " Cycle 43 35\n",
      "Took to collect: 5.973022699356079\n",
      "Took to train: 6.539870023727417\n",
      "\n",
      " Cycle 44 35\n",
      "Took to collect: 6.718211889266968\n",
      "Took to train: 6.539693117141724\n",
      "\n",
      " Cycle 45 35\n",
      "Took to collect: 8.02041220664978\n",
      "Took to train: 6.44887375831604\n",
      "\n",
      " Cycle 46 35\n",
      "Took to collect: 8.493167638778687\n",
      "Took to train: 6.449262619018555\n",
      "\n",
      " Cycle 47 35\n",
      "Took to collect: 7.827049493789673\n",
      "Took to train: 6.508431434631348\n",
      "\n",
      " Cycle 48 35\n",
      "Took to collect: 7.83107852935791\n",
      "Took to train: 6.470201253890991\n",
      "\n",
      " Cycle 49 35\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 8.140717029571533\n",
      "Took to train: 6.545265197753906\n",
      "\n",
      " Cycle 50 35\n",
      "Took to collect: 8.568177700042725\n",
      "Took to train: 6.532155513763428\n",
      "\n",
      " Cycle 51 35\n",
      "Took to collect: 8.024726390838623\n",
      "Took to train: 6.51828932762146\n",
      "\n",
      " Cycle 52 35\n",
      "Took to collect: 7.66732120513916\n",
      "Took to train: 6.53420615196228\n",
      "\n",
      " Cycle 53 35\n",
      "Took to collect: 9.190563440322876\n",
      "Took to train: 6.488920211791992\n",
      "\n",
      " Cycle 54 35\n",
      "Took to collect: 8.884960412979126\n",
      "Took to train: 6.5360424518585205\n",
      "\n",
      " Cycle 55 35\n",
      "Took to collect: 7.080229043960571\n",
      "Took to train: 6.531279802322388\n",
      "\n",
      " Cycle 56 35\n",
      "Took to collect: 7.186897277832031\n",
      "Took to train: 6.437527418136597\n",
      "\n",
      " Cycle 57 35\n",
      "Took to collect: 9.414391279220581\n",
      "Took to train: 6.436062574386597\n",
      "\n",
      " Cycle 58 35\n",
      "Took to collect: 7.338851451873779\n",
      "Took to train: 6.468061208724976\n",
      "\n",
      " Cycle 59 35\n",
      "Took to collect: 7.965136289596558\n",
      "Took to train: 6.4225380420684814\n",
      "\n",
      " Cycle 60 35\n",
      "Took to collect: 8.30081057548523\n",
      "Took to train: 6.403532266616821\n",
      "\n",
      " Cycle 61 35\n",
      "Took to collect: 7.566482782363892\n",
      "Took to train: 6.415280818939209\n",
      "\n",
      " Cycle 62 35\n",
      "Took to collect: 7.987317085266113\n",
      "Took to train: 6.402151823043823\n",
      "\n",
      " Cycle 63 35\n",
      "Took to collect: 9.888496160507202\n",
      "Took to train: 6.407137155532837\n",
      "\n",
      " Cycle 64 35\n",
      "Took to collect: 7.997896432876587\n",
      "Took to train: 6.409345388412476\n",
      "\n",
      " Cycle 65 35\n",
      "Took to collect: 8.591874122619629\n",
      "Took to train: 6.408247470855713\n",
      "\n",
      " Cycle 66 35\n",
      "Took to collect: 6.377798318862915\n",
      "Took to train: 6.396062850952148\n",
      "\n",
      " Cycle 67 35\n",
      "Took to collect: 6.139585018157959\n",
      "Took to train: 6.409921407699585\n",
      "\n",
      " Cycle 68 35\n",
      "Took to collect: 8.901679277420044\n",
      "Took to train: 6.409330368041992\n",
      "\n",
      " Cycle 69 35\n",
      "Took to collect: 8.100170135498047\n",
      "Took to train: 6.40603494644165\n",
      "\n",
      " Cycle 70 35\n",
      "Took to collect: 9.35974407196045\n",
      "Took to train: 6.406768560409546\n",
      "\n",
      " Cycle 71 35\n",
      "Took to collect: 6.229082345962524\n",
      "Took to train: 6.416339635848999\n",
      "\n",
      " Cycle 72 35\n",
      "Took to collect: 7.369973182678223\n",
      "Took to train: 6.499183177947998\n",
      "\n",
      " Cycle 73 35\n",
      "Took to collect: 7.812174558639526\n",
      "Took to train: 6.548539638519287\n",
      "\n",
      " Cycle 74 35\n",
      "Took to collect: 8.913223028182983\n",
      "Took to train: 6.4015045166015625\n",
      "\n",
      " Cycle 75 35\n",
      "Took to collect: 7.422060489654541\n",
      "Took to train: 6.407559871673584\n",
      "\n",
      " Cycle 76 35\n",
      "Took to collect: 9.334979057312012\n",
      "Took to train: 6.42443060874939\n",
      "\n",
      " Cycle 77 35\n",
      "Took to collect: 7.803495168685913\n",
      "Took to train: 6.366647481918335\n",
      "\n",
      " Cycle 78 35\n",
      "Took to collect: 7.166247367858887\n",
      "Took to train: 6.353180408477783\n",
      "\n",
      " Cycle 79 35\n",
      "Took to collect: 5.9791083335876465\n",
      "Took to train: 6.350401878356934\n",
      "\n",
      " Cycle 80 35\n",
      "Took to collect: 8.383373022079468\n",
      "Took to train: 6.349510908126831\n",
      "\n",
      " Cycle 81 35\n",
      "Took to collect: 8.689764499664307\n",
      "Took to train: 6.340151786804199\n",
      "\n",
      " Cycle 82 35\n",
      "Took to collect: 6.636899948120117\n",
      "Took to train: 6.343761920928955\n",
      "\n",
      " Cycle 83 35\n",
      "Took to collect: 7.329153537750244\n",
      "Took to train: 6.426918268203735\n",
      "\n",
      " Cycle 84 35\n",
      "Took to collect: 6.194292306900024\n",
      "Took to train: 6.506819009780884\n",
      "\n",
      " Cycle 85 35\n",
      "Took to collect: 8.912847995758057\n",
      "Took to train: 6.49579930305481\n",
      "\n",
      " Cycle 86 35\n",
      "Took to collect: 8.049209356307983\n",
      "Took to train: 6.398446559906006\n",
      "\n",
      " Cycle 87 35\n",
      "Took to collect: 6.164779424667358\n",
      "Took to train: 6.356034278869629\n",
      "\n",
      " Cycle 88 35\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 5.537682056427002\n",
      "Took to train: 6.372996807098389\n",
      "\n",
      " Cycle 89 35\n",
      "Took to collect: 7.642695188522339\n",
      "Took to train: 6.391963958740234\n",
      "\n",
      " Cycle 90 35\n",
      "Took to collect: 6.126364707946777\n",
      "Took to train: 6.3520402908325195\n",
      "\n",
      " Cycle 91 35\n",
      "Took to collect: 7.2885422706604\n",
      "Took to train: 6.379413604736328\n",
      "\n",
      " Cycle 92 35\n",
      "Took to collect: 7.011973142623901\n",
      "Took to train: 6.356074333190918\n",
      "\n",
      " Cycle 93 35\n",
      "Took to collect: 6.633736848831177\n",
      "Took to train: 6.440033912658691\n",
      "\n",
      " Cycle 94 35\n",
      "Took to collect: 6.070984125137329\n",
      "Took to train: 6.472001552581787\n",
      "\n",
      " Cycle 95 35\n",
      "Took to collect: 5.6506829261779785\n",
      "Took to train: 6.4306488037109375\n",
      "\n",
      " Cycle 96 35\n",
      "Took to collect: 6.8191728591918945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.513665676116943\n",
      "\n",
      " Cycle 97 35\n",
      "Took to collect: 5.851372003555298\n",
      "Took to train: 6.678555488586426\n",
      "\n",
      " Cycle 98 35\n",
      "Took to collect: 7.041784286499023\n",
      "Took to train: 6.688416242599487\n",
      "\n",
      " Cycle 99 35\n",
      "Took to collect: 7.7162182331085205\n",
      "Took to train: 6.567455768585205\n",
      "Time collect avg cycle: 7.632446517944336\n",
      "Time train avg cycle: 6.4478328418731685\n",
      "Total avg cycle: 14.090330812931061\n",
      "Ending epoch\n",
      "2020-10-26 11:49:19.319281 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 35 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    1.24413\n",
      "trainer/QF2 Loss                                    1.08327\n",
      "trainer/Policy Loss                                44.991\n",
      "trainer/Q1 Predictions Mean                       -44.995\n",
      "trainer/Q1 Predictions Std                         34.6692\n",
      "trainer/Q1 Predictions Max                          3.71788\n",
      "trainer/Q1 Predictions Min                       -104.831\n",
      "trainer/Q2 Predictions Mean                       -44.9201\n",
      "trainer/Q2 Predictions Std                         34.7282\n",
      "trainer/Q2 Predictions Max                          3.66543\n",
      "trainer/Q2 Predictions Min                       -104.805\n",
      "trainer/Q Targets Mean                            -44.8138\n",
      "trainer/Q Targets Std                              34.5893\n",
      "trainer/Q Targets Max                               4.32691\n",
      "trainer/Q Targets Min                            -104.916\n",
      "trainer/Log Pis Mean                                2.80142\n",
      "trainer/Log Pis Std                                 2.46668\n",
      "trainer/Log Pis Max                                 9.31296\n",
      "trainer/Log Pis Min                                -5.78355\n",
      "trainer/policy/mean Mean                           -0.273337\n",
      "trainer/policy/mean Std                             0.604627\n",
      "trainer/policy/mean Max                             0.9922\n",
      "trainer/policy/mean Min                            -0.99523\n",
      "trainer/policy/normal/std Mean                      0.368354\n",
      "trainer/policy/normal/std Std                       0.264625\n",
      "trainer/policy/normal/std Max                       1.51809\n",
      "trainer/policy/normal/std Min                       0.0416317\n",
      "trainer/policy/normal/log_std Mean                 -1.29436\n",
      "trainer/policy/normal/log_std Std                   0.823869\n",
      "trainer/policy/normal/log_std Max                   0.417451\n",
      "trainer/policy/normal/log_std Min                  -3.17889\n",
      "trainer/Alpha                                       0.010946\n",
      "trainer/Alpha Loss                                 -0.896545\n",
      "exploration/num steps total                    361000\n",
      "exploration/num paths total                      7258\n",
      "exploration/path length Mean                       48.5437\n",
      "exploration/path length Std                         6.91807\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                         8\n",
      "exploration/Rewards Mean                           -0.9962\n",
      "exploration/Rewards Std                             0.0615269\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -48.3592\n",
      "exploration/Returns Std                             7.31318\n",
      "exploration/Returns Max                            -7\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.36554\n",
      "exploration/Actions Std                             0.579498\n",
      "exploration/Actions Max                             0.999774\n",
      "exploration/Actions Min                            -0.999744\n",
      "exploration/Num Paths                             206\n",
      "exploration/Average Returns                       -48.3592\n",
      "exploration/env_infos/final/is_success Mean         0.0291262\n",
      "exploration/env_infos/final/is_success Std          0.16816\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0006\n",
      "exploration/env_infos/is_success Std                0.0244875\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      17851\n",
      "evaluation/num paths total                        361\n",
      "evaluation/path length Mean                        46.1\n",
      "evaluation/path length Std                         11.7\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         11\n",
      "evaluation/Rewards Mean                            -0.900217\n",
      "evaluation/Rewards Std                              0.299711\n",
      "evaluation/Rewards Max                             -0\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -41.5\n",
      "evaluation/Returns Std                             16.2804\n",
      "evaluation/Returns Max                             -8\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.237541\n",
      "evaluation/Actions Std                              0.505258\n",
      "evaluation/Actions Max                              0.977221\n",
      "evaluation/Actions Min                             -0.990197\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -41.5\n",
      "evaluation/env_infos/final/is_success Mean          0.1\n",
      "evaluation/env_infos/final/is_success Std           0.3\n",
      "evaluation/env_infos/final/is_success Max           1\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0.0021692\n",
      "evaluation/env_infos/is_success Std                 0.0465241\n",
      "evaluation/env_infos/is_success Max                 1\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.979443\n",
      "time/evaluation sampling (s)                       42.9865\n",
      "time/exploration sampling (s)                     763.264\n",
      "time/logging (s)                                    0.0274509\n",
      "time/sac training (s)                             200.781\n",
      "time/saving (s)                                     0.0195632\n",
      "time/training (s)                                   0.00707766\n",
      "time/epoch (s)                                   1008.07\n",
      "time/total (s)                                  51029.3\n",
      "Epoch                                              35\n",
      "---------------------------------------------  ---------------\n",
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 36\n",
      "\n",
      " Cycle 0 36\n",
      "Took to collect: 7.681619644165039\n",
      "Took to train: 6.346388339996338\n",
      "\n",
      " Cycle 1 36\n",
      "Took to collect: 7.684150457382202\n",
      "Took to train: 6.369467258453369\n",
      "\n",
      " Cycle 2 36\n",
      "Took to collect: 7.983064651489258\n",
      "Took to train: 6.545298099517822\n",
      "\n",
      " Cycle 3 36\n",
      "Took to collect: 7.049819231033325\n",
      "Took to train: 6.529791355133057\n",
      "\n",
      " Cycle 4 36\n",
      "Took to collect: 8.053919076919556\n",
      "Took to train: 6.544800281524658\n",
      "\n",
      " Cycle 5 36\n",
      "Took to collect: 6.237489938735962\n",
      "Took to train: 6.475766181945801\n",
      "\n",
      " Cycle 6 36\n",
      "Took to collect: 6.695555686950684\n",
      "Took to train: 6.377176761627197\n",
      "\n",
      " Cycle 7 36\n",
      "Took to collect: 6.131592273712158\n",
      "Took to train: 6.415469408035278\n",
      "\n",
      " Cycle 8 36\n",
      "Took to collect: 7.656515121459961\n",
      "Took to train: 6.420804500579834\n",
      "\n",
      " Cycle 9 36\n",
      "Took to collect: 7.17994499206543\n",
      "Took to train: 6.415102481842041\n",
      "\n",
      " Cycle 10 36\n",
      "Took to collect: 5.276154279708862\n",
      "Took to train: 6.419928550720215\n",
      "\n",
      " Cycle 11 36\n",
      "Took to collect: 7.6404712200164795\n",
      "Took to train: 6.37670111656189\n",
      "\n",
      " Cycle 12 36\n",
      "Took to collect: 6.802164077758789\n",
      "Took to train: 6.363887786865234\n",
      "\n",
      " Cycle 13 36\n",
      "Took to collect: 6.805853843688965\n",
      "Took to train: 6.371417999267578\n",
      "\n",
      " Cycle 14 36\n",
      "Took to collect: 6.382902145385742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took to train: 6.34877872467041\n",
      "\n",
      " Cycle 15 36\n",
      "Took to collect: 6.271400451660156\n",
      "Took to train: 6.412549257278442\n",
      "\n",
      " Cycle 16 36\n",
      "Took to collect: 6.086228847503662\n",
      "Took to train: 6.41936182975769\n",
      "\n",
      " Cycle 17 36\n",
      "Took to collect: 6.825148344039917\n",
      "Took to train: 6.418107748031616\n",
      "\n",
      " Cycle 18 36\n",
      "Took to collect: 7.011656761169434\n",
      "Took to train: 6.41347074508667\n",
      "\n",
      " Cycle 19 36\n",
      "Took to collect: 6.985495567321777\n",
      "Took to train: 6.398620843887329\n",
      "\n",
      " Cycle 20 36\n",
      "Took to collect: 6.347913980484009\n",
      "Took to train: 6.358630895614624\n",
      "\n",
      " Cycle 21 36\n",
      "Took to collect: 6.48455548286438\n",
      "Took to train: 6.345266342163086\n",
      "\n",
      " Cycle 22 36\n",
      "Took to collect: 6.3680419921875\n",
      "Took to train: 6.34990930557251\n",
      "\n",
      " Cycle 23 36\n",
      "Took to collect: 6.486955165863037\n",
      "Took to train: 6.3526434898376465\n",
      "\n",
      " Cycle 24 36\n",
      "Took to collect: 8.23716402053833\n",
      "Took to train: 6.416043519973755\n",
      "\n",
      " Cycle 25 36\n",
      "Took to collect: 6.430552244186401\n",
      "Took to train: 6.461764335632324\n",
      "\n",
      " Cycle 26 36\n",
      "Took to collect: 6.941339015960693\n",
      "Took to train: 6.384401321411133\n",
      "\n",
      " Cycle 27 36\n",
      "Took to collect: 6.704216480255127\n",
      "Took to train: 6.4064507484436035\n",
      "\n",
      " Cycle 28 36\n",
      "Took to collect: 8.203084230422974\n",
      "Took to train: 6.4679625034332275\n",
      "\n",
      " Cycle 29 36\n",
      "Took to collect: 7.90696120262146\n",
      "Took to train: 6.4738452434539795\n",
      "\n",
      " Cycle 30 36\n",
      "Took to collect: 7.346365213394165\n",
      "Took to train: 6.463102340698242\n",
      "\n",
      " Cycle 31 36\n",
      "Took to collect: 5.614579200744629\n",
      "Took to train: 6.475594997406006\n",
      "\n",
      " Cycle 32 36\n",
      "Took to collect: 7.000232696533203\n",
      "Took to train: 6.456954717636108\n",
      "\n",
      " Cycle 33 36\n",
      "Took to collect: 6.033625841140747\n",
      "Took to train: 6.483455657958984\n",
      "\n",
      " Cycle 34 36\n",
      "Took to collect: 6.879699230194092\n",
      "Took to train: 6.388094186782837\n",
      "\n",
      " Cycle 35 36\n",
      "Took to collect: 7.385664224624634\n",
      "Took to train: 6.459332227706909\n",
      "\n",
      " Cycle 36 36\n",
      "Took to collect: 7.358054876327515\n",
      "Took to train: 6.43104100227356\n",
      "\n",
      " Cycle 37 36\n",
      "Took to collect: 8.121758937835693\n",
      "Took to train: 6.423203945159912\n",
      "\n",
      " Cycle 38 36\n",
      "Took to collect: 7.607729196548462\n",
      "Took to train: 6.2965099811553955\n",
      "\n",
      " Cycle 39 36\n",
      "Took to collect: 7.702056646347046\n",
      "Took to train: 6.293469667434692\n",
      "\n",
      " Cycle 40 36\n",
      "Took to collect: 7.458085298538208\n",
      "Took to train: 6.283317804336548\n",
      "\n",
      " Cycle 41 36\n",
      "Took to collect: 6.36774468421936\n",
      "Took to train: 6.28525447845459\n",
      "\n",
      " Cycle 42 36\n",
      "Took to collect: 6.398016929626465\n",
      "Took to train: 6.423583030700684\n",
      "\n",
      " Cycle 43 36\n",
      "Took to collect: 5.673837900161743\n",
      "Took to train: 6.442457437515259\n",
      "\n",
      " Cycle 44 36\n",
      "Took to collect: 7.048628330230713\n",
      "Took to train: 6.316593647003174\n",
      "\n",
      " Cycle 45 36\n",
      "Took to collect: 6.945042848587036\n",
      "Took to train: 6.440038204193115\n",
      "\n",
      " Cycle 46 36\n",
      "Took to collect: 6.723710536956787\n",
      "Took to train: 6.413351774215698\n",
      "\n",
      " Cycle 47 36\n",
      "Took to collect: 8.283079147338867\n",
      "Took to train: 6.458549499511719\n",
      "\n",
      " Cycle 48 36\n",
      "Took to collect: 7.26869010925293\n",
      "Took to train: 6.388333082199097\n",
      "\n",
      " Cycle 49 36\n",
      "Took to collect: 6.644008636474609\n",
      "Took to train: 6.41044020652771\n",
      "\n",
      " Cycle 50 36\n",
      "Took to collect: 6.800567626953125\n",
      "Took to train: 6.428245782852173\n",
      "\n",
      " Cycle 51 36\n",
      "Took to collect: 6.913316965103149\n",
      "Took to train: 6.4366021156311035\n",
      "\n",
      " Cycle 52 36\n",
      "Took to collect: 6.33098578453064\n",
      "Took to train: 6.453208684921265\n",
      "\n",
      " Cycle 53 36\n",
      "Took to collect: 7.339919328689575\n",
      "Took to train: 6.45361065864563\n",
      "\n",
      " Cycle 54 36\n",
      "Took to collect: 6.720898866653442\n",
      "Took to train: 6.470871210098267\n",
      "\n",
      " Cycle 55 36\n",
      "Took to collect: 5.503727436065674\n",
      "Took to train: 6.512204170227051\n",
      "\n",
      " Cycle 56 36\n",
      "Took to collect: 6.399755954742432\n",
      "Took to train: 6.492469072341919\n",
      "\n",
      " Cycle 57 36\n",
      "Took to collect: 7.657250881195068\n",
      "Took to train: 6.5126776695251465\n",
      "\n",
      " Cycle 58 36\n",
      "Took to collect: 6.538689374923706\n",
      "Took to train: 6.505330801010132\n",
      "\n",
      " Cycle 59 36\n",
      "Took to collect: 6.213196516036987\n",
      "Took to train: 6.509704351425171\n",
      "\n",
      " Cycle 60 36\n",
      "Took to collect: 5.873111009597778\n",
      "Took to train: 6.4347288608551025\n",
      "\n",
      " Cycle 61 36\n",
      "Took to collect: 6.424772024154663\n",
      "Took to train: 6.4767539501190186\n",
      "\n",
      " Cycle 62 36\n",
      "Took to collect: 6.768671751022339\n",
      "Took to train: 6.43560004234314\n",
      "\n",
      " Cycle 63 36\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 6.354181289672852\n",
      "Took to train: 6.4972803592681885\n",
      "\n",
      " Cycle 64 36\n",
      "Took to collect: 8.589388608932495\n",
      "Took to train: 6.499831199645996\n",
      "\n",
      " Cycle 65 36\n",
      "Took to collect: 7.743569612503052\n",
      "Took to train: 6.481655597686768\n",
      "\n",
      " Cycle 66 36\n",
      "Took to collect: 7.8044867515563965\n",
      "Took to train: 6.462887763977051\n",
      "\n",
      " Cycle 67 36\n",
      "Took to collect: 6.607499361038208\n",
      "Took to train: 6.437107086181641\n",
      "\n",
      " Cycle 68 36\n",
      "Took to collect: 9.628120183944702\n",
      "Took to train: 6.5530846118927\n",
      "\n",
      " Cycle 69 36\n",
      "Took to collect: 6.688000202178955\n",
      "Took to train: 6.432522296905518\n",
      "\n",
      " Cycle 70 36\n",
      "Took to collect: 7.352542161941528\n",
      "Took to train: 6.3438920974731445\n",
      "\n",
      " Cycle 71 36\n",
      "Took to collect: 7.264951944351196\n",
      "Took to train: 6.390965938568115\n",
      "\n",
      " Cycle 72 36\n",
      "Took to collect: 6.867768287658691\n",
      "Took to train: 6.417445659637451\n",
      "\n",
      " Cycle 73 36\n",
      "Took to collect: 5.708826541900635\n",
      "Took to train: 6.414286851882935\n",
      "\n",
      " Cycle 74 36\n",
      "Took to collect: 7.930621147155762\n",
      "Took to train: 6.367335796356201\n",
      "\n",
      " Cycle 75 36\n",
      "Took to collect: 7.540956735610962\n",
      "Took to train: 6.345186948776245\n",
      "\n",
      " Cycle 76 36\n",
      "Took to collect: 7.681517839431763\n",
      "Took to train: 6.344235181808472\n",
      "\n",
      " Cycle 77 36\n",
      "Took to collect: 5.630478620529175\n",
      "Took to train: 6.337064981460571\n",
      "\n",
      " Cycle 78 36\n",
      "Took to collect: 7.4563305377960205\n",
      "Took to train: 6.4272966384887695\n",
      "\n",
      " Cycle 79 36\n",
      "Took to collect: 7.189234018325806\n",
      "Took to train: 6.538919448852539\n",
      "\n",
      " Cycle 80 36\n",
      "Took to collect: 7.021932363510132\n",
      "Took to train: 9.367538452148438\n",
      "\n",
      " Cycle 81 36\n",
      "Took to collect: 7.753784418106079\n",
      "Took to train: 10.212995767593384\n",
      "\n",
      " Cycle 82 36\n",
      "Took to collect: 6.378781795501709\n",
      "Took to train: 10.392128229141235\n",
      "\n",
      " Cycle 83 36\n",
      "Took to collect: 8.175195693969727\n",
      "Took to train: 10.325522422790527\n",
      "\n",
      " Cycle 84 36\n",
      "Took to collect: 7.642993688583374\n",
      "Took to train: 8.862035512924194\n",
      "\n",
      " Cycle 85 36\n",
      "Took to collect: 8.225484609603882\n",
      "Took to train: 10.325863122940063\n",
      "\n",
      " Cycle 86 36\n",
      "Took to collect: 7.887898206710815\n",
      "Took to train: 10.334104776382446\n",
      "\n",
      " Cycle 87 36\n",
      "Took to collect: 6.150352716445923\n",
      "Took to train: 9.22869610786438\n",
      "\n",
      " Cycle 88 36\n",
      "Took to collect: 6.27851676940918\n",
      "Took to train: 10.432955265045166\n",
      "\n",
      " Cycle 89 36\n",
      "Took to collect: 6.309541940689087\n",
      "Took to train: 9.987213134765625\n",
      "\n",
      " Cycle 90 36\n",
      "Took to collect: 7.896662950515747\n",
      "Took to train: 8.892550230026245\n",
      "\n",
      " Cycle 91 36\n",
      "Took to collect: 7.396929740905762\n",
      "Took to train: 10.450316429138184\n",
      "\n",
      " Cycle 92 36\n",
      "Took to collect: 7.9704368114471436\n",
      "Took to train: 10.544844388961792\n",
      "\n",
      " Cycle 93 36\n",
      "Took to collect: 7.9302685260772705\n",
      "Took to train: 8.868513107299805\n",
      "\n",
      " Cycle 94 36\n",
      "Took to collect: 8.482934951782227\n",
      "Took to train: 9.082410097122192\n",
      "\n",
      " Cycle 95 36\n",
      "Took to collect: 6.104870557785034\n",
      "Took to train: 9.259888410568237\n",
      "\n",
      " Cycle 96 36\n",
      "Took to collect: 6.616208791732788\n",
      "Took to train: 10.220669031143188\n",
      "\n",
      " Cycle 97 36\n",
      "Took to collect: 7.464656591415405\n",
      "Took to train: 9.789225816726685\n",
      "\n",
      " Cycle 98 36\n",
      "Took to collect: 6.087089538574219\n",
      "Took to train: 9.444655418395996\n",
      "\n",
      " Cycle 99 36\n",
      "Took to collect: 7.529675483703613\n",
      "Took to train: 9.607695579528809\n",
      "Time collect avg cycle: 7.032400944232941\n",
      "Time train avg cycle: 7.094753119945526\n",
      "Total avg cycle: 14.137308156490326\n",
      "Ending epoch\n",
      "2020-10-26 12:13:31.463269 EET | [her-sac-validation-newrange-3cm-run-1_2020_10_25_21_38_43_0000--s-0] Epoch 36 finished\n",
      "Logged tensorboard\n",
      "---------------------------------------------  ---------------\n",
      "trainer/num train calls                             0\n",
      "trainer/QF1 Loss                                    1.01411\n",
      "trainer/QF2 Loss                                    0.996851\n",
      "trainer/Policy Loss                                45.5162\n",
      "trainer/Q1 Predictions Mean                       -45.5336\n",
      "trainer/Q1 Predictions Std                         34.3386\n",
      "trainer/Q1 Predictions Max                         12.646\n",
      "trainer/Q1 Predictions Min                       -104.809\n",
      "trainer/Q2 Predictions Mean                       -45.5884\n",
      "trainer/Q2 Predictions Std                         34.3496\n",
      "trainer/Q2 Predictions Max                         12.9241\n",
      "trainer/Q2 Predictions Min                       -104.694\n",
      "trainer/Q Targets Mean                            -45.5161\n",
      "trainer/Q Targets Std                              34.3561\n",
      "trainer/Q Targets Max                              12.9919\n",
      "trainer/Q Targets Min                            -104.61\n",
      "trainer/Log Pis Mean                                3.02\n",
      "trainer/Log Pis Std                                 2.40281\n",
      "trainer/Log Pis Max                                11.8534\n",
      "trainer/Log Pis Min                                -5.05587\n",
      "trainer/policy/mean Mean                           -0.325185\n",
      "trainer/policy/mean Std                             0.611504\n",
      "trainer/policy/mean Max                             0.990461\n",
      "trainer/policy/mean Min                            -0.994886\n",
      "trainer/policy/normal/std Mean                      0.373351\n",
      "trainer/policy/normal/std Std                       0.236265\n",
      "trainer/policy/normal/std Max                       1.22909\n",
      "trainer/policy/normal/std Min                       0.0408536\n",
      "trainer/policy/normal/log_std Mean                 -1.24996\n",
      "trainer/policy/normal/log_std Std                   0.799976\n",
      "trainer/policy/normal/log_std Max                   0.206276\n",
      "trainer/policy/normal/log_std Min                  -3.19776\n",
      "trainer/Alpha                                       0.0120334\n",
      "trainer/Alpha Loss                                  0.0884061\n",
      "exploration/num steps total                    371000\n",
      "exploration/num paths total                      7459\n",
      "exploration/path length Mean                       49.7512\n",
      "exploration/path length Std                         2.71312\n",
      "exploration/path length Max                        50\n",
      "exploration/path length Min                        14\n",
      "exploration/Rewards Mean                           -0.9954\n",
      "exploration/Rewards Std                             0.0676671\n",
      "exploration/Rewards Max                            -0\n",
      "exploration/Rewards Min                            -1\n",
      "exploration/Returns Mean                          -49.5224\n",
      "exploration/Returns Std                             3.13236\n",
      "exploration/Returns Max                           -13\n",
      "exploration/Returns Min                           -50\n",
      "exploration/Actions Mean                           -0.414183\n",
      "exploration/Actions Std                             0.550886\n",
      "exploration/Actions Max                             0.999188\n",
      "exploration/Actions Min                            -0.999786\n",
      "exploration/Num Paths                             201\n",
      "exploration/Average Returns                       -49.5224\n",
      "exploration/env_infos/final/is_success Mean         0.00497512\n",
      "exploration/env_infos/final/is_success Std          0.0703589\n",
      "exploration/env_infos/final/is_success Max          1\n",
      "exploration/env_infos/final/is_success Min          0\n",
      "exploration/env_infos/initial/is_success Mean       0\n",
      "exploration/env_infos/initial/is_success Std        0\n",
      "exploration/env_infos/initial/is_success Max        0\n",
      "exploration/env_infos/initial/is_success Min        0\n",
      "exploration/env_infos/is_success Mean               0.0001\n",
      "exploration/env_infos/is_success Std                0.0099995\n",
      "exploration/env_infos/is_success Max                1\n",
      "exploration/env_infos/is_success Min                0\n",
      "evaluation/num steps total                      18351\n",
      "evaluation/num paths total                        371\n",
      "evaluation/path length Mean                        50\n",
      "evaluation/path length Std                          0\n",
      "evaluation/path length Max                         50\n",
      "evaluation/path length Min                         50\n",
      "evaluation/Rewards Mean                            -0.932\n",
      "evaluation/Rewards Std                              0.251746\n",
      "evaluation/Rewards Max                             -0\n",
      "evaluation/Rewards Min                             -1\n",
      "evaluation/Returns Mean                           -46.6\n",
      "evaluation/Returns Std                             10.2\n",
      "evaluation/Returns Max                            -16\n",
      "evaluation/Returns Min                            -50\n",
      "evaluation/Actions Mean                            -0.315912\n",
      "evaluation/Actions Std                              0.442326\n",
      "evaluation/Actions Max                              0.982034\n",
      "evaluation/Actions Min                             -0.991224\n",
      "evaluation/Num Paths                               10\n",
      "evaluation/Average Returns                        -46.6\n",
      "evaluation/env_infos/final/is_success Mean          0\n",
      "evaluation/env_infos/final/is_success Std           0\n",
      "evaluation/env_infos/final/is_success Max           0\n",
      "evaluation/env_infos/final/is_success Min           0\n",
      "evaluation/env_infos/initial/is_success Mean        0\n",
      "evaluation/env_infos/initial/is_success Std         0\n",
      "evaluation/env_infos/initial/is_success Max         0\n",
      "evaluation/env_infos/initial/is_success Min         0\n",
      "evaluation/env_infos/is_success Mean                0\n",
      "evaluation/env_infos/is_success Std                 0\n",
      "evaluation/env_infos/is_success Max                 0\n",
      "evaluation/env_infos/is_success Min                 0\n",
      "time/data storing (s)                               0.985609\n",
      "time/evaluation sampling (s)                       38.3396\n",
      "time/exploration sampling (s)                     703.263\n",
      "time/logging (s)                                    0.0271991\n",
      "time/sac training (s)                             235.986\n",
      "time/saving (s)                                     0.0234155\n",
      "time/training (s)                                   0.0083334\n",
      "time/epoch (s)                                    978.634\n",
      "time/total (s)                                  52481.2\n",
      "Epoch                                              36\n",
      "---------------------------------------------  ---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving current model\n",
      "Saved current model\n",
      "Evaluation sampling\n",
      "Image capture\n",
      "Evaluation done\n",
      "Epoch 37\n",
      "\n",
      " Cycle 0 37\n",
      "Took to collect: 8.007899045944214\n",
      "Took to train: 9.381683588027954\n",
      "\n",
      " Cycle 1 37\n",
      "Took to collect: 6.601903915405273\n",
      "Took to train: 8.770957708358765\n",
      "\n",
      " Cycle 2 37\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 6.732427597045898\n",
      "Took to train: 9.292103052139282\n",
      "\n",
      " Cycle 3 37\n",
      "Took to collect: 6.743898153305054\n",
      "Took to train: 9.548550367355347\n",
      "\n",
      " Cycle 4 37\n",
      "Took to collect: 7.5219244956970215\n",
      "Took to train: 8.87654423713684\n",
      "\n",
      " Cycle 5 37\n",
      "Took to collect: 6.770971775054932\n",
      "Took to train: 9.517401218414307\n",
      "\n",
      " Cycle 6 37\n",
      "Took to collect: 6.328049659729004\n",
      "Took to train: 9.645450115203857\n",
      "\n",
      " Cycle 7 37\n",
      "Took to collect: 7.666834831237793\n",
      "Took to train: 9.548575401306152\n",
      "\n",
      " Cycle 8 37\n",
      "Took to collect: 7.962104558944702\n",
      "Took to train: 9.56955885887146\n",
      "\n",
      " Cycle 9 37\n",
      "Took to collect: 6.323528528213501\n",
      "Took to train: 9.576058149337769\n",
      "\n",
      " Cycle 10 37\n",
      "Took to collect: 7.499853610992432\n",
      "Took to train: 8.705277681350708\n",
      "\n",
      " Cycle 11 37\n",
      "Took to collect: 5.557871580123901\n",
      "Took to train: 9.632115125656128\n",
      "\n",
      " Cycle 12 37\n",
      "Took to collect: 7.970834732055664\n",
      "Took to train: 9.099496126174927\n",
      "\n",
      " Cycle 13 37\n",
      "Took to collect: 6.835201740264893\n",
      "Took to train: 9.67080307006836\n",
      "\n",
      " Cycle 14 37\n",
      "Took to collect: 6.381415605545044\n",
      "Took to train: 9.49654245376587\n",
      "\n",
      " Cycle 15 37\n",
      "Took to collect: 6.054824590682983\n",
      "Took to train: 9.657353639602661\n",
      "\n",
      " Cycle 16 37\n",
      "Took to collect: 6.072141408920288\n",
      "Took to train: 9.79059886932373\n",
      "\n",
      " Cycle 17 37\n",
      "Took to collect: 5.784032344818115\n",
      "Took to train: 9.000211000442505\n",
      "\n",
      " Cycle 18 37\n",
      "Took to collect: 6.427338600158691\n",
      "Took to train: 8.931892156600952\n",
      "\n",
      " Cycle 19 37\n",
      "Took to collect: 7.5396623611450195\n",
      "Took to train: 9.346937894821167\n",
      "\n",
      " Cycle 20 37\n",
      "Took to collect: 7.578118801116943\n",
      "Took to train: 9.83622431755066\n",
      "\n",
      " Cycle 21 37\n",
      "Took to collect: 8.328052282333374\n",
      "Took to train: 9.898139953613281\n",
      "\n",
      " Cycle 22 37\n",
      "Took to collect: 8.344180822372437\n",
      "Took to train: 9.036028146743774\n",
      "\n",
      " Cycle 23 37\n",
      "Took to collect: 6.422987937927246\n",
      "Took to train: 9.898527383804321\n",
      "\n",
      " Cycle 24 37\n",
      "Took to collect: 6.425610780715942\n",
      "Took to train: 9.959411144256592\n",
      "\n",
      " Cycle 25 37\n",
      "Took to collect: 7.149439811706543\n",
      "Took to train: 8.901651620864868\n",
      "\n",
      " Cycle 26 37\n",
      "Took to collect: 6.496252775192261\n",
      "Took to train: 10.065847635269165\n",
      "\n",
      " Cycle 27 37\n",
      "Took to collect: 6.671704292297363\n",
      "Took to train: 10.03050184249878\n",
      "\n",
      " Cycle 28 37\n",
      "Took to collect: 7.3276941776275635\n",
      "Took to train: 9.602232694625854\n",
      "\n",
      " Cycle 29 37\n",
      "Took to collect: 6.9669413566589355\n",
      "Took to train: 8.974068403244019\n",
      "\n",
      " Cycle 30 37\n",
      "Took to collect: 5.6699748039245605\n",
      "Took to train: 10.075826644897461\n",
      "\n",
      " Cycle 31 37\n",
      "Real sim success -0.0 {'is_success': 1.0}\n",
      "Took to collect: 7.961967468261719\n",
      "Took to train: 9.44344425201416\n",
      "\n",
      " Cycle 32 37\n",
      "Took to collect: 6.591160297393799\n",
      "Took to train: 9.520112991333008\n",
      "\n",
      " Cycle 33 37\n",
      "Took to collect: 6.6060631275177\n",
      "Took to train: 10.061869144439697\n",
      "\n",
      " Cycle 34 37\n",
      "Took to collect: 7.07569146156311\n",
      "Took to train: 9.076125621795654\n",
      "\n",
      " Cycle 35 37\n",
      "Took to collect: 6.485614061355591\n",
      "Took to train: 11.22725796699524\n",
      "\n",
      " Cycle 36 37\n",
      "Took to collect: 7.37532114982605\n",
      "Took to train: 9.03010606765747\n",
      "\n",
      " Cycle 37 37\n",
      "Took to collect: 8.581775665283203\n",
      "Took to train: 9.063071012496948\n",
      "\n",
      " Cycle 38 37\n",
      "Took to collect: 7.264686584472656\n",
      "Took to train: 9.8596830368042\n",
      "\n",
      " Cycle 39 37\n",
      "Took to collect: 8.216996669769287\n",
      "Took to train: 9.169317245483398\n",
      "\n",
      " Cycle 40 37\n",
      "Took to collect: 7.463834524154663\n",
      "Took to train: 10.17422103881836\n",
      "\n",
      " Cycle 41 37\n",
      "Took to collect: 7.675151824951172\n",
      "Took to train: 9.210691452026367\n",
      "\n",
      " Cycle 42 37\n",
      "Took to collect: 5.958533763885498\n",
      "Took to train: 10.031008005142212\n",
      "\n",
      " Cycle 43 37\n"
     ]
    }
   ],
   "source": [
    "!python sac_training.py --run=1 \\\n",
    "--title=her-sac-validation-newrange-3cm \\\n",
    "--train_steps=100 \\\n",
    "--num_epochs=100 \\\n",
    "--her_percent=0.8 \\\n",
    "--env_name=Cloth-v1 \\\n",
    "--task=sideways \\\n",
    "--image_training=1 \\\n",
    "--buffer_size=100000 \\\n",
    "--randomize_params=1 \\\n",
    "--seed=1 \\\n",
    "--num_cycles=100 \\\n",
    "--max_path_length=50 \\\n",
    "--strict=1 \\\n",
    "--distance_threshold=0.03 \\\n",
    "--eval_steps=500 \\\n",
    "--min_expl_steps=1000 \\\n",
    "--randomize_geoms=0 \\\n",
    "--uniform_jnt_tend=1 \\\n",
    "--image_size=84 \\\n",
    "--rgb=1 \\\n",
    "--max_advance=0.05 \\\n",
    "--seed=1 \\\n",
    "--profile=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python sac_evaluation.py --run=1 \\\n",
    "--title=her-sac-validation-newrange \\\n",
    "--train_steps=100 \\\n",
    "--num_epochs=100 \\\n",
    "--her_percent=0.8 \\\n",
    "--env_name=Cloth-v1 \\\n",
    "--task=sideways \\\n",
    "--image_training=1 \\\n",
    "--buffer_size=100000 \\\n",
    "--randomize_params=1 \\\n",
    "--seed=1 \\\n",
    "--profile=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
